<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 4]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 10]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Gen-DBA: Generative Database Agents (Towards a Move 37 for Databases)](https://arxiv.org/abs/2601.16409)
*Yeasir Rayhan,Walid G. Aref*

Main category: cs.DB

TL;DR: 论文聚焦数据库领域AI的创新能力缺失，提出生成式数据库智能体（Gen-DBA）的构想，详细探讨其构建理念和关键技术路线。


<details>
  <summary>Details</summary>
Motivation: 受到自然语言处理、计算机视觉和机器人领域大模型突破的启发，作者期望数据库AI领域也能实现突破性进展，并提出应向生成式、创造性数据库智能体发展。

Method: 本文为愿景型论文，未进行实证研究，主要通过理论论证勾勒Gen-DBA的关键结构，包括基于Transformer的模型架构与生成式推理方法。

Result: 该论文提出在数据库系统领域寻求类似“Move 37”式的人工智能突破，即由AI展现出超越人类专家并创新非传统策略的能力。作者分析了当前AI4DB（数据库系统的人工智能）研究的现状，并提出打造生成式数据库智能体（Gen-DBA）的设想，其目标是为数据库学习任务引入生成式推理和创造性能力。论文还初步提出了Gen-DBA的构建框架，包括Transformer主干、硬件友好的分词机制、双阶段目标导向的下一个token预测训练范式，以及生成式推理过程。

Conclusion: 现有AI4DB系统尚未达到与围棋Move 37类似的突破，作者认为实现Gen-DBA可望带来数据库AI能力的质的飞跃，并为其设计提供初步蓝图。

Abstract: Move\,37 marks one of the major breakthroughs in AI in terms of its ability to surpass human expertise and discover novel strategies beyond the traditional game play in the strategic two-player board game of Go. The domains of Natural Language Processing, Computer Vision, and Robotics have also undergone a similar phenomenon through the advent of large foundational models in the form of Large Language Models (LLMs), Vision Language Models (VLMs) and Vision Language Action models (VLAs), respectively. In this paper, we investigate the current state of Artificial Intelligence for Database Systems research (AI4DB), and assess how far AI4DB systems are from achieving their own Move\,37 moment. We envision a Generative Database Agent (Gen-DBA, for short) as the pathway to achieving Move\,37 for database systems that will bring generative reasoning and creativity into the realm of database learning tasks. This vision paper explores this direction by presenting the recipe for building Gen-DBA that encompasses but is not limited to a Transformer backbone, a hardware-grounded tokenization mechanism, a two-stage Goal-Directed Next Token Prediction training paradigm, and a generative inference process.

</details>


### [2] [iPDB -- Optimizing SQL Queries with ML and LLM Predicates](https://arxiv.org/abs/2601.16432)
*Udesh Kumarasinghe,Tyler Liu,Chunwei Liu,Walid G. Aref*

Main category: cs.DB

TL;DR: iPDB通过将ML和LLM能力深度集成到关系型数据库及SQL中，实现高效、简便的语义计算，无需复杂数据迁移，效果领先。


<details>
  <summary>Details</summary>
Motivation: 现有SQL及关系型数据库不适合直接整合ML/LLM，导致数据多次迁移和复杂编码，效率低下。因此需要一种将数据库与ML/LLM能力高效结合的系统，实现便利而高效的数据智能处理。

Method: iPDB基于关系型数据库架构，扩展了SQL语法，加入LLM和ML调用作为语义运算组成部分。系统设计了“预测操作符”和新颖的语义查询优化策略，使语义相关的SQL操作高效执行。

Result: 该论文提出了iPDB系统——一种支持数据库内机器学习（ML）及大语言模型（LLM）推理的关系型数据库系统。iPDB通过扩展SQL语法，实现了ML与LLM的无缝集成，支持用户在SQL中直接进行语义投影、语义筛选、语义连接及分组计算等操作，大幅简化了原需复杂工程和多次数据迁移的流程。iPDB引入了全新关系型“预测（predict）操作符”及语义查询优化机制，提升了语义SQL查询的易用性和执行效率，并在实验中优于现有最先进方案。

Conclusion: iPDB能够高效支持和简化在数据库中执行机器学习与大语言模型的推理任务，实现性能优越的语义SQL查询。

Abstract: Structured Query Language (SQL) has remained the standard query language for databases. SQL is highly optimized for processing structured data laid out in relations. Meanwhile, in the present application development landscape, it is highly desirable to utilize the power of learned models to perform complex tasks. Large language models (LLMs) have been shown to understand and extract information from unstructured textual data. However, SQL as a query language and accompanying relational database systems are either incompatible or inefficient for workloads that require leveraging learned models. This results in complex engineering and multiple data migration operations that move data between the data sources and the model inference platform. In this paper, we present iPDB, a relational system that supports in-database machine learning (ML) and large language model (LLM) inferencing using extended SQL syntax. In iPDB, LLMs and ML calls can function as semantic projects, as predicates to perform semantic selects and semantic joins, or for semantic grouping in group-by clauses. iPDB has a novel relational predict operator and semantic query optimizations that enable users to write and efficiently execute semantic SQL queries, outperforming the state-of-the-art.

</details>


### [3] [A Scalable Transaction Management Framework for Consistent Document-Oriented NoSQL Databases](https://arxiv.org/abs/2601.16490)
*Adam A. E. Alflahi,Mohammed A. Y. Mohammed,Abdallah Alsammani*

Main category: cs.DB

TL;DR: 论文提出了一种面向NoSQL文档数据库的新型事务管理框架，在保持高一致性保障的同时，实现了在高并发场景下的吞吐量提升和事务稳定性显著优化。


<details>
  <summary>Details</summary>
Motivation: NoSQL数据库因其可扩展性和灵活性广泛应用于现代系统，但常用的最终一致性模型无法可靠地支持强事务处理，从而影响数据一致性与完整性。

Method: 提出一个包含事务生命周期管理、操作分类、预执行冲突检测、自适应加锁和基于超时的死锁预防的四阶段框架，并通过形式化正确性分析和基准测试（如YCSB）及多节点分布式实验，评估方法在不同负载及并发场景下的可行性和性能表现。

Result: 提出的四阶段事务管理框架降低了MongoDB等文档型NoSQL数据库在高并发环境下的事务中止率和延迟方差，消除了死锁，提升了吞吐量，并展现出良好的可扩展性。各项性能指标均优于基线系统及部分主流数据库（如CockroachDB、TiDB等）。

Conclusion: 精心设计的一致性机制可以显著提升NoSQL系统的数据完整性，并且不损害其扩展性。对MongoDB等系统应用此框架，能够在实际工作负载与多节点部署场景下获得更低的中止率与延迟波动及更高吞吐量。

Abstract: NoSQL databases are widely used in modern applications due to their scalability and schema flexibility, yet they often rely on eventual consistency models that limit reliable transaction processing. This study proposes a four-stage transaction management framework for document-oriented NoSQL databases, with MongoDB as the reference platform. The framework combines transaction lifecycle management, operation classification, pre-execution conflict detection, and an adaptive locking strategy with timeout-based deadlock prevention. Formal correctness analysis shows that the proposed approach guarantees conflict serializability under defined conditions. An experimental evaluation using the Yahoo Cloud Serving Benchmark (YCSB) workloads A, B, and F, with concurrency levels ranging from 1 to 100 clients, demonstrates a reduction in transaction abort rates from 8.3% to 4.7%, the elimination of observed deadlocks, and a 34.2% decrease in latency variance. Throughput improvements ranging from 6.3% to 18.4% are observed under high concurrency, particularly for read-modify-write workloads. Distributed experiments on clusters of up to 9 nodes confirm scalability, achieving 15.2% higher throughput and 53% lower abort rates than baseline systems. Comparisons with MongoDB's native transactions, CockroachDB, and TiDB indicate that the proposed framework strikes a good balance between consistency guarantees and performance overhead. Sensitivity analysis identifies optimal parameter settings, including a lock timeout of 100 ms, an initial backoff of 10 ms, and a maximum backoff of 500 ms. These results show that carefully designed consistency mechanisms can significantly improve data integrity in NoSQL systems without undermining scalability.

</details>


### [4] [A Categorical Approach to Semantic Interoperability across Building Lifecycle](https://arxiv.org/abs/2601.16663)
*Zoltan Nagy,Ryan Wisnesky,Kevin Carlson,Eswaran Subrahmanian,Gioele Zardini*

Main category: cs.DB

TL;DR: 论文以范畴论为基础，实现建筑生命周期多本体之间低复杂度、自动化的数据集成，显著提升异构数据互操作性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 建筑生命周期数据高度异构，当前四十余种元数据标准碎片化严重。传统对点映射方法扩展性差，普遍本体臃肿且难维护，缺乏能保留结构的信息转换数学基础。该研究目标是寻求系统性和可扩展的数据集成解决方案。

Method: 使用范畴论作为结构化异构建筑数据集成的数学基础。将建筑本体形式化为一阶理论，并在 Categorical Query Language (CQL) 中实现范畴化数据转换与集成。

Result: 范畴论方法实现了线性复杂度（O(n)）的本体数据集成，在 CQL 中完成了两个原型：1) IFC 设计数据到 BRICK 模型自动转换，2) IFC、BRICK 和 RealEstateCore 三方本体自动集成，显著减少映射需求且支持自动双向迁移和跨本体查询。

Conclusion: 范畴论及其在 CQL 中的应用为建筑数据集成提供了正确且高效的数学基础，有望推动建筑领域数据应用生态的类似智能手机平台式发展，提高可靠性和互操作性。

Abstract: Buildings generate heterogeneous data across their lifecycle, yet integrating these data remains a critical unsolved challenge. Despite three decades of standardization efforts, over 40 metadata schemas now span the building lifecycle, with fragmentation accelerating rather than resolving. Current approaches rely on point-to-point mappings that scale quadratically with the number of schemas, or universal ontologies that become unwieldy monoliths. The fundamental gap is the absence of mathematical foundations for structure-preserving transformations across heterogeneous building data. Here we show that category theory provides these foundations, enabling systematic data integration with $O(n)$ specification complexity for $n$ ontologies. We formalize building ontologies as first-order theories and demonstrate two proof-of-concept implementations in Categorical Query Language (CQL): 1) generating BRICK models from IFC design data at commissioning, and 2) three-way integration of IFC, BRICK, and RealEstateCore where only two explicit mappings yield the third automatically through categorical composition. Our correct-by-construction approach treats property sets as first-class schema entities and provides automated bidirectional migrations, and enables cross-ontology queries. These results establish feasibility of categorical methods for building data integration and suggest a path toward an app ecosystem for buildings, where mathematical foundations enable reliable component integration analogous to smartphone platforms.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [5] [Computational Foundations for Strategic Coopetition: Formalizing Collective Action and Loyalty](https://arxiv.org/abs/2601.16237)
*Vik Pant,Eric Yu*

Main category: cs.MA

TL;DR: 本文提出了一个扩展的团队级战略合作与竞争的计算框架，通过将忠诚度引入团队多智能体的效用函数，有效解决了团队中搭便车问题，并经过大规模实验与实际案例验证。


<details>
  <summary>Details</summary>
Motivation: 经典博弈模型下团队协作总是发生集体懈怠（搭便车），现有方法难以刻画复杂的合作-竞争团队动力，亟需可扩展计算方法揭示和缓解集体行动困境。

Method: 构建基于忠诚度调节的效用函数，包括忠诚收益和成本容忍机制，整合i*结构依赖，通过实验（3125种配置）及Apache HTTP Server实证验证，量化忠诚对团队贡献的影响，并统计分析显著性。

Result: 忠诚度机制使团队成员努力水平分化明显（中位数提升15.04倍），全部六大行为指标达线，实证案例（Apache项目）完全复现实际贡献演化过程，统计显著性强（p<0.001，效应量d=0.71）。

Conclusion: 团队成员的忠诚度能显著提升集体贡献与努力水平，有效缓解多智能体协作中的搭便车现象，模型在理论和实际软件团队中均获验证。

Abstract: Mixed-motive multi-agent settings are rife with persistent free-riding because individual effort benefits all members equally, yet each member bears the full cost of their own contribution. Classical work by Holmström established that under pure self-interest, Nash equilibrium is universal shirking. While i* represents teams as composite actors, it lacks scalable computational mechanisms for analyzing how collective action problems emerge and resolve in coopetitive settings. This technical report extends computational foundations for strategic coopetition to team-level dynamics, building on companion work formalizing interdependence/complementarity (arXiv:2510.18802) and trust dynamics (arXiv:2510.24909). We develop loyalty-moderated utility functions with two mechanisms: loyalty benefit (welfare internalization plus intrinsic contribution satisfaction) and cost tolerance (reduced effort burden for loyal members). We integrate i* structural dependencies through dependency-weighted team cohesion, connecting member incentives to team-level positioning. The framework applies to both human teams (loyalty as psychological identification) and multi-agent systems (alignment coefficients and adjusted cost functions). Experimental validation across 3,125 configurations demonstrates robust loyalty effects (15.04x median effort differentiation). All six behavioral targets achieve thresholds: free-riding baseline (96.5%), loyalty monotonicity (100%), effort differentiation (100%), team size effect (100%), mechanism synergy (99.5%), and bounded outcomes (100%). Empirical validation using published Apache HTTP Server (1995-2023) case study achieves 60/60 points, reproducing contribution patterns across formation, growth, maturation, and governance phases. Statistical significance confirmed at p<0.001, Cohen's d=0.71.

</details>


### [6] [AMBER: A Columnar Architecture for High-Performance Agent-Based Modeling in Python](https://arxiv.org/abs/2601.16292)
*Anh-Duy Pham*

Main category: cs.MA

TL;DR: 本论文提出AMBER框架，通过使用Polars DataFrame实现列式状态管理，显著提升了Python ABM仿真的计算性能与内存效率，为高性能智能体建模提供新范式。


<details>
  <summary>Details</summary>
Motivation: 当前基于Python的智能体建模（ABM）框架存在可访问性与大规模仿真计算性能之间的矛盾。该研究旨在解决Python易用性与高性能要求难以兼得的问题。

Method: 提出了一种新的架构方法：利用Polars DataFrame库以列式存储方式管理状态，替代传统每个智能体一个对象的实现。同时，对两种范式的计算特征进行了分析，并阐述了AMBER框架的架构设计，包括核心抽象、空间环境、实验管理及优化功能。最终通过三个标准基准进行实证评估。

Result: AMBER在不同工作负载下实现了1.2倍至93倍的加速，并在以全体属性操作占主导的模型中表现出最显著优势。内存使用峰值较面向对象框架减少30-50%。

Conclusion: 基于列式状态管理的架构，为基于解释型语言的高性能ABM提供了可行的基础。

Abstract: Agent-based modeling (ABM) has emerged as an indispensable methodology for studying complex adaptive systems across the natural and social sciences. However, Python-based ABM frameworks face a fundamental tension between the accessibility that has made Python dominant in scientific computing and the performance requirements of large-scale simulations. This paper introduces AMBER, a framework that resolves this tension through a novel architectural approach: replacing the conventional object-per-agent representation with columnar state management using the Polars DataFrame library. We analyze the computational characteristics of both paradigms, present the architectural design of AMBER including its core abstractions, spatial environments, experiment management, and optimization capabilities. Empirical evaluation on three canonical benchmarks demonstrates that AMBER achieves speedups of 1.2x to 93x depending on workload characteristics, with the greatest advantages for models dominated by population-wide attribute operations. Memory profiling reveals 30-50% reduction in peak usage compared to object-oriented frameworks. Our results establish columnar state management as a viable architectural foundation for high-performance ABM in interpreted languages.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems](https://arxiv.org/abs/2601.16286)
*Varun Chillara,Dylan Kline,Christopher Alvares,Evan Wooten,Huan Yang,Shlok Khetan,Cade Bauer,Tré Guillory,Tanishka Shah,Yashodhara Dhariwal,Volodymyr Pavlov,George Popstefanov*

Main category: cs.AI

TL;DR: 本文提出了SemanticALLI架构，通过将AI推理流程中易复用的中间逻辑结构化并缓存，从而显著提高了AI流水线的效率。


<details>
  <summary>Details</summary>
Motivation: 传统AI流水线存在大量中间推理逻辑的冗余重建，尤其是在用户自然语言表达多样的情况下，原有缓存方法难以捕捉并利用这些可复用的逻辑，导致效率低下。

Method: 将生成过程分为分析意图解析（AIR）和可视化合成（VS）两个阶段，将中间表示（IR）结构化为可缓存的工件，在流水线中实现高命中率的分阶段缓存。

Result: 与传统整体缓存方式38.7%的命中率相比，结构化分阶段缓存方式在可视化合成阶段能达到83.10%的命中率，显著减少了LLM调用次数和总时延，节约了token消耗。

Conclusion: 结构化中间表示与分阶段缓存能够极大提升Agentic AI流水线中的缓存命中率和推理效率，降低推理成本。

Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.

</details>


### [8] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: Doc2AHP通过结构约束和多智能体优化，实现了无专家参与的高质量决策建模，效果优于现有生成式模型。


<details>
  <summary>Details</summary>
Motivation: LLM在语义理解上表现优秀，但在结构一致性和复杂推理可靠性上存在不足。而传统AHP虽逻辑严密，但建设过程依赖领域专家，难以扩展。该方法旨在融合LLM泛化能力与AHP决策理论的严谨性，解决专业瓶颈。

Method: 提出Doc2AHP框架，结合AHP结构化推理原则，引入多智能体权重机制与自适应一致性优化，通过约束LLM在文档空间的结构化搜索，实现决策建模。

Result: Doc2AHP无需大量标注或人工干预，能够自动引导LLM完成结构一致的决策建模，逻辑完整性和下游任务准确性均显著优于直接生成式基线方法。

Conclusion: Doc2AHP有效结合LLM与AHP优势，实现面向复杂决策任务的自动结构推理，面向非专业用户赋能决策建模，且在逻辑与任务表现方面优越。

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [9] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: 本研究提出了用于评估临床决策AI在患者社交压力下鲁棒性的对抗仿真框架，发现传统基准不能反映真实安全性，强调需用多轮对抗测试以验证AI临床应用的可靠性。


<details>
  <summary>Details</summary>
Motivation: LLMs已表现出在临床决策支持中的潜力，但容易在患者不合理请求下妥协，影响其实际应用的安全性。因此需要新的评估方法以检验其在现实社交压力场景下的表现。

Method: 提出SycoEval-EM多智能体仿真框架，通过在急诊医学场景中模拟对抗性患者劝说，评估20个LLMs在1875次临床决策对话中的鲁棒性。分析不同情境（影像学检查、阿片类药物处方）下的顺从率以及不同说服策略的效果。

Result: 顺从率在0-100%之间，影像学检查的顺从率（38.8%）高于阿片类处方（25.0%），模型能力无法准确预测鲁棒性。所有说服策略效果接近（30.0-36.0%），显示模型普遍易受影响，无特定策略弱点。

Conclusion: 静态基准测试无法充分预测大型语言模型（LLMs）在临床社交压力下的安全性，亟需多轮对抗测试来进行临床AI认证。

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [10] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 医学多模态分类任务中，传统机器学习模型在大部分任务下表现最优，基础大模型与细微微调未展现出预期优势，方法选择需结合具体数据类型和任务特性。


<details>
  <summary>Details</summary>
Motivation: 结合多模态视觉-语言模型（VLMs）与大型语言模型（LLMs）有望推动医学分类应用，需要对比传统机器学习与新型变换器模型在多模态医学数据上的性能表现，指导模型选择。

Method: 采用四个公开医学多模态数据集（含文本与图像，二分类及多分类），比较了三类模型：经典ML（LR、LightGBM、ResNet-50）、prompt式LLM/VLM（Gemini 2.5）、PEFT微调（LoRA-Gemma3），使用统一的数据划分和指标进行性能评估。

Result: 传统机器学习模型在多数医学分类任务中总体表现最佳，尤其在结构化文本数据集上优势显著。LoRA微调的Gemma变体在所有任务中表现最差，无法泛化。零样本LLM/VLM（Gemini 2.5）在文本任务上效果不佳，但在多类图像任务上与ResNet-50基线相当。PEFT方法的微调效果高度依赖具体适配策略，本研究中的最小微调反而有害表现。

Conclusion: 基础大模型及参数高效微调（PEFT）策略未必在医学分类中优于传统机器学习，尤其在结构化文本和有限微调下效果有限。实践中推荐优先选用成熟的传统ML方法，并谨慎评估大模型与微调方案的适应性。

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [11] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 论文通过设计可调复杂性任务与精确干预手段，衡量大模型各项能力对多轮任务表现的关键性，发现部分能力持续有效，部分能力受限于环境。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型在复杂多轮任务中的不足，明确各类底层能力对提升模型表现的实际作用，为未来AI模型发展指明方向。

Method: 提出“oracle反事实”方法，对模型在多轮任务中的关键能力提供完美干预，通过程序化生成、可调复杂度的游戏任务对能力进行精确测量，避免现实基准测试的混杂影响。

Result: 该论文通过建立“oracle反事实框架”，分析大语言模型在多轮、长周期任务上的具体瓶颈，明确不同底层能力（如规划、状态跟踪、长上下文处理）对任务表现的影响。研究表明，诸如完美规划等能力在多种情境下能显著提升模型表现，但其他技能的效用则取决于环境与模型特性。

Conclusion: 部分底层能力（如规划）对多轮任务提升效果显著，环境和模型属性决定其他能力效用，指明未来AI模型应优先突破关键技能。

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [12] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: 提出AgentsEval多智能体推理框架，细化报告评估流程、提升医学评估的透明性与可靠性，并在多数据集、多扰动下效果突出。


<details>
  <summary>Details</summary>
Motivation: 现有医疗影像报告自动生成评估方法无法准确捕捉放射科诊断逻辑，导致评判不可靠、临床相关性不足。

Method: 采用多智能体，将评估流程分为标准定义、证据提取、对齐和一致性评分等步骤，同时建立多领域扰动基准进行全面实验。

Result: AgentsEval框架在多种语义扰动和影像数据集上展现出临床一致性、语义忠实性和可解释性，评估结果具备鲁棒性。

Conclusion: AgentsEval推动了医学报告生成系统评估的透明化与临床可信性，为大语言模型在医学影像领域的实际应用奠定了基础。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [13] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601是开源领域表现最优的5600亿参数MoE推理模型，通过统一训练框架与多创新设计，实现了在agentic推理、工具交互和现实环境鲁棒性上的突破。


<details>
  <summary>Details</summary>
Motivation: 提升开源模型在agentic推理任务上的能力，尤其对复杂工具交互、真实环境噪声及大规模多域训练场景进行优化，满足实际应用所需的推理泛化及鲁棒性。

Method: 提出了一个5600亿参数的开源专家混合(MoE)推理模型LongCat-Flash-Thinking-2601，采用域并行专家训练结合后融合，以及自端到端数据、环境、算法和基础设施协同设计，从预训练到后训练。同时系统性扩展了异步强化学习框架DORA以支持大规模多环境训练，并引入Heavy Thinking模式以测试时扩展推理深度和广度。

Result: 在广泛的agentic基准上取得开源模型中最先进表现，具备强工具交互泛化与真实场景鲁棒性。异步RL框架和针对噪声模式的训练流程，有效提升了模型稳定和性能。Heavy Thinking模式进一步增强了对复杂推理任务的应对能力。

Conclusion: 该模型显著提升了开源模型在复杂agentic任务中的泛化和鲁棒性能力，其系统性、多方面创新对大规模智能体推理模型的发展具有重要推动作用。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [14] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 本文提出了受昆虫启发的视觉导航智能体，将昆虫大脑的两种功能结构模型应用于机器人导航任务，既实现了高效的学习能力，又具备路径整合功能。该方法在计算资源极低的情况下，性能接近当前最先进模型，并能在更为真实的仿真环境中表现出较强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 受昆虫在复杂环境下以极低能耗完成高效导航的能力启发，旨在设计出计算高效且鲁棒性强的视觉导航智能体，满足现实场景中对低资源消耗与稳定性的需求。

Method: 方法上，将昆虫大脑中与联想学习和路径整合相关的结构进行了抽象建模，并应用于视觉点目标导航任务，与目前主流基准任务（如Habitat）进行类比与实验验证。

Result: 实验结果显示，所提出的智能体在极低的计算资源消耗下，在标准导航任务中能实现与SOTA模型相当的表现，并在更复杂和真实的仿真环境中表现出良好的抗干扰能力。

Conclusion: 受昆虫大脑机制启发的简易模型能以远低于计算成本的代价，在视觉点目标导航任务上达到与先进模型相当的表现，并具备良好的环境适应能力。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [15] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 强化学习优化的推理型LLM在心智理论任务中表现更稳健，主要得益于鲁棒性而非产生了新的推理机制。


<details>
  <summary>Details</summary>
Motivation: 近期大语言模型（LLMs）在心智理论（ToM）测试中表现优异，引发了关于其能力本质的讨论。与此同时，通过带可验证奖励的强化学习训练的推理型LLMs（RLVR）在多个基准上取得了明显进步。本研究旨在探究此类推理模型在ToM任务中的表现及其能力实质。

Method: 通过对推理型LLM应用机器心理学实验和标准ToM基准测试，分析其在不同提示与任务扰动下的表现，并与传统表现进行对比，从而评估模型能力来源。

Result: 实验发现，RLVR推理模型在面对提示变化和任务扰动时，表现出更强的鲁棒性。这些提升更可能归因于其在找到正确解答上的鲁棒性增强，而非拥有了全新形式的ToM推理能力。

Conclusion: 评估LLM社会认知行为时，应区分模型鲁棒性提升和心智理论能力本质，当前的推理模型优势主要在于解题鲁棒性，而非具备真正的新型社会认知推理。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [16] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: 论文开发AI平台辅助医疗设备维修，在超声仪案例中表现出高精度，平台含故障排查和同行交流功能，提升诊断与维修效率，缓解设备闲置和故障问题。


<details>
  <summary>Details</summary>
Motivation: 低中收入国家大量医疗设备因缺乏维护和技术支持而闲置或故障，影响诊断和患者治疗质量，驱动开发AI辅助平台以提升设备使用率和运行可靠性。

Method: 构建了集大语言模型与网页交互界面的AI系统，用户输入错误代码或症状后可获得详细排查和修复指导，并设有全球交流论坛，实际以超声仪设备作为案例进行精度与建议有效性验证。

Result: 该论文提出并验证了一个AI支持平台，旨在帮助低中收入国家的生物医学技术人员实现医疗设备的实时诊断与维修。系统结合大语言模型和在线界面，能够针对设备错误代码和症状给出精准排查方案，并通过全球技术论坛促进经验交流。在以Philips HDI 5000超声仪为例的验证中，系统对错误代码的解读精度达100%，提出的纠正措施准确率达80%。

Conclusion: AI驱动平台可有效协助生物医学技术人员进行设备故障诊断和修复，有望降低设备停机时间，显著改善资源受限地区的医疗服务水平。

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>
