{"id": "2601.11327", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11327", "abs": "https://arxiv.org/abs/2601.11327", "authors": ["Agata \u017bywot", "Xinyi Chen", "Maarten de Rijke"], "title": "Can Small Agent Collaboration Beat a Single Big LLM?", "comment": null, "summary": "This report studies whether small, tool-augmented agents can match or outperform larger monolithic models on the GAIA benchmark. Using Qwen3 models (4B-32B) within an adapted Agentic-Reasoning framework, we isolate the effects of model scale, explicit thinking (no thinking, planner-only, or full), and tool use (search, code, mind-map). Tool augmentation provides the largest and most consistent gains. Using tools, 4B models can outperform 32B models without tool access on GAIA in our experimental setup. In contrast, explicit thinking is highly configuration- and difficulty-dependent: planner-only thinking can improve decomposition and constraint tracking, while unrestricted full thinking often degrades performance by destabilizing tool orchestration, leading to skipped verification steps, excessive tool calls, non-termination, and output-format drift.", "AI": {"tldr": "\u5c0f\u6a21\u578b\u914d\u5408\u5de5\u5177\u589e\u5f3a\u53ef\u5728GAIA\u57fa\u51c6\u8d85\u8d8a\u672a\u589e\u5f3a\u5927\u6a21\u578b\uff0c\u5de5\u5177\u589e\u5f3a\u662f\u63d0\u5347\u7684\u4e3b\u8981\u6765\u6e90\uff0c\u8fc7\u5ea6\u63a8\u7406\u53ef\u80fd\u53cd\u800c\u964d\u4f4e\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u89c2\u70b9\u8ba4\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u6027\u80fd\u66f4\u597d\uff0c\u672c\u7814\u7a76\u63a2\u7d22\u5c0f\u6a21\u578b\u901a\u8fc7\u667a\u80fd\u7b56\u7565\uff08\u5de5\u5177\u589e\u5f3a\u4e0e\u63a8\u7406\u5c42\u7ea7\u63a7\u5236\uff09\u5f25\u8865\u89c4\u6a21\u52a3\u52bf\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u6210\u672c\u548c\u7075\u6d3b\u6027\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u4f5c\u8005\u91c7\u75284B-32B\u7684Qwen3\u6a21\u578b\uff0c\u5728\u6539\u8fdb\u7684Agentic-Reasoning\u6846\u67b6\u4e0b\uff0c\u901a\u8fc7\u63a7\u5236\u53d8\u91cf\u5bf9\u6bd4\u6a21\u578b\u89c4\u6a21\u3001\u63a8\u7406\u6a21\u5f0f\uff08\u65e0\u63a8\u7406\u3001\u4ec5\u89c4\u5212\u3001\u5b8c\u5168\u63a8\u7406\uff09\u3001\u5de5\u5177\u8c03\u7528\u4e09\u5927\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u5e76\u5728GAIA\u57fa\u51c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u8be5\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u5de5\u5177\u589e\u5f3a\uff0c\u8f83\u5c0f\u89c4\u6a21\u7684\u6a21\u578b\uff08\u4f8b\u59824B\u53c2\u6570\u7684Qwen3\uff09\u80fd\u591f\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8d85\u8d8a\u672a\u589e\u5f3a\u5927\u578b\u6a21\u578b\uff08\u598232B\u53c2\u6570\u7684\u6a21\u578b\uff09\u3002\u5de5\u5177\u589e\u5f3a\uff08\u5305\u62ec\u641c\u7d22\u3001\u7f16\u7a0b\u3001\u601d\u7ef4\u5bfc\u56fe\uff09\u6240\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u6700\u7a33\u5b9a\u3001\u6700\u663e\u8457\uff0c\u800c\u663e\u5f0f\u63a8\u7406\u7684\u6548\u679c\u5219\u53d6\u51b3\u4e8e\u5177\u4f53\u914d\u7f6e\u548c\u4efb\u52a1\u96be\u5ea6\u3002\u90e8\u5206\u63a8\u7406\uff08\u4ec5\u89c4\u5212\u5668\u6a21\u5f0f\uff09\u6709\u5229\u4e8e\u4efb\u52a1\u5206\u89e3\u4e0e\u7ea6\u675f\u8ffd\u8e2a\uff0c\u4f46\u201c\u5b8c\u5168\u81ea\u7531\u201d\u63a8\u7406\u53cd\u800c\u53ef\u80fd\u5bfc\u81f4\u8868\u73b0\u4e0b\u964d\uff0c\u56e0\u4e3a\u5b83\u4f1a\u6270\u4e71\u5de5\u5177\u8c03\u7528\u6d41\u7a0b\uff0c\u51fa\u73b0\u8df3\u8fc7\u9a8c\u8bc1\u3001\u8fc7\u5ea6\u8c03\u7528\u3001\u4efb\u52a1\u65e0\u6cd5\u5b8c\u6210\u53ca\u8f93\u51fa\u683c\u5f0f\u6df7\u4e71\u7b49\u95ee\u9898\u3002", "conclusion": "\u5de5\u5177\u589e\u5f3a\u5bf9\u4e8e\u5c0f\u6a21\u578b\u5c24\u5176\u5173\u952e\uff0c\u4f7f\u5176\u6027\u80fd\u5927\u5e45\u63d0\u5347\uff0c\u751a\u81f3\u8d85\u8fc7\u66f4\u5927\u6a21\u578b\u3002\u63a8\u7406\u7b56\u7565\u9700\u8c28\u614e\u9009\u62e9\uff0c\u8fc7\u4e8e\u590d\u6742\u7684\u663e\u5f0f\u63a8\u7406\u53ef\u80fd\u635f\u5bb3\u7cfb\u7edf\u6574\u4f53\u8868\u73b0\u3002"}}
{"id": "2601.10726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10726", "abs": "https://arxiv.org/abs/2601.10726", "authors": ["Ross Chu", "Yuting Huang"], "title": "Building AI Agents to Improve Job Referral Requests to Strangers", "comment": null, "summary": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u4e8eAI\u667a\u80fd\u4f53\u7684\u7cfb\u7edf\uff0c\u65e8\u5728\u534f\u52a9\u6c42\u804c\u8005\u4f18\u5316\u5728\u4e13\u4e1a\u793e\u533a\u4e2d\u7684\u5185\u63a8\u8bf7\u6c42\u6587\u672c\uff0c\u5e76\u5229\u7528\u6548\u679c\u8bc4\u4f30\u6a21\u578b\u5bf9\u4fee\u6539\u7ed3\u679c\u8fdb\u884c\u8d28\u91cf\u9884\u6d4b\u3002\u5f15\u5165\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u540e\uff0cAI\u80fd\u591f\u663e\u8457\u63d0\u5347\u5f31\u5185\u63a8\u8bf7\u6c42\u7684\u6548\u679c\uff0c\u5e76\u907f\u514d\u635f\u5bb3\u5f3a\u8bf7\u6c42\u7684\u8868\u73b0\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u63d0\u5347\u6c42\u804c\u8005\u901a\u8fc7\u7ebf\u4e0a\u793e\u533a\u83b7\u5f97\u5185\u63a8\u7684\u6210\u529f\u6982\u7387\uff0c\u5c24\u5176\u5173\u6ce8\u5982\u4f55\u5229\u7528AI\u6280\u672f\u81ea\u52a8\u4f18\u5316\u5185\u63a8\u8bf7\u6c42\u6587\u672c\uff0c\u4ece\u800c\u63d0\u5347\u5185\u63a8\u540c\u610f\u7387\u5e76\u4e3a\u5927\u89c4\u6a21\u90e8\u7f72\u63d0\u4f9b\u5148\u9a8c\u6709\u6548\u6027\u6307\u6807\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u6539\u5199\u578b\u667a\u80fd\u4f53\uff08Improver Agent\uff09\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bf9\u6c42\u804c\u5185\u63a8\u8bf7\u6c42\u8fdb\u884c\u6539\u5199\uff1b2\uff09\u8bc4\u4f30\u578b\u667a\u80fd\u4f53\uff08Evaluator Agent\uff09\u901a\u8fc7\u4e00\u4e2a\u9884\u6d4b\u5b9e\u9645\u83b7\u5f97\u5185\u63a8\u6982\u7387\u7684\u8bad\u7ec3\u6a21\u578b\u6765\u8bc4\u4f30\u6539\u5199\u8d28\u91cf\uff1b3\uff09\u5c06LLM\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7ed3\u5408\uff0c\u4ee5\u907f\u514d\u5bf9\u5f3a\u8bf7\u6c42\u7684\u4e0d\u826f\u6539\u5199\uff0c\u5e76\u5f3a\u5316\u5bf9\u5f31\u8bf7\u6c42\u7684\u4f18\u5316\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u7ed3\u5408RAG\u589e\u5f3a\u7684\u7f16\u8f91\u80fd\u63d0\u5347\u5f31\u8bf7\u6c4214%\u7684\u6210\u529f\u9884\u6d4b\u7387\uff0c\u4e14\u4e0d\u4f1a\u5f71\u54cd\u5f3a\u8bf7\u6c42\u7684\u8868\u73b0\u3002\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u4e3a\u5927\u89c4\u6a21\u5b9e\u9a8c\u524d\u7684\u4f18\u9009\u7279\u5f81\u63d0\u4f9b\u4e86\u5f3a\u4fe1\u53f7\u3002", "conclusion": "\u7ed3\u5408LLM\u4e0eRAG\u7684\u4fee\u6539\u65b9\u5f0f\u80fd\u5728\u4e0d\u5f71\u54cd\u5f3a\u8bf7\u6c42\u7684\u57fa\u7840\u4e0a\uff0c\u4f7f\u5f31\u8bf7\u6c42\u7684\u6a21\u578b\u9884\u6d4b\u6210\u529f\u7387\u63d0\u534714%\uff0c\u4e3a\u5927\u89c4\u6a21\u771f\u5b9e\u5b9e\u9a8c\u524d\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u9ad8\u4fe1\u53f7\u7684\u7279\u5f81\u9009\u62e9\u53c2\u8003\u3002"}}
{"id": "2601.10738", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10738", "abs": "https://arxiv.org/abs/2601.10738", "authors": ["Percy Jardine"], "title": "CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems", "comment": null, "summary": "Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.", "AI": {"tldr": "CTHA\u901a\u8fc7\u7ea6\u675f\u5c42\u95f4\u901a\u4fe1\u4e0e\u51b3\u7b56\u7a7a\u95f4\uff0c\u6709\u6548\u6539\u5584\u591a\u65f6\u95f4\u5c3a\u5ea6\u667a\u80fd\u4f53\u5c42\u6b21\u7ed3\u6784\u7684\u534f\u8c03\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7a33\u5b9a\u6027\u548c\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u65f6\u95f4\u5c3a\u5ea6\u667a\u80fd\u4f53\u67b6\u6784\u867d\u7136\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u5c42\u6b21\u7ed3\u6784\u5728\u6027\u80fd\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5176\u534f\u8c03\u7a33\u5b9a\u6027\u53d7\u5230\u4e25\u91cd\u635f\u5bb3\uff0c\u5e26\u6765\u5c42\u95f4\u51b2\u7a81\u3001\u9519\u8bef\u4f20\u64ad\u548c\u53ef\u6269\u5c55\u6027\u53d7\u9650\u7b49\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06\u5c42\u95f4\u901a\u4fe1\u6295\u5f71\u5230\u7ed3\u6784\u5316\u6d41\u5f62\uff0c\u5e76\u8bbe\u5b9a\u4e09\u7c7b\u5173\u952e\u7ea6\u675f\u2014\u2014\u6d88\u606f\u5408\u7ea6\u3001\u6743\u9650\u6d41\u5f62\u548c\u4ef2\u88c1\u89e3\u6790\uff0c\u4fdd\u969c\u5c42\u95f4\u4fe1\u606f\u6d41\u3001\u51b3\u7b56\u7a7a\u95f4\u53ca\u51b3\u7b56\u534f\u8c03\u7684\u6709\u5e8f\u6027\u4e0e\u7a33\u5b9a\u6027\u3002", "result": "\u63d0\u51fa\u7684CTHA\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u6545\u969c\u7ea7\u8054\uff08\u51cf\u5c1147%\uff09\uff0c\u63d0\u5347\u6837\u672c\u6548\u7387\uff08\u63d0\u53472.3\u500d\uff09\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u8d85\u8fc7\u65e0\u7ea6\u675f\u5c42\u6b21\u5316\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CTHA\u4f5c\u4e3a\u9488\u5bf9\u591a\u65f6\u95f4\u5c3a\u5ea6\u5c42\u6b21\u7ed3\u6784\u7684\u901a\u7528\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7ea6\u675f\u548c\u4ef2\u88c1\u673a\u5236\uff0c\u6df1\u5316\u4e86\u591a\u667a\u80fd\u4f53\u534f\u8c03\u7406\u8bba\u5e76\u4e3a\u81ea\u6cbb\u7cfb\u7edf\u53d1\u5c55\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.10744", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.10744", "abs": "https://arxiv.org/abs/2601.10744", "authors": ["Sen Wang", "Bangwei Liu", "Zhenkun Gao", "Lizhuang Ma", "Xuhong Wang", "Yuan Xie", "Xin Tan"], "title": "Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration", "comment": "Our dataset and code will be released at our \\href{https://wangsen99.github.io/papers/lmee/}{website}", "summary": "An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u957f\u671f\u8bb0\u5fc6\u4f53\u611f\u63a2\u7d22\u65b9\u6cd5\u4e0e\u57fa\u51c6\uff0c\u6784\u5efa\u6570\u636e\u96c6\u5e76\u8bbe\u8ba1\u4e86\u7ed3\u5408\u63a2\u7d22\u4e0e\u8bb0\u5fc6\u53ec\u56de\u7684\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u4e00\u6b21\u6027\u4f53\u611f\u4efb\u52a1\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u5b8c\u6210\u7ed3\u679c\uff0c\u5ffd\u7565\u63a2\u7d22\u8fc7\u7a0b\u548c\u8bb0\u5fc6\u5229\u7528\uff0c\u4f46\u590d\u6742\u957f\u671f\u4efb\u52a1\u548c\u901a\u7528\u73af\u5883\u4e0b\u64cd\u4f5c\u9700\u8981\u4f53\u611f\u4f53\u5177\u5907\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\u548c\u957f\u65f6\u8bb0\u5fc6\uff0c\u6709\u6548\u4f18\u5316\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u8bbe\u8ba1\u4e86LMEE\u957f\u671f\u8bb0\u5fc6\u4f53\u611f\u63a2\u7d22\u65b9\u6cd5\u53ca\u57fa\u51c6\uff0c\u5305\u62ec\u591a\u76ee\u6807\u5bfc\u822a\u548c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u95ee\u7b54\u4efb\u52a1\uff0c\u5e76\u63d0\u51faMemoryExplorer\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u591a\u6a21\u6001\u5927\u6a21\u578b\uff0c\u5f15\u5165\u5305\u62ec\u52a8\u4f5c\u9884\u6d4b\u3001\u524d\u6cbf\u9009\u62e9\u548c\u95ee\u7b54\u7684\u591a\u4efb\u52a1\u5956\u52b1\u673a\u5236\uff0c\u5b9e\u73b0\u4e3b\u52a8\u63a2\u7d22\u4e0e\u8bb0\u5fc6\u5229\u7528\u3002", "result": "\u6240\u63d0\u51fa\u7684MemoryExplorer\u65b9\u6cd5\uff0c\u5728\u957f\u65f6\u5e8f\u4f53\u611f\u4efb\u52a1\u4e2d\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u6700\u65b0\u6a21\u578b\uff0c\u5728\u4e3b\u52a8\u63a2\u7d22\u548c\u8bb0\u5fc6\u5229\u7528\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u63a2\u7d22\u8ba4\u77e5\u4e0e\u51b3\u7b56\u884c\u4e3a\uff0c\u589e\u5f3a\u4f53\u611f\u4f53\u4e3b\u52a8\u8bb0\u5fc6\u67e5\u8be2\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u66f4\u597d\u5b9e\u73b0\u7ec8\u8eab\u5b66\u4e60\uff0c\u5e76\u5728\u590d\u6742\u957f\u671f\u4efb\u52a1\u4e2d\u6709\u66f4\u4f18\u8868\u73b0\u3002"}}
{"id": "2601.10768", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10768", "abs": "https://arxiv.org/abs/2601.10768", "authors": ["Nina Bo\u010dkov\u00e1", "Barbora Voln\u00e1", "Mirko Dohnal"], "title": "Optimisation of complex product innovation processes based on trend models with three-valued logic", "comment": null, "summary": "This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.", "AI": {"tldr": "\u5229\u7528\u7b80\u5355\u8d8b\u52bf\u542f\u53d1\u5f0f\u6784\u5efa\u521b\u65b0\u8fc7\u7a0b\u6a21\u578b\uff0c\u7528\u8f6c\u79fb\u56fe\u5c55\u793a\u65b9\u6848\u95f4\u53ef\u80fd\u8f6c\u79fb\uff0c\u76f4\u89c2\u8868\u8fbe\u7cfb\u7edf\u6f14\u5316\u8def\u5f84\uff0c\u65e0\u9700\u590d\u6742\u6570\u503c\u5316\u3002", "motivation": "\u5206\u6790\u590d\u6742\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\uff0c\u5bfb\u6c42\u4f4e\u4fe1\u606f\u5f3a\u5ea6\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u542f\u53d1\u5f0f\u8d8b\u52bf\uff08\u589e\u957f\u3001\u51cf\u5c11\u3001\u6052\u5b9a\uff09\u5efa\u7acb\u6a21\u578b\uff0c\u901a\u8fc7\u8f6c\u79fb\u56fe\u63cf\u8ff0\u573a\u666f\u53ca\u5176\u8f6c\u6362\u3002", "result": "\u63d0\u51fa\u57fa\u4e8e\u542f\u53d1\u5f0f\u8d8b\u52bf\u7684\u6a21\u578b\uff0c\u5e76\u4ee5\u8f6c\u79fb\u56fe\u7684\u8def\u5f84\u63cf\u8ff0\u7cfb\u7edf\u53ef\u80fd\u7684\u8fc7\u53bb\u4e0e\u672a\u6765\u884c\u4e3a\u3002", "conclusion": "\u8d8b\u52bf\u6a21\u578b\u4e0e\u573a\u666f\u8f6c\u79fb\u56fe\u4e3a\u521b\u65b0\u8fc7\u7a0b\u7684\u8868\u8fbe\u63d0\u4f9b\u7b80\u6d01\u6709\u6548\u7684\u65b9\u5f0f\uff0c\u9002\u7528\u4fe1\u606f\u6709\u9650\u573a\u666f\u3002"}}
{"id": "2601.10904", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10904", "abs": "https://arxiv.org/abs/2601.10904", "authors": ["Fran\u00e7ois Chollet", "Mike Knoop", "Gregory Kamradt", "Bryan Landers"], "title": "ARC Prize 2025: Technical Report", "comment": null, "summary": "The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u68b3\u7406\u4e86ARC-AGI-2\u5927\u8d5b\u4e0e\u524d\u6cbf\u5b9e\u9a8c\u5ba4\u65b9\u6cd5\uff0c\u7a81\u51fa\u7ec6\u5316\u5faa\u73af\u673a\u5236\u7684\u5d1b\u8d77\uff0c\u5e76\u6307\u51fa\u5f53\u524dAI\u63a8\u7406\u80fd\u529b\u53d7\u9650\u4e8e\u77e5\u8bc6\u8986\u76d6\u4e0e\u57fa\u51c6\u6c61\u67d3\uff0c\u540c\u65f6\u9884\u544a\u4e86\u5f15\u5165\u4ea4\u4e92\u63a8\u7406\u4efb\u52a1\u7684ARC-AGI-3\u3002", "motivation": "ARC-AGI-2\u5f15\u5165\u4e86\u66f4\u9ad8\u590d\u6742\u5ea6\u7684\u4efb\u52a1\uff0c\u4e14\u4f5c\u4e3a\u8861\u91cfAI\u5c11\u6837\u672c\u6cdb\u5316\u4e0e\u62bd\u8c61\u63a8\u7406\u80fd\u529b\u7684\u91cd\u8981\u6807\u51c6\uff0c\u5907\u53d7\u5b66\u672f\u4e0e\u5de5\u4e1a\u754c\u5173\u6ce8\u3002\u968f\u7740\u5168\u7403\u7ade\u8d5b\u548c\u53c2\u4e0e\u7814\u7a76\u8005\u6fc0\u589e\uff0c\u7406\u89e3\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\u3001\u6280\u672f\u74f6\u9888\u53ca\u672a\u6765\u53d1\u5c55\u65b9\u5411\u6781\u5177\u4ef7\u503c\u3002", "method": "\u8c03\u7814\u5e76\u7efc\u8ff0\u5728ARC-AGI-2\u57fa\u51c6\u4e0a\u7684\u6700\u4f18\u65b9\u6cd5\uff0c\u91cd\u70b9\u5206\u6790\u7ec6\u5316\u5faa\u73af\uff08refinement loop\uff09\u7684\u521b\u65b0\uff0c\u5305\u62ec\u8fdb\u5316\u5f0f\u7a0b\u5e8f\u7efc\u5408\u548cAI\u7cfb\u7edf\u5e94\u7528\u5c42\u7ec6\u5316\uff0c\u4ee5\u53ca\u65b0\u578b\u96f6\u9884\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff1b\u540c\u65f6\u8bc4\u4f30\u524d\u6cbfAI\u5b9e\u9a8c\u5ba4\u516c\u5f00\u8868\u73b0\uff0c\u5e76\u5c55\u671b\u4e0b\u4e00\u7248ARC-AGI-3\u3002", "result": "\u5728Kaggle\u7ade\u8d5b\u4e2d\u6700\u4f73\u6210\u7ee9\u4e3a\u79c1\u6709\u6d4b\u8bd5\u96c624%\uff0c\u8fed\u4ee3\u7ec6\u5316\u5faa\u73af\u6210\u4e3a\u4e3b\u6d41\u521b\u65b0\uff0c\u51fa\u73b0\u4e86\u5c0f\u89c4\u6a21\uff08700\u4e07\u53c2\u6570\uff09\u4e14\u65e0\u9700\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u6a21\u578b\u5728\u4efb\u52a1\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u80fd\u3002\u4ea7\u4e1a\u754c\u56db\u5927\u524d\u6cbf\u5b9e\u9a8c\u5ba4\u5c06ARC-AGI\u4f5c\u4e3a\u516c\u5f00\u6807\u51c6\u3002\u5206\u6790\u663e\u793a\u4ecd\u5b58\u5728\u4ee5\u77e5\u8bc6\u8986\u76d6\u4e3a\u6838\u5fc3\u7684\u6027\u80fd\u9650\u5236\u4e0e\u57fa\u51c6\u6c61\u67d3\u98ce\u9669\u3002", "conclusion": "ARC-AGI\u5df2\u6210\u4e3aAI\u6cdb\u5316\u4e0e\u63a8\u7406\u7684\u884c\u4e1a\u6807\u51c6\uff0c\u7ec6\u5316\u5faa\u73af\u548c\u96f6\u9884\u8bad\u7ec3\u5c0f\u6a21\u578b\u7b49\u521b\u65b0\u5e26\u6765\u65b0\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u53d7\u77e5\u8bc6\u8303\u56f4\u9650\u5236\uff0c\u57fa\u51c6\u53ef\u4fe1\u5ea6\u53d7\u6311\u6218\u3002\u540e\u7eed\u901a\u8fc7\u5f15\u5165\u4ea4\u4e92\u3001\u89c4\u5212\u4e0e\u8bb0\u5fc6\u7b49\u80fd\u529b\uff0c\u6216\u5c06\u63a8\u52a8AI\u63a8\u7406\u7684\u8fdb\u4e00\u6b65\u7a81\u7834\u3002"}}
{"id": "2601.10922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10922", "abs": "https://arxiv.org/abs/2601.10922", "authors": ["Yosub Shin", "Michael Buriek", "Boris Sobolev", "Pavel Bushuyeu", "Vikas Kumar", "Haoyang Xu", "Samuel Watson", "Igor Molybog"], "title": "What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge", "comment": null, "summary": "We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.", "AI": {"tldr": "\u672c\u8bba\u6587\u5728\u56fa\u5b9a\u6a21\u578b\u548c\u8bad\u7ec3\u534f\u8bae\u4e0b\uff0c\u53d1\u73b0\u57fa\u4e8e\u96be\u5ea6\u7684\u6837\u672c\u9009\u62e9\u6700\u80fd\u63d0\u5347\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u6027\u80fd\uff0c\u6269\u5c55\u6570\u636e\u96c6\u89c4\u6a21\u4ec5\u964d\u4f4e\u7ed3\u679c\u6ce2\u52a8\uff0c\u591a\u6837\u6027\u4e0e\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u65e0\u76ca\u751a\u81f3\u6709\u5bb3\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u5728\u56fa\u5b9a\u6a21\u578b\u8bad\u7ec3\u534f\u8bae\u4e0b\uff0c\u6570\u636e\u9009\u62e9\u548c\u7b56\u5212\u5982\u4f55\u5f71\u54cd\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7NeurIPS 2025 DCVLR\u6311\u6218\uff0c\u4f7f\u7528\u7cbe\u5fc3\u7b56\u5212\u7684\u7d27\u51d1\u578b\u6570\u636e\u96c6\u5e76\u7ed3\u5408\u591a\u7ec4\u6d88\u878d\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e0d\u540c\u6570\u636e\u7b56\u5212\u7b56\u7565\uff08\u96be\u5ea6\u9009\u62e9\u3001\u89c4\u6a21\u6269\u5c55\u3001\u591a\u6837\u6027\u548c\u5408\u6210\u589e\u5f3a\uff09\u5bf9\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u7684\u5f71\u54cd\u3002", "result": "\u96be\u5ea6\u9a71\u52a8\u7684\u6837\u672c\u9009\u62e9\u662f\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u3002\u6269\u5c55\u6570\u636e\u96c6\u89c4\u6a21\u4e0d\u4e00\u5b9a\u63d0\u5347\u5747\u503c\u51c6\u786e\u7387\uff0c\u4e3b\u8981\u4f5c\u7528\u662f\u964d\u4f4e\u8bad\u7ec3\u7ed3\u679c\u7684\u6ce2\u52a8\u6027\u3002\u591a\u6837\u6027\u548c\u5408\u6210\u6570\u636e\u589e\u5f3a\u672a\u63d0\u5347\uff0c\u751a\u81f3\u53ef\u80fd\u524a\u5f31\u6a21\u578b\u8868\u73b0\u3002", "conclusion": "\u5728\u56fa\u5b9a\u6a21\u578b\u548c\u8bad\u7ec3\u534f\u8bae\u4e0b\uff0c\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u7684\u6570\u636e\u96c6\u9009\u62e9\u5177\u6709\u51b3\u5b9a\u6027\u4f5c\u7528\u3002\u57fa\u4e8e\u96be\u5ea6\u7684\u6837\u672c\u9009\u62e9\u5728\u63d0\u9ad8\u6027\u80fd\u4e0a\u8d21\u732e\u6700\u5927\uff0c\u800c\u589e\u52a0\u6570\u636e\u96c6\u89c4\u6a21\u4e3b\u8981\u662f\u964d\u4f4e\u6ce2\u52a8\u6027\uff0c\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u6709\u9650\u3002\u591a\u6837\u6027\u4e0e\u5408\u6210\u589e\u5f3a\u65b9\u6cd5\u672a\u5e26\u6765\u9884\u671f\u7684\u76ca\u5904\u3002"}}
{"id": "2601.11147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11147", "abs": "https://arxiv.org/abs/2601.11147", "authors": ["Zixu Wang", "Bingbing Xu", "Yige Yuan", "Huawei Shen", "Xueqi Cheng"], "title": "Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems", "comment": "17 pages, 4 figures, 3 tables", "summary": "Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \\textbf{SCALE}, which means \\underline{\\textbf{S}}elf prediction of the optimizer with few shot \\underline{\\textbf{CAL}}ibration for \\underline{\\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \\textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\\%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u6784\u5efa\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4efb\u52a1\u7ea7\u522b\u751f\u6210\u5c11\u91cf\u6700\u4f73\u5de5\u4f5c\u6d41\uff0c\u5e76\u7ed3\u5408\u81ea\u6211\u9884\u6d4b\u548c\u5c0f\u6837\u672c\u6821\u51c6\u66ff\u4ee3\u5168\u91cf\u9a8c\u8bc1\u6267\u884c\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684MAS\u7684\u8ba1\u7b97\u4e0e\u8d44\u6e90\u6210\u672c\uff0c\u4e14\u51e0\u4e4e\u4e0d\u635f\u5931\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4efb\u52a1\u3001\u67e5\u8be2\u7ea7\u522b\u751f\u6210\u5de5\u4f5c\u6d41\uff0c\u4f46\u5dee\u5f02\u4e0e\u6210\u672c\u672a\u88ab\u7cfb\u7edf\u8861\u91cf\uff0c\u5c24\u5176\u5728token\u6d88\u8017\u4e0e\u6267\u884c\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u8d44\u6e90\u74f6\u9888\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u5347\u6548\u7387\uff0c\u964d\u4f4e\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faSCALE\u751f\u6210\u6846\u67b6\uff0c\u81ea\u6211\u9884\u6d4b\u4efb\u52a1\u7ea7\u4f18\u5316\u7ed3\u679c\uff0c\u5e76\u5229\u7528\u5c0f\u6837\u672c\u6821\u51c6\u5b8c\u6210\u8bc4\u4f30\uff0c\u65e0\u9700\u8017\u65f6\u8017\u8d44\u6e90\u7684\u9010\u6761\u6267\u884c\u9a8c\u8bc1\uff1b\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4token\u6d88\u8017\u4e0e\u6027\u80fd\u8868\u73b0\u3002", "result": "SCALE\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5token\u6d88\u8017\u51cf\u5c1183%\uff0c\u6027\u80fd\u4ec5\u4e0b\u964d0.61%\uff0c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "SCALE\u6846\u67b6\u80fd\u591f\u5728\u663e\u8457\u51cf\u5c11token\u6d88\u8017\u7684\u524d\u63d0\u4e0b\uff0c\u7ef4\u6301\u4e0e\u73b0\u6709\u65b9\u6cd5\u51e0\u4e4e\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e73\u5747\u6027\u80fd\u635f\u5931\u4ec50.61%\u3002"}}
{"id": "2601.11178", "categories": ["cs.AI", "cs.CL", "cs.MM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11178", "abs": "https://arxiv.org/abs/2601.11178", "authors": ["Girish A. Koushik", "Helen Treharne", "Diptesh Kanojia"], "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech", "comment": "Under review at ICWSM 2026", "summary": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.11286", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11286", "abs": "https://arxiv.org/abs/2601.11286", "authors": ["Weihong Qi", "Fan Huang", "Rasika Muralidharan", "Jisun An", "Haewoon Kwak"], "title": "XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making", "comment": null, "summary": "We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.", "AI": {"tldr": "XChoice\u6846\u67b6\u80fd\u4ee5\u53ef\u89e3\u91ca\u65b9\u5f0f\u91cf\u5316AI\u4e0e\u4eba\u7c7b\u5728\u590d\u6742\u51b3\u7b56\u4e2d\u7684\u673a\u5236\u6027\u5bf9\u9f50\uff0c\u63ed\u793a\u4e0d\u540c\u4eba\u7fa4\u4e0e\u6d3b\u52a8\u4e0b\u5931\u914d\u70b9\uff0c\u5e76\u652f\u6301\u6709\u9488\u5bf9\u6027\u7684\u6539\u5584\u3002", "motivation": "\u4ee5\u5f80\u7528\u4e8e\u8861\u91cfAI\u4e0e\u4eba\u7c7b\u51b3\u7b56\u4e00\u81f4\u6027\u7684\u6307\u6807\uff08\u5982accuracy\u3001F1\uff09\u4ec5\u5173\u6ce8\u7ed3\u679c\u7684\u4e00\u81f4\u6027\uff0c\u65e0\u6cd5\u63ed\u793a\u673a\u5236\u5c42\u9762\u7684\u5bf9\u9f50\u7ec6\u8282\u3002\u7814\u7a76\u52a8\u673a\u662f\u5f00\u53d1\u66f4\u5177\u89e3\u91ca\u6027\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u6df1\u5165\u7406\u89e3AI\u548c\u4eba\u7c7b\u5728\u53d7\u7ea6\u675f\u51b3\u7b56\u4e2d\u7684\u5bf9\u9f50\u673a\u5236\u3002", "method": "\u63d0\u51faXChoice\u6846\u67b6\uff0c\u901a\u8fc7\u62df\u5408\u673a\u5236\u5316\u51b3\u7b56\u6a21\u578b\u4e8e\u4eba\u7c7b\u6570\u636e\u4e0e\u5927\u6a21\u578b\u751f\u6210\u7684\u51b3\u7b56\uff0c\u63d0\u53d6\u53ef\u89e3\u91ca\u53c2\u6570\u5e76\u5bf9\u6bd4\u8fd9\u4e9b\u53c2\u6570\u5411\u91cf\uff0c\u4ece\u800c\u91cf\u5316\u4e24\u8005\u5728\u51b3\u7b56\u56e0\u7d20\u91cd\u8981\u6027\u3001\u7ea6\u675f\u654f\u611f\u6027\u53ca\u6743\u8861\u504f\u597d\u7b49\u65b9\u9762\u7684\u5bf9\u9f50\u3002", "result": "\u5728\u7f8e\u56fd\u65f6\u95f4\u4f7f\u7528\u8c03\u67e5\u6570\u636e\uff08ATUS\uff09\u4e0a\u6d4b\u8bd5\u8868\u660e\uff0c\u4e0d\u540c\u6a21\u578b\u3001\u6d3b\u52a8\u3001\u5b50\u7fa4\u4f53\u95f4\u5b58\u5728\u663e\u8457\u4e14\u5f02\u8d28\u5316\u7684\u5bf9\u9f50\u6c34\u5e73\uff0c\u4e14\u5728\u9ed1\u4eba\u548c\u5df2\u5a5a\u7fa4\u4f53\u4e2d\u53d1\u73b0\u660e\u663e\u5931\u914d\u3002\u901a\u8fc7\u4e0d\u53d8\u6027\u5206\u6790\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u7528RAG\u5e72\u9884\u8bc4\u4f30\u4e86\u5b9a\u5411\u7f13\u89e3\u6548\u679c\u3002", "conclusion": "XChoice\u80fd\u63d0\u4f9b\u673a\u5236\u5c42\u9762\u5bf9\u9f50\u7684\u8bca\u65ad\u548c\u89e3\u91ca\uff0c\u6709\u52a9\u4e8e\u9488\u5bf9\u6027\u5730\u6539\u8fdbAI\u6a21\u578b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u505c\u7559\u5728\u7ed3\u679c\u7edf\u8ba1\u7684\u4e00\u81f4\u6027\u5c42\u9762\u3002"}}
{"id": "2601.11389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11389", "abs": "https://arxiv.org/abs/2601.11389", "authors": ["Hedieh Haddad", "Thibault Falque", "Pierre Talbot", "Pascal Bouvry"], "title": "Hyperparameter Optimization of Constraint Programming Solvers", "comment": "28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization", "summary": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.\n  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.\n  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\uff08probe and solve\u7b97\u6cd5\uff09\uff0c\u80fd\u5728\u6709\u9650\u65f6\u95f4\u5185\u5e2e\u52a9\u7ea6\u675f\u89c4\u5212\u6c42\u89e3\u5668\u81ea\u52a8\u9009\u62e9\u66f4\u4f18\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u4ece\u800c\u63d0\u9ad8\u6c42\u89e3\u6027\u80fd\u3002", "motivation": "\u7ea6\u675f\u89c4\u5212\u6c42\u89e3\u5668\u6027\u80fd\u6781\u4f9d\u8d56\u5176\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u800c\u624b\u52a8\u8c03\u4f18\u590d\u6742\u4e14\u8017\u65f6\u3002\u8feb\u5207\u9700\u8981\u81ea\u52a8\u5316\u3001\u65e0\u9700\u4eba\u5de5\u7ecf\u9a8c\u7684\u8c03\u53c2\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u65f6\u95f4\u8d44\u6e90\u6709\u9650\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002", "method": "\u8be5\u65b9\u6cd5\u5206\u4e3a\u63a2\u6d4b\uff08probe\uff09\u548c\u6c42\u89e3\uff08solve\uff09\u4e24\u4e2a\u9636\u6bb5\u3002\u5148\u5229\u7528\u53ef\u914d\u7f6e\u7684\u8d85\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\uff08\u5982\u8d1d\u53f6\u65af\u4f18\u5316\u4e0eHamming\u8ddd\u79bb\u641c\u7d22\uff09\u5728\u9650\u5b9a\u65f6\u95f4\u5185\u8fdb\u884c\u53c2\u6570\u63a2\u7d22\uff0c\u518d\u7528\u627e\u5230\u7684\u6700\u4f18\u914d\u7f6e\uff0c\u5728\u5269\u4f59\u65f6\u95f4\u5185\u8fdb\u884c\u5b9e\u9645\u95ee\u9898\u6c42\u89e3\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8d1d\u53f6\u65af\u4f18\u5316\u5728ACE\u6c42\u89e3\u5668\u4e0a25.4%\u7684\u5b9e\u4f8b\u83b7\u5f97\u66f4\u4f18\u89e3\uff0c57.9%\u4e0e\u9ed8\u8ba4\u6301\u5e73\uff1b\u5728Choco\u4e0a38.6%\u5b9e\u4f8b\u8868\u73b0\u66f4\u4f73\uff0c\u4e14\u6574\u4f53\u4f18\u4e8eHamming\u8ddd\u79bb\u641c\u7d22\u3002\u8bc1\u660e\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u63a2\u7d22\u7b56\u7565\u5728\u6c42\u89e3\u5668\u8d85\u53c2\u6570\u4f18\u5316\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "probe and solve\u7b97\u6cd5\u901a\u8fc7\u5728\u4e24\u4e2a\u4e3b\u6d41\u6c42\u89e3\u5668\uff08ACE\u548cChoco\uff09\u4e0a\u7684\u5b9e\u9a8c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u90e8\u5206\u5b9e\u4f8b\u7684\u89e3\u8d28\u91cf\uff0c\u5e76\u8868\u73b0\u51fa\u5bf9\u9ed8\u8ba4\u914d\u7f6e\u548c\u4f20\u7edf\u641c\u7d20\u7b56\u7565\u7684\u660e\u663e\u4f18\u52bf\uff0c\u8868\u660e\u5176\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u901a\u7528\u7684\u6c42\u89e3\u5668\u8c03\u4f18\u65b9\u6cd5\u3002"}}
{"id": "2601.11468", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11468", "abs": "https://arxiv.org/abs/2601.11468", "authors": ["Alessandro Padella", "Massimiliano de Leoni", "Marlon Dumas"], "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs", "comment": "19 pages, 4 figure, TMIS journal submission", "summary": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\u6846\u67b6\uff0c\u4e0d\u4ec5\u9884\u6d4b\u603b\u8017\u65f6\uff0c\u8fd8\u7efc\u5408\u8bc4\u4f30\u5176\u5728\u591a\u79cd\u5173\u952e\u7ee9\u6548\u6307\u6807\uff08KPI\uff09\u4e0a\u7684\u8868\u73b0\u3002\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6570\u636e\u7a00\u7f3a\uff08\u4ec5100\u6761\u8f68\u8ff9\uff09\u60c5\u51b5\u4e0b\uff0cLLM\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u77e5\u8bc6\u4e0e\u8bad\u7ec3\u6570\u636e\u76f8\u5173\u6027\u8fdb\u884c\u63a8\u7406\u3002\u7814\u7a76\u8fd8\u53d1\u73b0LLM\u5177\u5907\u66f4\u590d\u6742\u7684\u63a8\u7406\u80fd\u529b\uff0c\u800c\u975e\u7b80\u5355\u5957\u7528\u4f20\u7edf\u9884\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\u65b9\u6cd5\u9010\u6e10\u91c7\u7528\u673a\u5668\u5b66\u4e60\u4e0e\u6df1\u5ea6\u5b66\u4e60\uff0c\u4f46\u5bf9\u5176\u6cdb\u5316\u80fd\u529b\u3001\u8bed\u4e49\u7406\u89e3\u548c\u63a8\u7406\u673a\u5236\u7684\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76LLM\u80fd\u5426\u901a\u8fc7\u66f4\u590d\u6742\u7684\u63a8\u7406\u548c\u8bed\u4e49\u5229\u7528\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u63d0\u5347\u591a\u7ef4\u6d41\u7a0b\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u539f\u6709\u7684LLM\u6846\u67b6\uff0c\u4e0d\u518d\u4ec5\u9650\u4e8e\u603b\u65f6\u95f4\u9884\u6d4b\uff0c\u65b0\u589e\u5bf9\u591a\u79cd\u5173\u952e\u7ee9\u6548\u6307\u6807\uff08\u5982\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\uff09\u7684\u8bc4\u4f30\u3002\u5b9e\u8bc1\u8bc4\u4f30\u57fa\u4e8e\u4e09\u4e2a\u4e0d\u540c\u7684\u4e8b\u4ef6\u65e5\u5fd7\uff0c\u5e76\u5728\u603b\u65f6\u95f4\u548c\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u4e24\u9879KPI\u4e0a\u4e0e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u540c\u65f6\u6df1\u5165\u7814\u7a76LLM\u63a8\u7406\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u4ec5\u6709100\u6761\u8f68\u8ff9\u7684\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\uff0cLLM\u5728\u603b\u65f6\u95f4\u548c\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u4e24\u4e2a\u5173\u952e\u7ee9\u6548\u6307\u6807\u4e0a\u660e\u663e\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6709\u6548\u5229\u7528\u8bad\u7ec3\u6570\u636e\u7684\u5185\u5728\u7ed3\u6784\u548c\u6a21\u578b\u77e5\u8bc6\uff0c\u5c55\u73b0\u51fa\u590d\u6742\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "conclusion": "LLM\u5728\u6570\u636e\u91cf\u6709\u9650\u7684\u6d41\u7a0b\u76d1\u63a7\u4efb\u52a1\u4e2d\uff0c\u80fd\u591f\u9ad8\u6548\u5229\u7528\u5185\u5728\u77e5\u8bc6\u548c\u8bad\u7ec3\u6570\u636e\u5173\u8054\uff0c\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5177\u5907\u66f4\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u5177\u6cdb\u5316\u6027\u4e0e\u667a\u80fd\u6027\u7684\u65b9\u6848\u3002"}}
{"id": "2601.11479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11479", "abs": "https://arxiv.org/abs/2601.11479", "authors": ["Yohai Trabelsi", "Guojun Xiong", "Fentabil Getnet", "St\u00e9phane Verguet", "Milind Tambe"], "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning", "comment": null, "summary": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.", "AI": {"tldr": "\u63d0\u51faLEG\u6df7\u5408\u6846\u67b6\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u4e13\u5bb6\u610f\u89c1\u81ea\u7136\u8bed\u8a00\u8f6c\u5316\u8fdb\u4f18\u5316\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u536b\u751f\u8bbe\u65bd\u5347\u7ea7\u4f18\u5148\u6392\u5e8f\u7684\u9ad8\u8986\u76d6\u7387\u548c\u4e13\u5bb6\u6307\u5bfc\u878d\u5408\uff0c\u5728\u57c3\u585e\u4fc4\u6bd4\u4e9a\u5b9e\u8bc1\u6548\u679c\u826f\u597d\u3002", "motivation": "\u8d44\u6e90\u6709\u9650\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u5728\u519c\u6751\u536b\u751f\u670d\u52a1\u5347\u7ea7\u4e2d\u517c\u987e\u7406\u8bba\u6700\u4f18\u548c\u4e13\u5bb6/\u5229\u76ca\u76f8\u5173\u65b9\u591a\u5143\u504f\u597d\uff0c\u63d0\u9ad8\u8986\u76d6\u7387\u4e0e\u51b3\u7b56\u7684\u53ef\u884c\u6027\u3002", "method": "\u6df7\u5408\u4f18\u5316\u6846\u67b6LEG\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6269\u5c55\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u5c06\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u7406\u8bba\u4f18\u5316\u7ed3\u5408\uff0c\u7528\u4e8e\u536b\u751f\u7ad9\u5347\u7ea7\u7684\u4f18\u5148\u7ea7\u6392\u5e8f\u3002", "result": "\u5728\u57c3\u585e\u4fc4\u6bd4\u4e9a\u4e09\u533a\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u80fd\u6709\u6548\u878d\u5408\u4e13\u5bb6\u6307\u5bfc\u548c\u4f18\u5316\u4fdd\u969c\uff0c\u63d0\u9ad8\u670d\u52a1\u8986\u76d6\u7387\uff0c\u5e76\u4e14\u63a8\u8fdb\u66f4\u516c\u5e73\u3001\u6570\u636e\u9a71\u52a8\u7684\u536b\u751f\u7cfb\u7edf\u89c4\u5212\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u517c\u987e\u4e13\u5bb6\u5f15\u5bfc\u4e0e\u7406\u8bba\u4f18\u5316\uff0c\u4e3a\u536b\u751f\u7cfb\u7edf\u89c4\u5212\u63d0\u4f9b\u5177\u5907\u516c\u5e73\u6027\u548c\u5b9e\u9645\u53ef\u64cd\u4f5c\u6027\u7684\u6280\u672f\u652f\u6491\uff0c\u6709\u8f83\u597d\u63a8\u5e7f\u6f5c\u529b\u3002"}}
{"id": "2601.05487", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05487", "abs": "https://arxiv.org/abs/2601.05487", "authors": ["Huanxiang Lin", "Qianyue Wang", "Jinwu Hu", "Bailin Chen", "Qing Du", "Mingkui Tan"], "title": "EvidFuse: Writing-Time Evidence Learning for Consistent Text-Chart Data Reporting", "comment": null, "summary": "Data-driven reports communicate decision-relevant insights by tightly interleaving narrative text with charts grounded in underlying tables. However, current LLM-based systems typically generate narratives and visualizations in staged pipelines, following either a text-first-graph-second or a graph-first-text-second paradigm. These designs often lead to chart-text inconsistency and insight freezing, where the intermediate evidence space becomes fixed and the model can no longer retrieve or construct new visual evidence as the narrative evolves, resulting in shallow and predefined analysis. To address the limitations, we propose \\textbf{EvidFuse}, a training-free multi-agent framework that enables writing-time text-chart interleaved generation for data-driven reports. EvidFuse decouples visualization analysis from long-form drafting via two collaborating components: a \\textbf{Data-Augmented Analysis Agent}, equipped with Exploratory Data Analysis (EDA)-derived knowledge and access to raw tables, and a \\textbf{Real-Time Evidence Construction Writer} that plans an outline and drafts the report while intermittently issuing fine-grained analysis requests. This design allows visual evidence to be constructed and incorporated exactly when the narrative requires it, directly constraining subsequent claims and enabling on-demand expansion of the evidence space. Experiments demonstrate that EvidFuse attains the top rank in both LLM-as-a-judge and human evaluations on chart quality, chart-text alignment, and report-level usefulness.", "AI": {"tldr": "EvidFuse\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u5b9e\u73b0\u5199\u4f5c\u65f6\u7075\u6d3b\u63d2\u5165\u9ad8\u8d28\u91cf\u56fe\u8868\uff0c\u6709\u6548\u63d0\u5347\u62a5\u544a\u7684\u8868\u8fbe\u529b\uff0c\u88ab\u9a8c\u8bc1\u4e3a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\u5728\u751f\u6210\u6570\u636e\u9a71\u52a8\u62a5\u544a\u65f6\uff0c\u6587\u672c\u4e0e\u56fe\u8868\u7684\u751f\u6210\u5f80\u5f80\u5206\u9636\u6bb5\u8fdb\u884c\uff0c\u5bfc\u81f4\u56fe\u8868\u4e0e\u6587\u672c\u4e0d\u4e00\u81f4\u53ca\u89c1\u89e3\u50f5\u5316\uff0c\u5f71\u54cd\u5206\u6790\u6df1\u5ea6\u548c\u7075\u6d3b\u6027\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5b9e\u73b0\u66f4\u7d27\u5bc6\u7684\u6587\u672c-\u56fe\u8868\u534f\u540c\u751f\u6210\u3002", "method": "\u63d0\u51fa\u4e86EvidFuse\uff0c\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4e24\u4e2a\u7ec4\u4ef6\u534f\u4f5c\uff1aData-Augmented Analysis Agent\u8d1f\u8d23\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u5e76\u8bbf\u95ee\u539f\u59cb\u8868\u683c\uff0cReal-Time Evidence Construction Writer\u8d1f\u8d23\u89c4\u5212\u548c\u64b0\u5199\u62a5\u544a\uff0c\u5e76\u5728\u9700\u8981\u65f6\u8bf7\u6c42\u7ec6\u81f4\u5206\u6790\uff0c\u5b9e\u73b0\u5199\u4f5c\u65f6\u7684\u6587\u672c\u4e0e\u56fe\u8868\u4ea4\u66ff\u751f\u6210\u3002", "result": "EvidFuse\u5728\u56fe\u8868\u8d28\u91cf\u3001\u56fe\u8868\u4e0e\u6587\u672c\u4e00\u81f4\u6027\u4ee5\u53ca\u62a5\u544a\u7ea7\u6709\u7528\u6027\u65b9\u9762\uff0c\u5747\u5728LLM\u81ea\u52a8\u8bc4\u4ef7\u548c\u4eba\u5de5\u8bc4\u6d4b\u4e2d\u53d6\u5f97\u6700\u9ad8\u5206\u3002", "conclusion": "EvidFuse\u80fd\u591f\u663e\u8457\u63d0\u5347\u6570\u636e\u9a71\u52a8\u62a5\u544a\u7684\u6587\u672c-\u56fe\u8868\u4e00\u81f4\u6027\u4e0e\u5206\u6790\u6df1\u5ea6\uff0c\u4e3a\u62a5\u544a\u751f\u6210\u8bbe\u5b9a\u4e86\u65b0\u7684\u6807\u51c6\u3002"}}
