<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue](https://arxiv.org/abs/2601.08950)
*Mayank Sharma,Roy Pea,Hari Subramonyam*

Main category: cs.AI

TL;DR: 构建并公开了面向知识建构的教学对话数据集ConvoLearn，微调后模型在教学对话任务中的表现显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在教育应用中存在过度直接给出答案、难以支持对话式和建构主义学习等根本性缺陷，因此需要通过设计具有教育理论支撑的数据集与训练方式，提升其教学有效性。

Method: 数据集采集方面，通过人类教师与模拟学生开展受控的科学对话生成半合成数据集。使用QLoRA技术对Mistral 7B模型进行了微调，并通过31名教师的人工评估进行性能测试。

Result: 该论文提出了一种名为ConvoLearn的数据集，专注于通过知识建构理论提升大语言模型（LLMs）的教学对话能力，具体涵盖六大核心教育维度，并在模拟场景下构建了1250段教与学的对话。通过在此数据集上采用QLoRA进行训练，模型展示出知识建构导向的行为转变。人类教师评估结果显示，微调后的Mistral 7B在表现上优于基础模型和Claude Sonnet 4.5。

Conclusion: 构建ConvoLearn数据集并基于其训练的模型能够有效促进LLMs在教育场景中的知识建构型对话行为，为后续构建建构主义AI导师及其评估提供了新的框架。

Abstract: In educational applications, LLMs exhibit several fundamental pedagogical limitations, such as their tendency to reveal solutions rather than support dialogic learning. We introduce ConvoLearn (https://huggingface.co/datasets/masharma/convolearn ), a dataset grounded in knowledge building theory that operationalizes six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. We construct a semi-synthetic dataset of 1250 tutor-student dialogues (20 turns each) in middle school Earth Science through controlled interactions between human teachers and a simulated student. Using QLoRA, we demonstrate that training on this dataset meaningfully shifts LLM behavior toward knowledge-building strategies. Human evaluation by 31 teachers shows our fine-tuned Mistral 7B (M = 4.10, SD = 1.03) significantly outperforms both its base version (M = 2.59, SD = 1.11) and Claude Sonnet 4.5 (M = 2.87, SD = 1.29) overall. This work establishes a potential framework to guide future development and evaluation of constructivist AI tutors.

</details>


### [2] [The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments](https://arxiv.org/abs/2601.09032)
*Logan Ritchie,Sushant Mehta,Nick Heiner,Mason Yu,Edwin Chen*

Main category: cs.AI

TL;DR: 本文实证评估了前沿大模型在真实电商工作任务上的多步能力，揭示了工具使用、规划、适应性、扎根性与常识推理的能力层级，并发现即使最强模型任务失败率仍高达40%。提出了多样化任务设计方法，分析了失败特点，表明现有模型距离人类水平还有明显差距。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）为基础的智能体快速发展，AI评估方式由单轮回复转向在交互环境中多步任务完成。现实工作场景下模型部署需求推动了对此类模型多层次能力的深入检验。

Method: 在Surge的真实电商强化学习环境中，针对150个工作场景任务，对前沿AI模型进行了经验性评估。分析模型在任务完成过程中的表现，并归纳出agent能力层级。同时采用多样化任务设计并结合领域专家参与，深入失败案例分析。

Result: 即使当前表现最好的模型，在约40%的任务上仍然失败，且这些失败集中在能力层级的相应位置。弱模型主要在工具使用和规划方面有缺陷，强模型则在复杂情境推理和隐含信息理解上失败。详细分析了失败原因及其分布规律。

Conclusion: 尽管前沿模型已能实现多步连贯行为，但在人类水平的实际工作场景任务中仍存在显著能力缺口。本文提出了任务中心的RL环境设计方法，强调整体任务多样性与专家贡献，对agent后续发展具有启示意义。

Abstract: The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formation, (3) adaptability, (4) groundedness, and (5) common-sense reasoning. Even the best-performing models fail approximately 40\% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. We introduce a task-centric design methodology for RL environments that emphasizes diversity and domain expert contributions, provide detailed failure analysis, and discuss implications for agent development. Our findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.

</details>


### [3] [Programming over Thinking: Efficient and Robust Multi-Constraint Planning](https://arxiv.org/abs/2601.09097)
*Derrick Goh Xin Deik,Quanyu Long,Zhengyuan Liu,Nancy F. Chen,Wenya Wang*

Main category: cs.AI

TL;DR: 提出SCOPE框架，通过分离推理与代码执行，在多约束任务中大幅提升准确率并降低成本，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多约束规划存在：1）纯推理法推理链长，容易出错且计算资源消耗高；2）LLM结合代码或求解器虽具备执行力，但灵活性不足，难以适应不同问题。亟需一种兼具灵活性、一致性及高效性的通用规划框架。

Method: 提出SCOPE（Scalable COde Planning Engine）框架，将问题特定的自然语言推理与通用代码执行解耦。通过先用LLM进行逻辑推理，再用算法代码执行约束求解，从而提升一致性和通用性。

Result: SCOPE利用模块化思想实现推理与执行的分离，使求解器可重用、确定、一致。基于GPT-4o在TravelPlanner任务上达到93.1%成功率，比最佳对照方法（CoT）提升61.6%，推理成本降1.4倍，推理时间缩短4.67倍。代码已开源。

Conclusion: SCOPE有效破解了LLM在多约束任务中的一致性及通用性难题，提供了一种可扩展、高效的规划引擎，对多领域复杂任务具较强适应性。

Abstract: Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.

</details>


### [4] [DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model](https://arxiv.org/abs/2601.09100)
*Lixiang Zhang,Chenggong Zhao,Qing Gao,Xiaoke Zhao,Gengyi Bai,Jinhu Lv*

Main category: cs.AI

TL;DR: 提出DScheLLM方法，利用微调大语言模型和双系统（快-慢）推理架构，首次高效解决动态车间调度问题，实验效果优异。


<details>
  <summary>Details</summary>
Motivation: 传统调度方法难以应对制造过程中的动态扰动（如加工时间变化、机器故障、任务插入），适应性和泛化能力有限。

Method: 构建统一的大语言模型框架，基于问题求解器生成的精确调度数据对大模型进行LoRA微调，在快-慢推理模式下分别处理不同规模扰动，实现动态事件下的高效智能调度。

Result: 实验表明，快思模式能高效地产生高质量调度方案，慢思模式生成的决策输入与专业求解器兼容且格式规范。两种模式均显示出适应各类动态扰动的优良能力。

Conclusion: 大语言模型在动态车间调度领域展现出智能、自适应优化的巨大潜力，DScheLLM为工业调度问题提供了新思路。

Abstract: Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.

</details>


### [5] [AviationLMM: A Large Multimodal Foundation Model for Civil Aviation](https://arxiv.org/abs/2601.09105)
*Wenbin Li,Jingling Wu,Xiaoyong Lin. Jing Chen,Cong Chen*

Main category: cs.AI

TL;DR: 论文提出AviationLMM多模态基础模型，重点解决民航AI碎片化、数据异构的问题，推动民航智能化进程。


<details>
  <summary>Details</summary>
Motivation: 现有民航AI系统碎片化、数据割裂，缺乏统一的信息整合与智能推理能力，难以满足实际复杂应用需求。该工作旨在填补AI基础模型与民航需求之间的技术空白。

Method: 构建统一架构，整合空地语音、监控雷达、机载遥测、视频与结构化文本等多模态输入，采用跨模态对齐与融合技术，实现灵活输出。强调场景生成、预训练、隐私、信任与鲁棒性等关键技术环节。

Result: 提出AviationLMM大型多模态基础模型，统合民航多源异构数据，实现语音、雷达、传感、文本等多模态数据融合，为民航安全、效率、客户满意度等提供智能支持。模型可感知多模态输入，并输出情境摘要、风险预警、预测诊断、事故重建等多元结果。

Conclusion: AviationLMM有望成为民航领域多模态数据智能处理的基础工具，促进航空安全与智能化发展，并推动相关基础研究的协同进展。

Abstract: Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.

</details>


### [6] [PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?](https://arxiv.org/abs/2601.09152)
*Yiwen Tu,Xuan Liu,Lianhui Qin,Haojian Jin*

Main category: cs.AI

TL;DR: 本文提出的PRA方法通过模拟和评估个性化隐私推理，有效提升了对用户隐私关注的预测能力，并具有良好的领域迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有隐私关注分析大多停留在群体层面，缺乏对用户个体化隐私推理过程的建模，难以精准反映每个用户对不同隐私情境的真实反应。

Method: 基于个体评论历史和上下文信息，结合隐私认知理论，构建AI-agent模拟个体‘隐私心智’，通过情境过滤触发相关隐私记忆，生成模拟评论。另有基于LLM的评估器，参考权威隐私关注分类法，验证生成推理的可信度。

Result: PRA在Hacker News真实讨论实验中，较基线模型提升了隐私关注预测准确率，并能跨领域迁移隐私推理能力。

Conclusion: PRA能够更准确地预测用户对隐私的关注，并在AI、电商及医疗领域展现出可迁移的隐私推理模式。

Abstract: This paper introduces PRA, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PRA integrates privacy and cognitive theories to simulate user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user's "privacy mind", dynamically activates relevant privacy memory through a contextual filter that emulates bounded rationality, and generates synthetic comments reflecting how that user would likely respond to new privacy scenarios. A complementary LLM-as-a-Judge evaluator, calibrated against an established privacy concern taxonomy, quantifies the faithfulness of generated reasoning. Experiments on real-world Hacker News discussions show that \PRA outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.

</details>


### [7] [Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback](https://arxiv.org/abs/2601.09182)
*JungMin Yun,JuneHyoung Kwon,MiHyeon Kim,YoungBin Kim*

Main category: cs.AI

TL;DR: 论文批评了当前LLM自动生成评审的方案，提出应以LLM辅助和培训人类审稿人为核心，通过设计审稿人导师和反馈系统，提高评审质量，实现学术生态的可持续发展。


<details>
  <summary>Details</summary>
Motivation: AI研究领域的迅猛发展加剧了审稿人缺口，威胁同行评议的可持续性，并导致评审质量下滑，亟需新的解决方案。

Method: 分析现有LLM自动生成评审的不足，提出以高质量评审标准为基础，设计LLM辅助的审稿人培训与反馈系统。

Result: 提出LLM辅助的导师系统和反馈系统，分别用于提升审稿人的长期能力和实时优化审稿质量，为更加可持续的学术生态系统提供了新路径。

Conclusion: 论文提出应以大语言模型（LLM）辅助和培训人类审稿人为核心，提升审稿质量与生态可持续性。

Abstract: The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. We define the core principles of high-quality peer review and propose two complementary systems grounded in these foundations: (i) an LLM-assisted mentoring system that cultivates reviewers' long-term competencies, and (ii) an LLM-assisted feedback system that helps reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.

</details>


### [8] [Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models](https://arxiv.org/abs/2601.09260)
*Yan Liu,Feng Zhang,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Han Liu,Yangdong Deng*

Main category: cs.AI

TL;DR: CoT-Flow将链式思考变为概率流，以高效且高性能地提升大语言模型推理表现。


<details>
  <summary>Details</summary>
Motivation: 现有链式思考方法将推理过程视为不可分割的整体，无法度量各步骤对结果的具体贡献，导致推理效率低、优化难度大。论文旨在克服这些细粒度信息不足的问题。

Method: 该工作提出了CoT-Flow框架，将推理过程各步骤视为概率流。基于此，分别设计了流引导解码（greedy flow-based decoding）以生成信息高效的推理路径，以及流强化学习以构建无需外部验证器的奖励函数。

Result: CoT-Flow框架通过将离散推理步骤概念化为连续概率流，定量衡量每一步对最终答案的贡献，从而优化大模型的推理能力。实验显示该方法在推理效率和性能之间达到了更优平衡。

Conclusion: 通过对推理过程的细粒度信息度量和优化，CoT-Flow实现了推理效率与推理性能的提升，且无需额外监督或外部验证器。

Abstract: High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify step-wise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, we propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.

</details>


### [9] [Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants](https://arxiv.org/abs/2601.09264)
*Ziyi Shi,Xusen Guo,Hongliang Lu,Mingxing Peng,Haotian Wang,Zheng Zhu,Zhenning Li,Yuxuan Liang,Xinhu Zheng,Hai Yang*

Main category: cs.AI

TL;DR: 作者提出了基于大型语言模型（LLM）的多智能体政策制定框架，实现跨行政区疫情管理协同。在美国COVID-19数据实证中，方法有效降低感染和死亡数，验证了其疫情管控优势。


<details>
  <summary>Details</summary>
Motivation: 传统疫情防控中，不同行政区之间的政策常常各自为战、事后调整，缺乏前瞻性和区域协同，难以实现高效控制疫情蔓延。该文章旨在解决跨区域政策协同和主动干预这一核心难题。

Method: 为每个行政区分配一个LLM智能体，结合本区疫情演化、跨区通讯、真实流动与政策数据，通过疫情模拟器和闭环仿真，智能体间协作探索干预方案并共识协调政策；用2020年美国COVID-19真实数据进行效能验证。

Result: 在美国州级COVID-19真实数据测试下，该框架可将单州累计感染数和死亡数降幅最高达63.7%和40.1%；跨州总降幅分别达39.0%和27.0%。显示该方法在疫情协同管控中的显著效果。

Conclusion: 研究证明，基于LLM的多智能体系统能有效实现跨区域疫情政策的协调与优化，显著提升疫情防控效果。为未来应对类似公共卫生危机提供了智能化、协同化的新范式。

Abstract: Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions. Within our framework, each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, our framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking...

</details>


### [10] [RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering](https://arxiv.org/abs/2601.09269)
*Wencheng Ye,Liang Peng,Xiaoyang Yuan,Yi Bin,Pengpeng Zeng,Hengyu Jin,Heng Tao Shen*

Main category: cs.AI

TL;DR: 作者提出RISER，一种无需参数更新、可插拔的推理增强框架，通过路由机制动态组合推理向量，实现高效、可解释、精确的大模型推理控制，在多项任务中有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在领域特定推理任务中通常依赖训练密集型的参数更新方法，虽然激活操控（activation steering）作为一种高效替代方案出现，但目前方法手动干预且静态，无法适应复杂推理的动态性。

Method: RISER构建推理向量库，利用轻量级路由器根据每个输入动态组合与激活向量，通过任务级别奖励强化学习优化路由器，以实现可组合性和自适应性的推理激活。

Result: RISER在七项不同基准测试中平均提升零样本推理准确率3.4%-6.5%，超过CoT（Chain-of-Thought）推理，同时具有2-3倍的token效率和更稳健的准确率提升。

Conclusion: RISER能够自适应地组合和激活多个可解释的推理向量，形成精确的控制策略，提升了大语言模型推理的可控性和效率，拓展了参数高效推理的应用前景。

Abstract: Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4-6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2-3x higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.

</details>


### [11] [$A^3$-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation](https://arxiv.org/abs/2601.09274)
*Jian Zhang,Yu He,Zhiyuan Wang,Zhangqi Wang,Kai He,Fangzhi Xu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: A^3-Bench是聚焦双尺度记忆激活的科学推理基准，利用锚点和吸引子机制对模型进行科学推理能力评测，并引入AAUI指标量化记忆利用，实验验证了记忆激活对推理表现的重要影响。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅关注最终答案或推理连贯性，忽视了人类推理中记忆激活与再利用的关键机制。该机制有助于提升推理一致性和稳定性，作者希望通过新的评测框架揭示并度量这一过程。

Method: 提出了A^3-Bench基准，通过锚点（Anchor）和吸引子（Attractor）的记忆激活机制，评估科学推理中的记忆驱动过程。采用SAPM流程系统性注释跨领域2,198道科学推理题，并设计了AAUI（锚点-吸引子利用指数）指标，以量化记忆激活率。实验对比不同模型及范式下的表现。

Result: 构建了A^3-Bench，并在各类基座模型和推理范式上，实证验证了记忆激活（锚点与吸引子利用）与推理表现的相关性；AAUI指标清晰反映了模型在推理过程中记忆激活能力的差异。

Conclusion: A^3-Bench有效弥补了现有基准在记忆驱动机制评测方面的不足，为研究模型推理中的记忆动力学提供了工具和新视角，未来可用于进一步推动模型在科学推理与知识再利用能力上的提升。

Abstract: Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the \textit{memory-driven} mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose $A^3$-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate $A^3$-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.

</details>


### [12] [M$^3$Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning](https://arxiv.org/abs/2601.09278)
*Xiaohan Yu,Chao Feng,Lang Mei,Chong Chen*

Main category: cs.AI

TL;DR: 该文提出了解决多模态信息检索智能体泛化及数据稀缺问题的新模型M$^3$Searcher，并构建数据集。方法在多模态复杂任务中效果优异。


<details>
  <summary>Details</summary>
Motivation: 现有DeepResearch风格的智能体在自动信息获取和合成方面表现出色，但仅限于文本模态，对于扩展到多模态环境面临着模态工具泛化和复杂多模态检索路径数据稀缺两大挑战。

Method: 提出M$^3$Searcher智能体，通过将信息获取与答案推导解耦，采用面向检索的多目标奖励优化，并开发了多模态多跳数据集MMSearchVQA用于强化学习训练。

Result: M$^3$Searcher在实验中优于现有方法，在复杂多模态任务上展现了较强的迁移适应性和推理能力。

Conclusion: 通过模块化设计和多目标奖励优化，M$^3$Searcher能更好地兼顾事实准确性、推理合理性和检索能力，适合复杂多模态搜索任务。

Abstract: Recent advances in DeepResearch-style agents have demonstrated strong capabilities in autonomous information acquisition and synthesize from real-world web environments. However, existing approaches remain fundamentally limited to text modality. Extending autonomous information-seeking agents to multimodal settings introduces critical challenges: the specialization-generalization trade-off that emerges when training models for multimodal tool-use at scale, and the severe scarcity of training data capturing complex, multi-step multimodal search trajectories. To address these challenges, we propose M$^3$Searcher, a modular multimodal information-seeking agent that explicitly decouples information acquisition from answer derivation. M$^3$Searcher is optimized with a retrieval-oriented multi-objective reward that jointly encourages factual accuracy, reasoning soundness, and retrieval fidelity. In addition, we develop MMSearchVQA, a multimodal multi-hop dataset to support retrieval centric RL training. Experimental results demonstrate that M$^3$Searcher outperforms existing approaches, exhibits strong transfer adaptability and effective reasoning in complex multimodal tasks.

</details>


### [13] [STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models](https://arxiv.org/abs/2601.09281)
*Jingjing Zhou,Gaoxiang Cong,Li Su,Liang Li*

Main category: cs.AI

TL;DR: 本文关注于大型推理模型（LRMs）在生成复杂推理链时引发的敏感信息泄露风险，并提出了无需参数调整、推理时就能实施的敏感轨迹调控（STaR）方法，能在推理全流程保护隐私。


<details>
  <summary>Details</summary>
Motivation: 现有大模型的“遗忘”方法主要只针对最终答案，忽略了推理链中间过程的隐藏敏感泄露，导致不能真正保护隐私，需构建能全链路感知和消除敏感内容的新机制。

Method: 方法包括四步：1）通过语义感知检测定位敏感内容；2）用安全前缀提示注入整体约束；3）在推理链各阶段动态阻断敏感信息输出；4）用自适应分词过滤防止复现与变体泄露。同时提出MCS与MIA两项新的评估指标。

Result: 在R-TOFU数据集实验显示，STaR显著提升了包括中间步骤在内的全链路敏感信息删除的一致性和安全性，并以很小的性能损失达成更完整的隐私保护，确立了领域新标准。

Conclusion: STaR方法实现了对中间推理步骤的敏感内容全程抑制，解决了仅去除最终答案敏感信息导致的隐私泄露与安全隐患，在R-TOFU基准上证明能以极低的效用损失实现稳定、高效的隐私保护。

Abstract: Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.

</details>


### [14] [Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing](https://arxiv.org/abs/2601.09282)
*Leszek Sliwko,Jolanta Mizeria-Pietraszko*

Main category: cs.AI

TL;DR: 提出了一种基于自然语言、意图驱动的集群调度方法，通过LLM解析用户软偏好提示，实现了更便捷且准确的调度配置，并取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有集群工作负载分配需要复杂配置，用户体验和可用性存在明显不足。

Method: 设计并实现了一个Kubernetes调度器扩展器，集成LLM（通过AWS Bedrock），解析带有自然语言注释的调度请求，通过集群状态缓存及意图分析器提升性能，并在多个场景下进行定量与定性评估。

Result: 原型系统在LLM解析自然语言分配提示上取得了超过95%的准确率，且在六大调度场景中，大多数情况下优于或等同于标准Kubernetes配置，尤其复杂场景下表现突出。

Conclusion: 使用LLM进行语义软亲和调度可有效提升工作负载编排的易用性，但现阶段同步LLM调用存在延迟，需异步处理以满足生产级需求。

Abstract: Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.

</details>


### [15] [Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments](https://arxiv.org/abs/2601.09382)
*Qinglong Shi,Donghai Wang,Hantao Zhou,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He*

Main category: cs.AI

TL;DR: 本论文提出主动型任务导向智能体，通过新范式与综合评测标准，显著提升长周期任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型智能体仅具备被动响应，对长期意图维护及动态环境适应性不足，亟需突破静态用户需求与动态环境之间的能力瓶颈。

Method: 提出了主动型任务导向智能体的新交互范式，包括基于意图的监控和事件触发的跟进，并通过高质量数据合成管道与新基准ChronosBench对模型进行评估。

Result: 提出的模型在复杂任务（包括用户意图变化）上任务完成率达到85.19%，显著优于现有主流模型，并证明了数据驱动策略的有效性。

Conclusion: 主动型交互和高质量数据生成结合，有效加强了智能体跨越静态用户意图与动态环境的任务执行能力，对长周期智能体交互有重要推动意义。

Abstract: Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity through two key capabilities, (i) Intent-Conditioned Monitoring: The agent autonomously formulates trigger conditions based on dialog history; (ii) Event-Triggered Follow-up: The agent actively engages the user upon detecting useful environmental updates. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria of task-oriented interaction in a dynamic environment by proposing a new benchmark, namely ChronosBench. We evaluated some leading close-source and open-source models at present and revealed their flaws in long-term task-oriented interaction. Furthermore, our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. And the result validated the effectiveness of our data-driven strategy.

</details>


### [16] [Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning](https://arxiv.org/abs/2601.09536)
*Dongjie Cheng,Yongqi Li,Zhixin Ma,Hongru Cai,Yupeng Hu,Wenjie Wang,Liqiang Nie,Wenjie Li*

Main category: cs.AI

TL;DR: 该论文提出了一种统一的生成式多模态推理方法，能够在推理过程中动态生成中间图像，提升多模态任务推理的广泛性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理方法一般采用单一任务模式，难以推广到多变的推理任务，且缺乏对生成推理过程的普适性支持。作者旨在借助生成式机制，实现多样化且统一的多模态推理能力。

Method: 作者提出了Omni-R1框架，包含两阶段SFT+RL训练，结合感知对齐损失和感知奖励以实现功能性图像生成，同时推出Omni-R1-Zero，通过从文本推理数据自举生成视觉步骤，无需多模态标注。

Result: 实证显示，Omni-R1可在多种多模态任务上实现统一的生成式推理，Omni-R1-Zero无需标注却能达到或超过Omni-R1平均性能，验证了方法的有效性与泛化潜能。

Conclusion: Omni-R1和Omni-R1-Zero均能实现统一的多模态生成式推理，Omni-R1-Zero表现甚至可达到或超越Omni-R1，显示了无标注推理的可行性和潜力。

Abstract: Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.

</details>


### [17] [Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning](https://arxiv.org/abs/2601.09667)
*Zhiyuan Hu,Yunhai Hu,Juncheng Liu,Shuyue Stella Li,Yucheng Wang,Zhen Xu,See-Kiong Ng,Anh Tuan Luu,Xinxing Xu,Bryan Hooi,Cynthia Breazeal,Hae Won Park*

Main category: cs.AI

TL;DR: MATTRL在不调整模型参数的情况下，通过结构化经验注入和多专家协作，提升了多智能体系统在多领域推理任务中的表现和稳健性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习训练资源消耗大且稳定性差，主要受队友协同导致的非平稳性，以及稀疏高方差奖励影响，因此亟需一种无需微调且稳健高效的多智能体推理方案。

Method: 提出了MATTRL（Multi-Agent Test-Time Reinforcement Learning）框架，在推理阶段将结构化文本经验注入多智能体协作团队，通过专家团队多轮讨论、检索与整合测试时经验、共识决策，并研究了轮次级经验池的奖励归因方案及其反馈注入。

Result: 在医学、数学和教育等挑战性基准测试中，MATTRL相较多智能体基础线平均准确率提升3.67%、相较单智能体基础线提升8.67%；消融实验验证了不同奖励归因机制对训练结果的影响。

Conclusion: MATTRL框架能够在无需微调的情况下，显著提升多智能体系统在推理任务中的稳健性和准确率。

Abstract: Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\% over a multi-agent baseline, and by 8.67\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [18] [TiInsight: A SQL-based Automated Exploratory Data Analysis System through Large Language Models](https://arxiv.org/abs/2601.09404)
*Jun-Peng Zhu,Boyan Niu,Peng Cai,Zheming Ni,Kai Xu,Jiajun Huang,Shengbo Ma,Bing Wang,Xuan Zhou,Guanglei Bao,Donghui Zhang,Liu Tang,Qi Liu*

Main category: cs.DB

TL;DR: 提出并实现了面向SQL的自动化跨领域数据探索系统TiInsight，具备强大的自然语言交互和数据可视化能力，并已在实际环境中验证。


<details>
  <summary>Details</summary>
Motivation: 现有的SQL数据分析方法缺乏自动化和跨领域分析能力，且对大语言模型在数据探索领域的作用研究不足。

Method: 结合GUI界面、HDC层级数据上下文生成、问题澄清与分解、自然语言转SQL（TiSQL）以及数据可视化（TiChart）构成完整的数据探索流程。

Result: 提出了TiInsight系统，实现了SQL驱动的自动化跨领域数据探索，并已在实际生产环境部署，同时展示了系统在代表性数据集上的能力。

Conclusion: TiInsight能有效提升数据分析的自动化和跨领域能力，推动数据探索从人工向智能转变，适用于生产级应用。

Abstract: The SQL-based exploratory data analysis has garnered significant attention within the data analysis community. The emergence of large language models (LLMs) has facilitated the paradigm shift from manual to automated data exploration. However, existing methods generally lack the ability for cross-domain analysis, and the exploration of LLMs capabilities remains insufficient. This paper presents TiInsight, an SQL-based automated cross-domain exploratory data analysis system. First, TiInsight offers a user-friendly GUI enabling users to explore data using natural language queries. Second, TiInsight offers a robust cross-domain exploratory data analysis pipeline: hierarchical data context (i.e., HDC) generation, question clarification and decomposition, text-to-SQL (i.e., TiSQL), and data visualization (i.e., TiChart). Third, we have implemented and deployed TiInsight in the production environment of PingCAP and demonstrated its capabilities using representative datasets. The demo video is available at https://youtu.be/JzYFyYd-emI.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [19] [SC-MAS: Constructing Cost-Efficient Multi-Agent Systems with Edge-Level Heterogeneous Collaboration](https://arxiv.org/abs/2601.09434)
*Di Zhao,Longhui Ma,Siwei Wang,Miao Wang,Yi Kong*

Main category: cs.MA

TL;DR: SC-MAS通过异构协作实现更优准确率和推理成本，在多数据集验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型的多智能体系统协作模式单一，限制了针对不同任务角色的灵活协作，导致成本高、效率不足。

Method: 提出SC-MAS框架，将多智能体系统（MAS）建模为有向图，边明确表示协作策略；系统通过统一控制器动态分配角色、协作模式与语言模型，支持异构、低成本协作。

Result: SC-MAS在MMLU数据集上准确率提升3.35%，推理成本降低15.38%；在MBPP数据集上准确率提升3.53%，成本降低12.13%。

Conclusion: 异构协作策略显著提升了多智能体系统的性能与性价比，SC-MAS框架为高效构建多智能体系统提供可行方案。

Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) enhance complex problem solving through multi-agent collaboration, but often incur substantially higher costs than single-agent systems. Recent MAS routing methods aim to balance performance and overhead by dynamically selecting agent roles and language models. However, these approaches typically rely on a homogeneous collaboration mode, where all agents follow the same interaction pattern, limiting collaboration flexibility across different roles. Motivated by Social Capital Theory, which emphasizes that different roles benefit from distinct forms of collaboration, we propose SC-MAS, a framework for constructing heterogeneous and cost-efficient multi-agent systems. SC-MAS models MAS as directed graphs, where edges explicitly represent pairwise collaboration strategies, allowing different agent pairs to interact through tailored communication patterns. Given an input query, a unified controller progressively constructs an executable MAS by selecting task-relevant agent roles, assigning edge-level collaboration strategies, and allocating appropriate LLM backbones to individual agents. Experiments on multiple benchmarks demonstrate the effectiveness of SC-MAS. In particular, SC-MAS improves accuracy by 3.35% on MMLU while reducing inference cost by 15.38%, and achieves a 3.53% accuracy gain with a 12.13% cost reduction on MBPP. These results validate the feasibility of SC-MAS and highlight the effectiveness of heterogeneous collaboration in multi-agent systems.

</details>


### [20] [CrowdLLM: Building LLM-Based Digital Populations Augmented with Generative Models](https://arxiv.org/abs/2512.07890)
*Ryan Feng Lin,Keyu Tian,Hanming Zheng,Congjing Zhang,Li Zeng,Shuai Huang*

Main category: cs.MA

TL;DR: 提出融合大语言模型和生成模型的新框架CrowdLLM，能够更精准地模拟真实人群行为，提升数字群体的多样性和代表性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的数字人群无法充分模拟真实人群的多样性和准确性，因此亟需改进方法；提升数字人群质量有助于降低实验成本并规避伦理风险。

Method: 提出了CrowdLLM，将预训练大语言模型（LLM）与生成模型结合以提升数字人群的多样性和准确性。通过理论分析和跨多领域实验，对CrowdLLM的表现进行了评估。

Result: CrowdLLM在众包、投票、用户评分等多个领域的实验中都表现出较高的拟真性和分布上的保真度，相比单一LLM方法更接近真实人群数据分布。

Conclusion: CrowdLLM是一种高质量、可扩展且具代表性的数字人群模拟方案，有望应用于社会模拟、众包、推荐等多个领域，有效降低真实实验中的成本与伦理风险。

Abstract: The emergence of large language models (LLMs) has sparked much interest in creating LLM-based digital populations that can be applied to many applications such as social simulation, crowdsourcing, marketing, and recommendation systems. A digital population can reduce the cost of recruiting human participants and alleviate many concerns related to human subject study. However, research has found that most of the existing works rely solely on LLMs and could not sufficiently capture the accuracy and diversity of a real human population. To address this limitation, we propose CrowdLLM that integrates pretrained LLMs and generative models to enhance the diversity and fidelity of the digital population. We conduct theoretical analysis of CrowdLLM regarding its great potential in creating cost-effective, sufficiently representative, scalable digital populations that can match the quality of a real crowd. Comprehensive experiments are also conducted across multiple domains (e.g., crowdsourcing, voting, user rating) and simulation studies which demonstrate that CrowdLLM achieves promising performance in both accuracy and distributional fidelity to human data.

</details>
