{"id": "2601.11327", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11327", "abs": "https://arxiv.org/abs/2601.11327", "authors": ["Agata \u017bywot", "Xinyi Chen", "Maarten de Rijke"], "title": "Can Small Agent Collaboration Beat a Single Big LLM?", "comment": null, "summary": "This report studies whether small, tool-augmented agents can match or outperform larger monolithic models on the GAIA benchmark. Using Qwen3 models (4B-32B) within an adapted Agentic-Reasoning framework, we isolate the effects of model scale, explicit thinking (no thinking, planner-only, or full), and tool use (search, code, mind-map). Tool augmentation provides the largest and most consistent gains. Using tools, 4B models can outperform 32B models without tool access on GAIA in our experimental setup. In contrast, explicit thinking is highly configuration- and difficulty-dependent: planner-only thinking can improve decomposition and constraint tracking, while unrestricted full thinking often degrades performance by destabilizing tool orchestration, leading to skipped verification steps, excessive tool calls, non-termination, and output-format drift.", "AI": {"tldr": "\u5de5\u5177\u589e\u5f3a\u80fd\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\uff0c\u751a\u81f3\u8d85\u8fc7\u66f4\u5927\u6a21\u578b\uff1b\u663e\u5f0f\u601d\u8003\u9700\u8c28\u614e\u8bbe\u8ba1\uff0c\u5426\u5219\u53ef\u80fd\u53cd\u800c\u635f\u5bb3\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u5c0f\u89c4\u6a21\u3001\u5de5\u5177\u589e\u5f3a\u578b\u667a\u80fd\u4f53\u662f\u5426\u80fd\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5339\u654c\u751a\u81f3\u8d85\u8d8a\u5927\u578b\u4e00\u4f53\u5316\u6a21\u578b\u3002", "method": "\u91c7\u7528Qwen3\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\uff084B-32B\uff09\u5728\u7ecf\u8fc7\u6539\u9020\u7684Agentic-Reasoning\u6846\u67b6\u4e0b\uff0c\u8bbe\u7f6e\u4e0d\u540c\u7684\u601d\u8003\u65b9\u5f0f\uff08\u65e0\u3001\u4ec5\u89c4\u5212\u3001\u5b8c\u5168\u601d\u8003\uff09\u548c\u5de5\u5177\u4f7f\u7528\uff08\u641c\u7d22\u3001\u4ee3\u7801\u3001\u601d\u7ef4\u5bfc\u56fe\uff09\uff0c\u4ee5\u5206\u6790\u5404\u56e0\u7d20\u5bf9GAIA\u57fa\u51c6\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5de5\u5177\u589e\u5f3a\u4e3a\u6a21\u578b\u6027\u80fd\u5e26\u6765\u4e86\u6700\u5927\u4e14\u6700\u7a33\u5b9a\u7684\u63d0\u5347\u3002\u914d\u5907\u5de5\u5177\u7684\u5c0f\u6a21\u578b\uff084B\uff09\u53ef\u4ee5\u5728GAIA\u4efb\u52a1\u4e0a\u8d85\u8fc7\u4e0d\u914d\u5907\u5de5\u5177\u7684\u5927\u6a21\u578b\uff0832B\uff09\u3002\u663e\u5f0f\u601d\u8003\u5bf9\u6027\u80fd\u5f71\u54cd\u9ad8\u5ea6\u4f9d\u8d56\u5177\u4f53\u8bbe\u7f6e\u548c\u4efb\u52a1\u96be\u5ea6\u3002", "conclusion": "\u5de5\u5177\u589e\u5f3a\u662f\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\u7684\u5173\u952e\uff0c\u5c24\u5176\u5728\u5c0f\u6a21\u578b\u4e0a\u8868\u73b0\u7a81\u51fa\u3002\u663e\u5f0f\u601d\u8003\u7684\u8bbe\u8ba1\u9700\u7ed3\u5408\u4efb\u52a1\u914d\u7f6e\uff0c\u5426\u5219\u53ef\u80fd\u5e26\u6765\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2601.10726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10726", "abs": "https://arxiv.org/abs/2601.10726", "authors": ["Ross Chu", "Yuting Huang"], "title": "Building AI Agents to Improve Job Referral Requests to Strangers", "comment": null, "summary": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86AI\u667a\u80fd\u4f53\u81ea\u52a8\u4f18\u5316\u6c42\u804c\u8f6c\u4ecb\u8bf7\u6c42\uff0c\u901a\u8fc7RAG\u589e\u5f3aLLM\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6210\u529f\u7387\uff0c\u6539\u5584\u5f31\u8bf7\u6c42\u4e14\u4e0d\u5f71\u54cd\u5f3a\u8bf7\u6c42\u3002", "motivation": "\u6c42\u804c\u8005\u5728\u5728\u7ebf\u793e\u533a\u53d1\u9001\u7684\u8f6c\u4ecb\u8bf7\u6c42\u666e\u904d\u5b58\u5728\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u5176\u83b7\u5f97\u63a8\u8350\u673a\u4f1a\u3002\u7814\u7a76\u5e0c\u671b\u901a\u8fc7AI\u81ea\u52a8\u63d0\u5347\u8bf7\u6c42\u6587\u672c\u8d28\u91cf\uff0c\u663e\u8457\u63d0\u5347\u5f31\u8bf7\u6c42\u7684\u6210\u529f\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u7c7bAI\u667a\u80fd\u4f53\uff1a\u63d0\u5347\u667a\u80fd\u4f53\uff08\u5bf9\u8bf7\u6c42\u6587\u672c\u8fdb\u884c\u6539\u5199\uff09\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\uff08\u91c7\u7528\u9884\u6d4b\u8f6c\u4ecb\u6982\u7387\u7684\u6a21\u578b\u8bc4\u4f30\u6539\u5199\u6548\u679c\uff09\uff1b\u5e76\u5f15\u5165RAG\u6280\u672f\u4ee5\u589e\u5f3aLLM\u5728\u751f\u6210\u5185\u5bb9\u65f6\u7684\u76f8\u5173\u6027\u548c\u8d28\u91cf\u3002", "result": "\u7ed3\u5408RAG\u7684LLM\u667a\u80fd\u4f53\uff0c\u4f7f\u8f6c\u4ecb\u8bf7\u6c42\u8d28\u91cf\u8f83\u5f31\u8005\u7684\u6210\u529f\u6982\u7387\u63d0\u5347\u4e8614%\uff0c\u4e14\u4e0d\u4f1a\u5bf9\u5f3a\u8bf7\u6c42\u9020\u6210\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u5229\u7528\u7ed3\u5408RAG\u7684LLM\u667a\u80fd\u4f53\u80fd\u591f\u663e\u8457\u63d0\u5347\u6c42\u804c\u8005\u5728\u4e13\u4e1a\u793e\u4ea4\u793e\u533a\u4e2d\u8f6c\u4ecb\u8bf7\u6c42\u7684\u9884\u6d4b\u6210\u529f\u7387\uff0c\u5c24\u5176\u662f\u5bf9\u539f\u672c\u8f83\u5f31\u7684\u8bf7\u6c42\uff0c\u540c\u65f6\u907f\u514d\u5bf9\u5f3a\u8bf7\u6c42\u5e26\u6765\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2601.10738", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10738", "abs": "https://arxiv.org/abs/2601.10738", "authors": ["Percy Jardine"], "title": "CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems", "comment": null, "summary": "Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.", "AI": {"tldr": "\u63d0\u51faCTHA\u67b6\u6784\uff0c\u901a\u8fc7\u4e09\u7c7b\u7ea6\u675f\u6062\u590d\u548c\u589e\u5f3a\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u4e0e\u6269\u5c55\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u4efb\u52a1\u7684\u5b8c\u6210\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u591a\u65f6\u95f4\u5c3a\u5ea6\u7684\u667a\u80fd\u4f53\u67b6\u6784\u867d\u7136\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u4f46\u56e0\u6b64\u5f15\u5165\u7684\u5206\u5c42\u7ed3\u6784\u7834\u574f\u4e86\u539f\u6709\u7684\u534f\u8c03\u7a33\u5b9a\u6027\uff0c\u5bfc\u81f4\u5c42\u95f4\u51b2\u7a81\u3001\u9519\u8bef\u6269\u6563\u548c\u53ef\u6269\u5c55\u6027\u53d7\u9650\u7b49\u95ee\u9898\u3002\u63a8\u8fdb\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7a33\u5b9a\u548c\u9ad8\u6548\u534f\u8c03\u9700\u6c42\u9a71\u52a8\u4e86\u672c\u5de5\u4f5c\u7684\u4ea7\u751f\u3002", "method": "\u63d0\u51fa\u4e86\u53d7\u7ea6\u675f\u7684\u65f6\u95f4\u5c42\u6b21\u67b6\u6784\uff08Constrained Temporal Hierarchical Architecture\uff0cCTHA\uff09\uff0c\u901a\u8fc7\u5c06\u5c42\u95f4\u901a\u4fe1\u7a7a\u95f4\u6295\u5f71\u5230\u7ed3\u6784\u5316\u6d41\u5f62\uff0c\u5e76\u5f15\u5165\u7ea6\u675f\u5316\u4ef2\u88c1\u673a\u5236\uff0c\u5b9e\u73b0\u5206\u5c42\u4e4b\u95f4\u7684\u534f\u8c03\u548c\u51b3\u7b56\u4e00\u81f4\u3002CTHA\u5305\u542b\u4e09\u7c7b\u5173\u952e\u7ea6\u675f\uff1a(1) \u6d88\u606f\u5951\u7ea6\u7ea6\u675f\u2014\u2014\u7528\u7c7b\u578b\u5316\u6458\u8981\u3001\u8ba1\u5212\u548c\u7b56\u7565\u5305\u89c4\u8303\u5c42\u95f4\u4fe1\u606f\u6d41\uff1b(2) \u6743\u9650\u6d41\u5f62\u7ea6\u675f\u2014\u2014\u6839\u636e\u65f6\u95f4\u8303\u56f4\u9650\u5236\u5404\u5c42\u51b3\u7b56\u7a7a\u95f4\uff1b(3) \u4ef2\u88c1\u5206\u89e3\u7ea6\u675f\u2014\u2014\u4fdd\u8bc1\u591a\u5c42\u51b3\u7b56\u65e0\u51b2\u7a81\u5408\u6210\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCTHA\u53ef\u6709\u6548\u5b8c\u6210\u5927\u89c4\u6a21\u590d\u6742\u4efb\u52a1\uff0c\u4e0e\u65e0\u7ea6\u675f\u5c42\u6b21\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5931\u8d25\u7ea7\u8054\u51cf\u5c1147%\uff0c\u6837\u672c\u6548\u7387\u63d0\u53472.3\u500d\u4e14\u5177\u5907\u66f4\u4f18\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "CTHA\u4ee5\u4e25\u8c28\u7684\u7406\u8bba\u539f\u5219\u6269\u5c55\u4e86\u65f6\u95f4\u5c42\u6b21\u67b6\u6784\uff0c\u589e\u5f3a\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u8c03\u6027\u548c\u6027\u80fd\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u591a\u667a\u80fd\u4f53\u534f\u8c03\u673a\u5236\uff0c\u5e76\u63a8\u52a8\u81ea\u4e3b\u7cfb\u7edf\u7684\u7a33\u5065\u53d1\u5c55\u3002"}}
{"id": "2601.10744", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.10744", "abs": "https://arxiv.org/abs/2601.10744", "authors": ["Sen Wang", "Bangwei Liu", "Zhenkun Gao", "Lizhuang Ma", "Xuhong Wang", "Yuan Xie", "Xin Tan"], "title": "Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration", "comment": "Our dataset and code will be released at our \\href{https://wangsen99.github.io/papers/lmee/}{website}", "summary": "An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLMEE\u6846\u67b6\u548cMemoryExplorer\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u591a\u6a21\u6001\u5927\u6a21\u578b\u5b9e\u73b0\u4e3b\u52a8\u8bb0\u5fc6\u67e5\u8be2\uff0c\u5e76\u5728\u65b0\u6784\u5efa\u7684\u8bc4\u6d4b\u57fa\u51c6LMEE-Bench\u4e0a\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u4e3b\u6d41\u7684\u5177\u8eab\u667a\u80fd\u4efb\u52a1\u591a\u4ee5\u4e00\u6b21\u6027\u4efb\u52a1\u5b8c\u6210\u5ea6\u4e3a\u76ee\u6807\uff0c\u666e\u904d\u5ffd\u89c6\u4e86\u63a2\u7d22\u8fc7\u7a0b\u548c\u957f\u671f\u8bb0\u5fc6\u5229\u7528\uff0c\u800c\u7406\u60f3\u7684\u5177\u8eab\u667a\u80fd\u4f53\u5e94\u5177\u5907\u6301\u7eed\u5b66\u4e60\u3001\u957f\u671f\u7b56\u7565\u4f18\u5316\u80fd\u529b\u4ee5\u9002\u5e94\u590d\u6742\u73af\u5883\u3002", "method": "\u63d0\u51fa\u957f\u671f\u8bb0\u5fc6\u5177\u8eab\u63a2\u7d22\uff08LMEE\uff09\u6846\u67b6\u53ca\u914d\u5957\u57fa\u51c6LMEE-Bench\uff0c\u652f\u6301\u591a\u76ee\u6807\u5bfc\u822a\u4e0e\u57fa\u4e8e\u8bb0\u5fc6\u7684\u95ee\u7b54\uff1b\u63d0\u51faMemoryExplorer\u65b9\u6cd5\uff0c\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u591a\u6a21\u6001\u5927\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u5956\u52b1\u51fd\u6570\u5f15\u5bfc\u667a\u80fd\u4f53\u4e3b\u52a8\u63a2\u7d22\u548c\u8bb0\u5fc6\u56de\u6eaf\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u957f\u65f6\u5e8f\u5177\u8eab\u667a\u80fd\u4efb\u52a1\u4e2d\u5bf9\u6bd4\u4e3b\u6d41\u63a2\u7d22\u6a21\u578b\uff0c\u5c55\u73b0\u4e86\u663e\u8457\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u9a8c\u8bc1\u4e86\u901a\u8fc7\u878d\u5408\u4e3b\u52a8\u63a2\u7d22\u548c\u8bb0\u5fc6\u5229\u7528\uff0c\u53ef\u4ee5\u63d0\u5347\u5177\u8eab\u667a\u80fd\u4f53\u7684\u957f\u671f\u4efb\u52a1\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u7ec8\u751f\u5b66\u4e60\u578b\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2601.10768", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10768", "abs": "https://arxiv.org/abs/2601.10768", "authors": ["Nina Bo\u010dkov\u00e1", "Barbora Voln\u00e1", "Mirko Dohnal"], "title": "Optimisation of complex product innovation processes based on trend models with three-valued logic", "comment": null, "summary": "This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u7528\u8d8b\u52bf\u5efa\u6a21\u548c\u8f6c\u79fb\u56fe\u63cf\u8ff0\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\uff0c\u51cf\u5c11\u5bf9\u5177\u4f53\u6570\u503c\u4f9d\u8d56\u3002", "motivation": "\u4e3a\u907f\u514d\u5728\u5efa\u6a21\u590d\u6742\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\u65f6\u5bf9\u5177\u4f53\u6570\u503c\u6216\u7c97\u96c6\u4fe1\u606f\u7684\u4f9d\u8d56\uff0c\u63d0\u51fa\u4ee5\u8d8b\u52bf\u4e3a\u91cf\u5316\u624b\u6bb5\u6784\u5efa\u6a21\u578b\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u901a\u7528\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u4ee5\u8d8b\u52bf\u4e3a\u57fa\u7840\u7684\u542f\u53d1\u5f0f\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u8f6c\u79fb\u56fe\u65b9\u6cd5\u63cf\u8ff0\u72b6\u6001\u53ca\u5176\u95f4\u8f6c\u79fb\uff0c\u63ed\u793a\u521b\u65b0\u8fc7\u7a0b\u7684\u591a\u6837\u6027\u3002", "result": "\u8be5\u8bba\u6587\u5229\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\u5efa\u6a21\u590d\u6742\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\uff0c\u5c06\u6bcf\u4e00\u542f\u53d1\u5f0f\u8868\u8fbe\u4e3a\u7b80\u5355\u8d8b\u52bf\uff08\u589e\u52a0\u3001\u51cf\u5c11\u6216\u6052\u5b9a\uff09\uff0c\u4ee5\u6700\u5c0f\u5316\u5bf9\u53c2\u6570\u5316\u4fe1\u606f\u7684\u4f9d\u8d56\u3002\u89e3\u51b3\u65b9\u6848\u88ab\u5b9a\u4e49\u4e3a\u4e00\u7ec4\u573a\u666f\u53ca\u5176\u95f4\u53ef\u80fd\u7684\u72b6\u6001\u8f6c\u79fb\uff0c\u5e76\u901a\u8fc7\u8f6c\u79fb\u56fe\u52a0\u4ee5\u8868\u8fbe\u3002\u7cfb\u7edf\u4efb\u4f55\u53ef\u80fd\u7684\u8fc7\u53bb\u6216\u672a\u6765\u884c\u4e3a\u90fd\u53ef\u901a\u8fc7\u56fe\u4e2d\u7684\u8def\u5f84\u5448\u73b0\u3002", "conclusion": "\u901a\u8fc7\u8d8b\u52bf\u6a21\u578b\u548c\u8f6c\u79fb\u56fe\uff0c\u53ef\u4ee5\u5168\u9762\u523b\u753b\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\u7684\u591a\u79cd\u53ef\u80fd\u6f14\u5316\u8def\u5f84\uff0c\u65e0\u9700\u4f9d\u8d56\u590d\u6742\u7684\u53c2\u6570\u6216\u6570\u503c\u4fe1\u606f\u3002"}}
{"id": "2601.10922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10922", "abs": "https://arxiv.org/abs/2601.10922", "authors": ["Yosub Shin", "Michael Buriek", "Boris Sobolev", "Pavel Bushuyeu", "Vikas Kumar", "Haoyang Xu", "Samuel Watson", "Igor Molybog"], "title": "What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge", "comment": null, "summary": "We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.", "AI": {"tldr": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u591a\u6a21\u6001\u63a8\u7406\u56fa\u5b9a\u6a21\u578b\u548c\u8bad\u7ec3\u6d41\u7a0b\u4e0b\uff0c\u6570\u636e\u7b5b\u9009\u4e2d\u7684\u96be\u5ea6\u548c\u5bf9\u9f50\u6bd4\u591a\u6837\u6027\u4e0e\u5408\u6210\u589e\u5f3a\u66f4\u91cd\u8981\uff0c\u4e3b\u5bfc\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u63a2\u7a76\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u7b5b\u9009\uff08curation\uff09\u7b56\u7565\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u5df2\u56fa\u5b9a\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u6d41\u7a0b\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u56fa\u5b9a\u6a21\u578b\u548c\u8bad\u7ec3\u6d41\u7a0b\u540e\uff0c\u91c7\u7528\u6e90\u81eaWalton Multimodal Cold Start\u7684\u7d27\u51d1\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u96be\u5ea6\u7b5b\u9009\u548c\u5bf9\u9f50\u6784\u5efa\u8bad\u7ec3\u96c6\uff0c\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u5bf9\u6bd4\u6570\u636e\u89c4\u6a21\u3001\u591a\u6837\u6027\u3001\u5408\u6210\u589e\u5f3a\u7b49\u56e0\u7d20\u5bf9\u63a8\u7406\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u5728NeurIPS 2025 DCVLR\u6311\u6218\u8d5b\u4e2d\uff0c\u5229\u7528\u57fa\u4e8e\u96be\u5ea6\u7b5b\u9009\u5e76\u5bf9\u9f50\u7684\u57fa\u7840\u6570\u636e\u96c6\uff0c\u83b7\u5f97\u7b2c\u4e00\u540d\u3002\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u96be\u5ea6\u9a71\u52a8\u7684\u6570\u636e\u7b5b\u9009\u662f\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\uff0c\u6570\u636e\u96c6\u89c4\u6a21\u6269\u5927\u4ec5\u51cf\u5c11\u8bad\u7ec3\u7684\u65b9\u5dee\uff0c\u5bf9\u5747\u503c\u51c6\u786e\u7387\u5f71\u54cd\u6709\u9650\uff0c\u591a\u6837\u6027\u548c\u5408\u6210\u589e\u5f3a\u53cd\u800c\u65e0\u76ca\u751a\u81f3\u6709\u5bb3\u3002", "conclusion": "DCVLR\u95ee\u9898\u5c5e\u4e8e\u9971\u548c\u8bc4\u6d4b\u9636\u6bb5\uff0c\u6570\u636e\u96c6\u7684\u5bf9\u9f50\u548c\u96be\u5ea6\u9009\u62e9\u5bf9\u4e8e\u63d0\u5347\u6570\u636e-\u6548\u7387\u578b\u591a\u6a21\u6001\u63a8\u7406\u6027\u80fd\u8d77\u51b3\u5b9a\u6027\u4f5c\u7528\uff0c\u5e38\u7528\u7684\u591a\u6837\u6027\u548c\u589e\u5f3a\u624b\u6bb5\u5e76\u4e0d\u80fd\u5e26\u6765\u989d\u5916\u6536\u76ca\u3002"}}
{"id": "2601.11012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11012", "abs": "https://arxiv.org/abs/2601.11012", "authors": ["Jiahao Wang", "Shuangjia Zheng"], "title": "Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics", "comment": null, "summary": "The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.", "code_url": "https://github.com/GENTEL-lab/HADES", "code_stars": 0, "code_last_update": "2026-01-16", "AI": {"tldr": "\u4e3a\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u5728\u86cb\u767d\u8bbe\u8ba1\u4e2d\u7684\u9ad8\u7ef4\u590d\u6742\u6027\u548c\u7ed3\u6784\u7ea6\u675f\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u5408\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u7684HADES\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u9879\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u6210\u529f\u5b9e\u73b0\u86cb\u767d\u7ed3\u6784\u4e0e\u5e8f\u5217\u4e92\u7ea6\u675f\u7684\u9ad8\u6548\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5e8f\u5217\u7684\u86cb\u767d\u4f18\u5316\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u9ad8\u7ef4\u590d\u6742\u6027\uff0c\u6613\u53d7\u4e92\u4f5c\u6548\u5e94\uff08epistasis\uff09\u548c\u7ed3\u6784\u7ea6\u675f\u5ffd\u89c6\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u4f18\u5316\u6548\u679c\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u4e86HADES\uff0c\u4e00\u79cd\u57fa\u4e8e\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u91c7\u6837\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u7684\u8fd1\u4f3c\u540e\u9a8c\u9ad8\u6548\u91c7\u6837\u3002\u91c7\u7528\u52a8\u91cf\u548c\u6a21\u62df\u7269\u7406\u8fd0\u52a8\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u52a0\u901f\u91c7\u6837\uff0c\u5e76\u7ed3\u5408\u4f4d\u7f6e\u79bb\u6563\u5316\u5c06\u8fde\u7eed\u72b6\u6001\u8f6c\u6362\u4e3a\u79bb\u6563\u86cb\u767d\u5e8f\u5217\u3002\u540e\u9a8c\u7531\u4e24\u9636\u6bb5\u7f16\u7801-\u89e3\u7801\u6846\u67b6\u652f\u6301\uff0c\u4ee5\u5b66\u4e60\u7a81\u53d8\u90bb\u5c45\u95f4\u7684\u7ed3\u6784\u548c\u529f\u80fd\u5173\u7cfb\uff0c\u5f62\u6210\u5e73\u6ed1\u7684\u91c7\u6837\u666f\u89c2\u3002", "result": "\u5927\u89c4\u6a21\u5b9e\u9a8c\u8868\u660e\uff0cHADES\u5728\u591a\u9879\u8bc4\u4f30\u6307\u6807\u4e0a\u8d85\u8d8a\u5f53\u524d\u4e3b\u6d41\u65b9\u6cd5\uff0c\u80fd\u591f\u8bbe\u8ba1\u51fa\u7ed3\u6784\u76f8\u4f3c\u4e14\u529f\u80fd\u4f18\u5316\u7684\u86cb\u767d\u5e8f\u5217\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u57fa\u51c6\uff0c\u5728\u5927\u91cf\u4f53\u5916\u8bc4\u4f30\u6307\u6807\u4e2d\u8868\u73b0\u66f4\u4f73\uff0c\u80fd\u591f\u6709\u6548\u5730\u8fdb\u884c\u86cb\u767d\u5e8f\u5217\u7684\u8bbe\u8ba1\u548c\u4f18\u5316\uff0c\u5145\u5206\u5229\u7528\u86cb\u767d\u7ed3\u6784\u4e0e\u5e8f\u5217\u7684\u4e92\u7ea6\u675f\u5173\u7cfb\u3002"}}
{"id": "2601.11037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11037", "abs": "https://arxiv.org/abs/2601.11037", "authors": ["Shiyu Liu", "Yongjing Yin", "Jianhao Yan", "Yunbo Tang", "Qinggang Zhang", "Bei Li", "Xin Chen", "Jingang Wang", "Xunliang Cai", "Jinsong Su"], "title": "BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search", "comment": "Code is available at https://github.com/Liushiyu-0709/BAPO-Reliable-Search", "summary": "RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBAPO\uff0c\u4f18\u5316LLM\u57fa\u4e8eRL\u7684agent\u63a8\u7406\u8fb9\u754c\u8bc6\u522b\u80fd\u529b\uff0c\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u8bc1\u636e\u4e0d\u8db3\u65f6\u6b63\u786e\u4f7f\u7528\u201cIDK\u201d\uff0c\u5927\u5e45\u589e\u5f3a\u641c\u7d22\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709RL\u4f18\u5316\u7684LLM agentic search\u5728\u89e3\u7b54\u590d\u6742\u95ee\u9898\u65f6\uff0c\u7f3a\u4e4f\u5bf9\u81ea\u8eab\u63a8\u7406\u8fb9\u754c\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u5f88\u5c11\u5728\u4fe1\u606f\u4e0d\u5145\u5206\u65f6\u56de\u7b54\u201cIDK\u201d\uff0c\u5bfc\u81f4\u4e0d\u53ef\u9760\u751a\u81f3\u98ce\u9669\u6027\u7684\u7b54\u6848\u3002\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u4e9f\u9700\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Boundary-Aware Policy Optimization (BAPO)\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u62ec\u5206\u7ec4\u8fb9\u754c\u611f\u77e5\u5956\u52b1\u548c\u81ea\u9002\u5e94\u5956\u52b1\u8c03\u8282\u5668\uff0c\u4fc3\u8fdb\u5728\u63a8\u7406\u53d7\u9650\u65f6\u5408\u7406\u4f7f\u7528\u201cIDK\u201d\u3002\u5728\u65e9\u671f\u63a2\u7d22\u65f6\u901a\u8fc7\u8c03\u8282\u5668\u6291\u5236\u5956\u52b1\uff0c\u907f\u514d\u6a21\u578b\u6ee5\u7528\u201cIDK\u201d\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cBAPO\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u4e86agentic search\u7684\u6574\u4f53\u53ef\u9760\u6027\u3002", "conclusion": "BAPO\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eRL\u7684agentic search\u5728LLM\u4e0a\u7684\u53ef\u9760\u6027\uff0c\u4f7f\u5176\u5728\u8bc1\u636e\u4e0d\u8db3\u6216\u63a8\u7406\u53d7\u9650\u65f6\u80fd\u66f4\u597d\u5730\u4f7f\u7528\u201cIDK\u201d\u56de\u7b54\u3002"}}
{"id": "2601.11100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11100", "abs": "https://arxiv.org/abs/2601.11100", "authors": ["Zhezheng Hao", "Hong Wang", "Jian Luo", "Jianqing Zhang", "Yuyan Zhou", "Qiang Lin", "Can Wang", "Hande Dong", "Jiawei Chen"], "title": "ReCreate: Reasoning and Creating Domain Agents Driven by Experience", "comment": null, "summary": "Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.", "AI": {"tldr": "ReCreate\u901a\u8fc7\u7cfb\u7edf\u6027\u5229\u7528\u667a\u80fd\u4f53\u4ea4\u4e92\u7ecf\u9a8c\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u3001\u53ef\u89e3\u91ca\u4e14\u9ad8\u6027\u80fd\u7684\u9886\u57df\u667a\u80fd\u4f53\u751f\u6210\uff0c\u5728\u591a\u4e2a\u9886\u57df\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4e0e\u73b0\u6709\u81ea\u52a8\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u591a\u4e3a\u4eba\u5de5\u8bbe\u8ba1\uff0c\u6784\u5efa\u4ee3\u4ef7\u9ad8\uff0c\u96be\u4ee5\u9002\u5e94\u591a\u53d8\u7684\u4efb\u52a1\u9700\u6c42\u3002\u81ea\u52a8\u751f\u6210\u667a\u80fd\u4f53\u7684\u73b0\u6709\u65b9\u6cd5\u591a\u4ee5\u9ed1\u7bb1\u65b9\u5f0f\u8fdb\u884c\uff0c\u53ea\u5173\u6ce8\u6700\u7ec8\u6027\u80fd\u6307\u6807\uff0c\u5ffd\u7565\u4e86\u5bfc\u81f4\u667a\u80fd\u4f53\u6210\u8d25\u7684\u5177\u4f53\u539f\u56e0\uff0c\u4e14\u8ba1\u7b97\u4ee3\u4ef7\u9ad8\u3002\u6545\u9700\u63d0\u51fa\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u667a\u80fd\u4f53\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReCreate\u7684\u4ee5\u7ecf\u9a8c\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u667a\u80fd\u4f53\u751f\u6210\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5305\u542b\u4e09\u5927\u6838\u5fc3\u6a21\u5757\uff1a\uff081\uff09\u667a\u80fd\u4f53\u7ecf\u9a8c\u5b58\u50a8\u4e0e\u68c0\u7d22\uff0c\u5b9e\u73b0\u4ea4\u4e92\u5386\u53f2\u7684\u6309\u9700\u8c03\u53d6\u548c\u5206\u6790\uff1b\uff082\uff09\u63a8\u7406-\u521b\u9020\u534f\u540c\u6d41\u6c34\u7ebf\uff0c\u5c06\u6267\u884c\u7ecf\u9a8c\u6620\u5c04\u4e3a scaffold\uff08\u667a\u80fd\u4f53\u7ed3\u6784\uff09\u7684\u7f16\u8f91\u5efa\u8bae\uff1b\uff083\uff09\u5206\u5c42\u5f0f\u66f4\u65b0\u673a\u5236\uff0c\u5c06\u5177\u4f53\u5b9e\u4f8b\u62bd\u8c61\u4e3a\u53ef\u590d\u7528\u7684\u9886\u57df\u6a21\u5f0f\u3002\u6574\u4f53\u91c7\u7528agent-as-optimizer\u8303\u5f0f\uff0c\u6301\u7eed\u5229\u7528\u7ecf\u9a8c\u4f18\u5316\u667a\u80fd\u4f53\u8bbe\u8ba1\u3002", "result": "\u5728\u591a\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0cReCreate\u6846\u67b6\u65e0\u8bba\u662f\u5bf9\u6bd4\u4eba\u5de5\u8bbe\u8ba1\u8fd8\u662f\u73b0\u6709\u81ea\u52a8\u5316\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u521d\u59cb\u4ec5\u4f7f\u7528\u6781\u5c11\u79cd\u5b50\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\uff0c\u5747\u8868\u73b0\u51fa\u66f4\u4f18\u5f02\u7684\u6027\u80fd\u3002", "conclusion": "ReCreate\u6846\u67b6\u5b9e\u73b0\u4e86\u57fa\u4e8e\u7ecf\u9a8c\u7684\u667a\u80fd\u4f53\u81ea\u52a8\u751f\u6210\u4e0e\u4f18\u5316\uff0c\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u8d85\u8fc7\u4eba\u5de5\u548c\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5229\u7528\u4ea4\u4e92\u5386\u53f2\u4f5c\u4e3a\u4f18\u5316\u4f9d\u636e\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.11178", "categories": ["cs.AI", "cs.CL", "cs.MM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11178", "abs": "https://arxiv.org/abs/2601.11178", "authors": ["Girish A. Koushik", "Helen Treharne", "Diptesh Kanojia"], "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech", "comment": "Under review at ICWSM 2026", "summary": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.", "AI": {"tldr": "TANDEM\u8f6c\u53d8\u4e86\u97f3\u89c6\u9891\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u4efb\u52a1\u4e3a\u7ed3\u6784\u5316\u63a8\u7406\u95ee\u9898\uff0c\u5229\u7528\u65b0\u9896\u7684\u8054\u52a8\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u591a\u6a21\u6001\u89e3\u91ca\u6027\u4e0e\u8bc6\u522b\u51c6\u786e\u5ea6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u957f\u6587\u672c\u591a\u6a21\u6001\u5185\u5bb9\uff08\u97f3\u9891\u3001\u89c6\u89c9\u3001\u6587\u672c\u7b49\uff09\u4f7f\u6709\u5bb3\u53d9\u8ff0\u66f4\u5177\u9690\u853d\u6027\u548c\u590d\u6742\u6027\uff0c\u81ea\u52a8\u5316\u68c0\u6d4b\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u65e0\u6cd5\u4e3a\u4eba\u5de5\u76d1\u7ba1\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u8bc1\u636e\u3002", "method": "\u65b9\u6cd5\u5f15\u5165TANDEM\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u7531\u4e8c\u5206\u7c7b\u8f6c\u4e3a\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u5229\u7528\u89c6\u89c9-\u6587\u672c\u4e0e\u97f3\u9891-\u6587\u672c\u6a21\u578b\u8054\u52a8\uff0c\u901a\u8fc7\u65e0\u987b\u5bc6\u96c6\u6807\u6ce8\u7684\u81ea\u7ea6\u675f\u8de8\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u5171\u540c\u4f18\u5316\uff0c\u5b9e\u73b0\u5bf9\u6709\u5bb3\u5185\u5bb9\u7684\u7a33\u5b9a\u63a8\u7406\u548c\u7cbe\u786e\u65f6\u5e8f\u5b9a\u4f4d\u3002", "result": "\u63d0\u51fa\u7684TANDEM\u6846\u67b6\u5728\u4e09\u5927\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728HateMM\u76ee\u6807\u8bc6\u522b\u4efb\u52a1\u4e2dF1\u5206\u6570\u4e3a0.73\uff08\u6bd4SOTA\u63d0\u534730%\uff09\uff0c\u5e76\u80fd\u7cbe\u786e\u5b8c\u6210\u65f6\u5e8f\u5b9a\u4f4d\u3002", "conclusion": "\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u673a\u5236\u662f\u53ef\u884c\u7684\uff0c\u8fd9\u4e3a\u4e0b\u4e00\u4ee3\u900f\u660e\u4e14\u53ef\u64cd\u4f5c\u7684\u5185\u5bb9\u5b89\u5168\u5de5\u5177\u63d0\u4f9b\u4e86\u8303\u4f8b\u3002"}}
{"id": "2601.11286", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11286", "abs": "https://arxiv.org/abs/2601.11286", "authors": ["Weihong Qi", "Fan Huang", "Rasika Muralidharan", "Jisun An", "Haewoon Kwak"], "title": "XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making", "comment": null, "summary": "We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.", "AI": {"tldr": "XChoice\u6846\u67b6\u4ee5\u673a\u5236\u578b\u53c2\u6570\u4e3a\u6307\u6807\uff0c\u63ed\u793aAI\u4e0e\u4eba\u7c7b\u5728\u65f6\u95f4\u5206\u914d\u7b49\u51b3\u7b56\u4e2d\u7684\u6df1\u5c42\u6b21\u4e00\u81f4\u6027\u4e0e\u5931\u8861\uff0c\u6bd4\u4f20\u7edf\u7ed3\u679c\u6307\u6807\u66f4\u5177\u89e3\u91ca\u529b\u3002", "motivation": "\u76ee\u524d\u7528\u4e8e\u8bc4\u4f30AI\u4e0e\u4eba\u7c7b\u5728\u53d7\u9650\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u4e00\u81f4\u6027\u7684\u65b9\u6cd5\uff0c\u5982\u51c6\u786e\u7387\u548cF1\u8bc4\u5206\uff0c\u65e0\u6cd5\u63ed\u793a\u66f4\u6df1\u5c42\u6b21\u7684\u51b3\u7b56\u673a\u5236\u548c\u5185\u5728\u53c2\u6570\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u5177\u89e3\u91ca\u6027\u548c\u673a\u5236\u6027\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5c06AI\u548c\u4eba\u7c7b\u7684\u51b3\u7b56\u6570\u636e\u62df\u5408\u5230\u673a\u5236\u578b\u51b3\u7b56\u6a21\u578b\uff0c\u5e76\u6062\u590d\u53c2\u6570\uff0c\u8fdb\u800c\u6bd4\u8f83\u53c2\u6570\u5411\u91cf\uff0c\u8bc4\u4f30\u5bf9\u9f50\u72b6\u51b5\u3002\u6a21\u578b\u5e94\u7528\u4e8eATUS\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u5f02\u8d28\u6027\u5206\u6790\u3001\u9c81\u68d2\u6027\u68c0\u9a8c\u4ee5\u53ca\u9488\u5bf9\u6027\u5e72\u9884\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u4e86XChoice\u6846\u67b6\uff0c\u901a\u8fc7\u62df\u5408\u673a\u5236\u578b\u51b3\u7b56\u6a21\u578b\uff0c\u6062\u590d\u51fa\u53ef\u89e3\u91ca\u53c2\u6570\uff08\u51b3\u7b56\u8981\u7d20\u91cd\u8981\u6027\u3001\u7ea6\u675f\u654f\u611f\u6027\u3001\u6743\u8861\uff09\uff0c\u5e76\u901a\u8fc7\u53c2\u6570\u5411\u91cf\u6bd4\u8f83\u6df1\u5165\u5206\u6790AI\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u60c5\u51b5\u3002\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0\uff0c\u4e0d\u540c\u6a21\u578b\u3001\u6d3b\u52a8\u548c\u5b50\u7fa4\u4f53\u95f4\u5b58\u5728\u5f02\u8d28\u6027\u5bf9\u9f50\u60c5\u51b5\uff0c\u5176\u4e2d\u9ed1\u4eba\u548c\u5df2\u5a5a\u7fa4\u4f53\u7684\u5bf9\u9f50\u5931\u8861\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "XChoice\u80fd\u591f\u8bca\u65ad\u5e76\u91cf\u5316AI-human misalignment\u7684\u5177\u4f53\u673a\u5236\uff0c\u4e3a\u540e\u7eed\u5b9a\u5411\u6539\u8fdb\uff08\u5982RAG\u5e72\u9884\uff09\u63d0\u4f9b\u4f9d\u636e\uff0c\u63a8\u52a8\u9886\u57df\u4ece\u8868\u9762\u7ed3\u679c\u5bf9\u9f50\u8d70\u5411\u673a\u5236\u89e3\u91ca\u548c\u5e72\u9884\u4f18\u5316\u3002"}}
{"id": "2601.11354", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11354", "abs": "https://arxiv.org/abs/2601.11354", "authors": ["Weiyi Wang", "Xinchi Chen", "Jingjing Gong", "Xuanjing Huang", "Xipeng Qiu"], "title": "AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems", "comment": null, "summary": "Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u9488\u5bf9\u7a7a\u95f4\u89c4\u5212\u95ee\u9898\u7684\u667a\u80fd\u4f53\u57fa\u51c6\uff0c\u5e76\u53d1\u73b0\u5f53\u524d\u901a\u7528LLMs\u5728\u771f\u5b9e\u7269\u7406\u7ea6\u675f\u4e0b\u4efb\u52a1\u8868\u73b0\u8f83\u5f31\u3002", "motivation": "\u4ee5\u5f80\u667a\u80fd\u4f53\u57fa\u51c6\u591a\u9488\u5bf9\u7b26\u53f7\u6216\u5f31\u7269\u7406\u573a\u666f\uff0c\u672a\u5145\u5206\u8bc4\u4f30LLMs\u5728\u771f\u5b9e\u7269\u7406\u7ea6\u675f\u9886\u57df\u7684\u89c4\u5212\u80fd\u529b\u3002\u9488\u5bf9\u822a\u5929\u53ca\u9ad8\u73b0\u5b9e\u6027\u73af\u5883\u7684\u9700\u6c42\uff0c\u63d0\u51fa\u65b0\u7684\u57fa\u51c6\u4ee5\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5efa\u7acb\u9ad8\u7269\u7406\u7ea6\u675f\u3001\u591a\u76ee\u6807\u3001\u9700\u957f\u65f6\u51b3\u7b56\u7684\u7a7a\u95f4\u89c4\u5212\u4efb\u52a1\u96c6\uff0c\u5e76\u6574\u5408\u591a\u79cd\u8c03\u5ea6\u673a\u5236\uff08\u5982\u5730\u9762\u7ad9\u901a\u4fe1\u3001\u5730\u7403\u89c2\u6d4b\uff09\uff0c\u901a\u8fc7\u7edf\u4e00\u534f\u8bae\u6d4b\u8bd5\u5f53\u524d\u4e3b\u6d41\u5f00\u6e90\u4e0e\u95ed\u6e90\u667a\u80fd\u4f53LLMs\u7cfb\u7edf\u8868\u73b0\u3002", "result": "\u63d0\u51fa\u4e86AstroReason-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u667a\u80fd\u4f53\u5728\u7a7a\u95f4\u89c4\u5212\u95ee\u9898\uff08SPP\uff09\u4e2d\u7684\u89c4\u5212\u8868\u73b0\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u73b0\u6709\u667a\u80fd\u4f53LLMs\u5728\u5177\u5907\u4e25\u683c\u7269\u7406\u7ea6\u675f\u7684\u5b9e\u9645\u573a\u666f\u4e0b\uff0c\u660e\u663e\u4e0d\u5982\u4e13\u7528\u95ee\u9898\u6c42\u89e3\u5668\u3002", "conclusion": "AstroReason-Bench\u4e3a\u672a\u6765\u667a\u80fd\u4f53\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u5177\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002\u5f53\u524dLLMs\u5728\u9ad8\u7269\u7406\u73b0\u5b9e\u6027\u573a\u666f\u4e0b\u5c1a\u5b58\u663e\u8457\u4e0d\u8db3\u3002"}}
{"id": "2601.11389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11389", "abs": "https://arxiv.org/abs/2601.11389", "authors": ["Hedieh Haddad", "Thibault Falque", "Pierre Talbot", "Pascal Bouvry"], "title": "Hyperparameter Optimization of Constraint Programming Solvers", "comment": "28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization", "summary": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.\n  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.\n  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.", "AI": {"tldr": "\u8be5\u7b97\u6cd5\u81ea\u52a8\u8c03\u4f18\u7ea6\u675f\u6c42\u89e3\u5668\u8d85\u53c2\u6570\uff0c\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u663e\u8457\u8d85\u8fc7\u9ed8\u8ba4\u914d\u7f6e\u548c\u7b80\u5355\u5c40\u90e8\u641c\u7d22\u3002", "motivation": "\u7ea6\u675f\u89c4\u5212\u6c42\u89e3\u5668\u7684\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u8d85\u53c2\u6570\u8bbe\u7f6e\uff0c\u4f46\u624b\u5de5\u8c03\u53c2\u8017\u65f6\u4e14\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u7684\u9ad8\u6548\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u6765\u63d0\u5347\u6c42\u89e3\u8d28\u91cf\u5e76\u964d\u4f4e\u4eba\u529b\u6d88\u8017\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u81ea\u52a8\u5316\u8d85\u53c2\u6570\u4f18\u5316\u6846\u67b6\uff1a\u5148\u7528\u63a2\u6d4b\u9636\u6bb5\u7edf\u8ba1\u5404\u79cd\u8d85\u53c2\u6570\u8868\u73b0\uff08\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u548cHamming\u8ddd\u79bb\u641c\u7d22\uff09\uff0c\u518d\u5728\u5269\u4f59\u65f6\u95f4\u7528\u6700\u4f73\u914d\u7f6e\u89e3\u51b3\u95ee\u9898\uff0c\u5e76\u5728ACE\u4e0eChoco\u6c42\u89e3\u5668\u3001\u591a\u5b9e\u4f8b\u4e0b\u5bf9\u4e0d\u540c\u65b9\u6cd5\u8fdb\u884c\u5b9e\u9a8c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u8d85\u53c2\u6570\u4f18\u5316\u6846\u67b6\u2014\u2014Probe and Solve\u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230CPMpy\u5e93\u4e2d\u3002\u8be5\u65b9\u6cd5\u5728\u7ea6\u675f\u89c4\u5212\u6c42\u89e3\u5668ACE\u548cChoco\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u9ed8\u8ba4\u914d\u7f6e\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u65f6\uff0cProbe and Solve\u7b97\u6cd5\u80fd\u572825.4%\u7684ACE\u5b9e\u4f8b\u548c38.6%\u7684Choco\u5b9e\u4f8b\u4e0a\u663e\u8457\u63d0\u5347\u89e3\u51b3\u8d28\u91cf\uff0c\u4e14\u5728\u5927\u591a\u6570\u5269\u4f59\u5b9e\u4f8b\u4e2d\u80fd\u5339\u914d\u6216\u8d85\u8fc7\u9ed8\u8ba4\u6027\u80fd\u3002\u540c\u65f6\uff0c\u8be5\u7b97\u6cd5\u5728\u76f8\u540c\u8bbe\u7f6e\u4e0b\u660e\u663e\u4f18\u4e8e\u57fa\u4e8eHamming\u8ddd\u79bb\u7684\u641c\u7d22\u65b9\u6cd5\u3002", "conclusion": "Probe and Solve\u7b97\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u7ea6\u675f\u89c4\u5212\u6c42\u89e3\u5668\u7684\u6027\u80fd\uff0c\u662f\u4e00\u79cd\u5207\u5b9e\u6709\u6548\u4e14\u80fd\u5145\u5206\u5229\u7528\u8d44\u6e90\u7684\u8d85\u53c2\u6570\u81ea\u52a8\u4f18\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u7c7b\u578b\u95ee\u9898\u3002"}}
{"id": "2601.11468", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11468", "abs": "https://arxiv.org/abs/2601.11468", "authors": ["Alessandro Padella", "Massimiliano de Leoni", "Marlon Dumas"], "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs", "comment": "19 pages, 4 figure, TMIS journal submission", "summary": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86LLM\u5728\u9884\u6d4b\u6d41\u7a0b\u76d1\u63a7\u4e2d\u7684\u5e94\u7528\uff0c\u7ed3\u679c\u8868\u660e\u5176\u5728\u6570\u636e\u5c11\u65f6\u8868\u73b0\u4f18\u5f02\u4e14\u5177\u5907\u66f4\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u5bf9\u672a\u6765\u6d41\u7a0b\u667a\u80fd\u5177\u6709\u501f\u9274\u4ef7\u503c\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u9886\u57df\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5982\u4f55\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u5347\u9884\u6d4b\u6548\u679c\u3001\u6269\u5c55\u5176\u6cdb\u5316\u80fd\u529b\u548c\u63a8\u7406\u673a\u5236\u5c1a\u5f85\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u672c\u6587\u6269\u5c55\u4e86\u5148\u524d\u4ee5LLM\u4e3a\u6838\u5fc3\u3001\u57fa\u4e8eprompt\u7684\u65b9\u6cd5\uff0c\u56f4\u7ed5\u5173\u952e\u6027\u80fd\u6307\u6807\uff08KPI\uff09\uff0c\u5728\u4e09\u4e2a\u4e0d\u540c\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u7efc\u5408\u6027\u8bc4\u4f30\u5176\u6cdb\u5316\u6027\u3001\u8bed\u4e49\u5229\u7528\u53ca\u63a8\u7406\u673a\u5236\uff0c\u6db5\u76d6\u603b\u65f6\u957f\u9884\u6d4b\u4e0e\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u4e24\u4e2a\u5178\u578bKPI\uff0c\u5e76\u5206\u6790\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u4ec5\u6709100\u6761\u6d41\u7a0b\u8bb0\u5f55\u7684\u6570\u636e\u7a00\u7f3a\u60c5\u666f\u4e0b\uff0cLLM\u65b9\u6cd5\u5728\u603b\u65f6\u957f\u548c\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u4e0a\u5747\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\uff1b\u6b64\u5916\uff0c\u5b9e\u9a8c\u8bc1\u660eLLM\u4e0d\u4ec5\u80fd\u5229\u7528\u5176\u5185\u5728\u5148\u9a8c\u77e5\u8bc6\uff0c\u8fd8\u80fd\u6709\u6548\u5229\u7528\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u76f8\u4e92\u5173\u8054\uff1b\u63a8\u7406\u673a\u5236\u5206\u6790\u5c55\u793a\u4e86LLM\u5177\u5907\u66f4\u9ad8\u9636\u7684\u63a8\u7406\u80fd\u529b\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u7167\u642c\u5df2\u6709\u65b9\u6cd5\u3002", "conclusion": "LLM\u4e0d\u4ec5\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u5b9e\u73b0\u66f4\u4f18\u9884\u6d4b\uff0c\u8fd8\u80fd\u8fdb\u884c\u590d\u6742\u63a8\u7406\uff0c\u663e\u793a\u51fa\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u7684\u6f5c\u529b\uff0c\u63a8\u8fdb\u4e86\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u5728\u6cdb\u5316\u6027\u4e0e\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u8fb9\u754c\u3002"}}
{"id": "2601.11479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11479", "abs": "https://arxiv.org/abs/2601.11479", "authors": ["Yohai Trabelsi", "Guojun Xiong", "Fentabil Getnet", "St\u00e9phane Verguet", "Milind Tambe"], "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning", "comment": null, "summary": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.", "AI": {"tldr": "\u63d0\u51faLEG\u6846\u67b6\uff0c\u5c06\u4e13\u5bb6\u5b9a\u6027\u77e5\u8bc6\u4e0e\u4f18\u5316\u7b97\u6cd5\u7ed3\u5408\uff0c\u7528\u4e8e\u533b\u7597\u70b9\u4f18\u5148\u5347\u7ea7\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u3001\u516c\u5e73\uff0c\u5b9e\u73b0\u8986\u76d6\u6700\u5927\u5316\u3002", "motivation": "\u536b\u751f\u8d44\u6e90\u6709\u9650\uff0c\u9700\u5728\u5347\u7ea7\u533b\u7597\u70b9\u65f6\u4f18\u5148\u6392\u5e8f\uff0c\u5b9e\u73b0\u6700\u5927\u4eba\u53e3\u8986\u76d6\uff1b\u4e13\u5bb6\u548c\u5229\u76ca\u76f8\u5173\u65b9\u7684\u6807\u51c6\u591a\u4e3a\u8bed\u8a00\u8868\u8ff0\uff0c\u96be\u4ee5\u91cf\u5316\uff0c\u9700\u4e00\u79cd\u80fd\u7ed3\u5408\u5b9a\u91cf\u4f18\u5316\u4e0e\u5b9a\u6027\u4e13\u5bb6\u77e5\u8bc6\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Large language model and Extended Greedy\uff08LEG\uff09\u6df7\u5408\u6846\u67b6\uff0c\u5c06\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u4f18\u5316\u7b97\u6cd5\u7ed3\u5408\uff0c\u7528\u4e8e\u5347\u7ea7\u533b\u7597\u70b9\u3002\u8be5\u6846\u67b6\u878d\u5408\u4e86\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u8986\u76d6\u7387\u4f18\u5316\u8d2a\u5fc3\u7b97\u6cd5\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u4eba\u673a\u4ea4\u4e92\u8fed\u4ee3\uff0c\u4ee5\u5b9e\u73b0\u4e13\u5bb6\u5b9a\u6027\u6307\u5bfc\u4e0e\u4f18\u5316\u76ee\u6807\u7684\u7edf\u4e00\u3002", "result": "\u5728\u57c3\u585e\u4fc4\u6bd4\u4e9a\u4e09\u5730\u533a\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u663e\u793a\uff0cLEG\u6846\u67b6\u80fd\u517c\u987e\u4eba\u53e3\u8986\u76d6\u7684\u6700\u4f18\u5316\u4e0e\u4e13\u5bb6\u5b9a\u6027\u9700\u6c42\uff0c\u6709\u6548\u63d0\u5347\u516c\u5e73\u6027\u4e0e\u6570\u636e\u9a71\u52a8\u7684\u536b\u751f\u7cfb\u7edf\u89c4\u5212\u3002", "conclusion": "LEG\u6846\u67b6\u4e3a\u536b\u751f\u8bbe\u65bd\u5347\u7ea7\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u8d44\u6e90\u5229\u7528\u6700\u4f18\u5316\u4e0e\u4e13\u5bb6\u4e3b\u5bfc\u7684\u653f\u7b56\u5236\u5b9a\uff0c\u5bf9\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u6570\u636e\u9a71\u52a8\u533b\u7597\u51b3\u7b56\u5177\u6709\u91cd\u8981\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2601.11492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11492", "abs": "https://arxiv.org/abs/2601.11492", "authors": ["Kaiwen Wang", "Kaili Zheng", "Rongrong Deng", "Qingmin Fan", "Milin Zhang", "Zongrui Li", "Xuesi Zhou", "Bo Han", "Liren Chen", "Chenyi Guo", "Ji Wu"], "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics", "comment": null, "summary": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.", "AI": {"tldr": "BoxMind\u5229\u7528AI\u89e3\u6790\u62f3\u51fb\u8d5b\u4e8b\u89c6\u9891\uff0c\u63d0\u53d6\u6280\u672f-\u6218\u672f\u6307\u6807\uff0c\u7ed3\u5408\u56fe\u6a21\u578b\u4f18\u5316\u8d5b\u5c40\u9884\u6d4b\u4e0e\u5373\u65f6\u6218\u672f\u5efa\u8bae\uff0c\u5728\u5965\u8fd0\u4f1a\u5b9e\u6218\u4e2d\u63d0\u5347\u961f\u4f0d\u6218\u7ee9\u3002", "motivation": "\u62f3\u51fb\u7b49\u5bf9\u6297\u578b\u8fd0\u52a8\u56e0\u52a8\u4f5c\u590d\u6742\u53ca\u6218\u672f\u7ed3\u6784\u8868\u5f81\u532e\u4e4f\uff0cAI\u9a71\u52a8\u6218\u672f\u5206\u6790\u53d1\u5c55\u6ede\u540e\u3002\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7ed3\u6784\u5316\u6218\u672f\u8868\u5f81\u4e0e\u667a\u80fd\u5206\u6790\uff0c\u63d0\u5347\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u7ade\u6280\u4f53\u80b2\u4e2d\u7684\u51b3\u7b56\u652f\u6301\u80fd\u529b\u3002", "method": "1. \u660e\u786e\u5b9a\u4e49\u539f\u5b50\u62f3\u51fb\u4e8b\u4ef6\uff0c\u5177\u5907\u65f6\u95f4\u3001\u7a7a\u95f4\u4e0e\u6280\u672f\u5c5e\u6027\u30022. \u89c6\u9891\u89e3\u6790\u4e3a18\u7c7b\u6280\u672f-\u6218\u672f\u6307\u6807\u30023. \u6784\u5efa\u56fe\u7ed3\u6784\u6a21\u578b\uff0c\u878d\u5408\u663e\u5f0f\u7279\u5f81\u4e0e\u9690\u53d8\u91cf\u8fdb\u884c\u8d5b\u5c40\u52a8\u6001\u5efa\u6a21\u30024. \u5c06\u9884\u6d4b\u7ed3\u679c\u5bfc\u5411\u6218\u672f\u8c03\u6574\uff0c\u5b9e\u73b0\u95ed\u73af\u53cd\u9988\u63a8\u8350\u3002", "result": "BoxMind\u7cfb\u7edf\u80fd\u591f\u89e3\u6790\u62f3\u51fb\u6bd4\u8d5b\u7684\u52a8\u4f5c\u52a8\u6001\uff0c\u5c06\u6bd4\u8d5b\u5f55\u50cf\u4e2d\u7684\u539f\u5b50\u62f3\u51fb\u4e8b\u4ef6\u6620\u5c04\u4e3a18\u4e2a\u5c42\u6b21\u5316\u6280\u672f-\u6218\u672f\u6307\u6807\uff0c\u901a\u8fc7\u56fe\u7ed3\u6784\u9884\u6d4b\u6a21\u578b\u878d\u5408\u663e\u5f0f\u7684\u6280\u672f-\u6218\u672f\u7279\u5f81\u4e0e\u53ef\u5b66\u4e60\u7684\u65f6\u53d8\u9690\u53d8\u91cf\uff0c\u5b9e\u73b0\u8d5b\u5c40\u8f93\u51fa\u9884\u6d4b\u4e0e\u6218\u672f\u5efa\u8bae\u3002", "conclusion": "BoxMind\u4e0d\u4ec5\u5728\u6bd4\u8d5b\u7ed3\u679c\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff08BoxerGraph\u6570\u636e\u96c669.8%\u3001\u5965\u8fd0\u8d5b\u4e8b87.5%\u51c6\u786e\u7387\uff09\uff0c\u8fd8\u80fd\u751f\u6210\u5ab2\u7f8e\u4eba\u7c7b\u4e13\u5bb6\u7684\u6218\u672f\u63a8\u8350\uff0c\u5e76\u5df2\u5728\u9876\u7ea7\u8d5b\u4e8b\u95ed\u73af\u5e94\u7528\u9a8c\u8bc1\uff0c\u63a8\u52a8\u961f\u4f0d\u53d6\u5f97\u5386\u53f2\u6027\u6210\u7ee9\u3002"}}
{"id": "2601.05487", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05487", "abs": "https://arxiv.org/abs/2601.05487", "authors": ["Huanxiang Lin", "Qianyue Wang", "Jinwu Hu", "Bailin Chen", "Qing Du", "Mingkui Tan"], "title": "EvidFuse: Writing-Time Evidence Learning for Consistent Text-Chart Data Reporting", "comment": null, "summary": "Data-driven reports communicate decision-relevant insights by tightly interleaving narrative text with charts grounded in underlying tables. However, current LLM-based systems typically generate narratives and visualizations in staged pipelines, following either a text-first-graph-second or a graph-first-text-second paradigm. These designs often lead to chart-text inconsistency and insight freezing, where the intermediate evidence space becomes fixed and the model can no longer retrieve or construct new visual evidence as the narrative evolves, resulting in shallow and predefined analysis. To address the limitations, we propose \\textbf{EvidFuse}, a training-free multi-agent framework that enables writing-time text-chart interleaved generation for data-driven reports. EvidFuse decouples visualization analysis from long-form drafting via two collaborating components: a \\textbf{Data-Augmented Analysis Agent}, equipped with Exploratory Data Analysis (EDA)-derived knowledge and access to raw tables, and a \\textbf{Real-Time Evidence Construction Writer} that plans an outline and drafts the report while intermittently issuing fine-grained analysis requests. This design allows visual evidence to be constructed and incorporated exactly when the narrative requires it, directly constraining subsequent claims and enabling on-demand expansion of the evidence space. Experiments demonstrate that EvidFuse attains the top rank in both LLM-as-a-judge and human evaluations on chart quality, chart-text alignment, and report-level usefulness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u514d\u75ab\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6EvidFuse\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u9a71\u52a8\u62a5\u544a\u7684\u6587\u672c\u4e0e\u56fe\u8868\u534f\u540c\u751f\u6210\u3002", "motivation": "\u5f53\u524dLLM\u7cfb\u7edf\u62a5\u544a\u751f\u6210\u591a\u91c7\u53d6\u5206\u9636\u6bb5\u6d41\u7a0b\uff0c\u5bb9\u6613\u5bfc\u81f4\u56fe\u6587\u4e0d\u4e00\u81f4\u548c\u89c1\u89e3\u7a7a\u95f4\u53d7\u9650\uff0c\u96be\u4ee5\u52a8\u6001\u8c03\u6574\u5206\u6790\u5185\u5bb9\u3002\u4e9f\u9700\u4e00\u79cd\u80fd\u5728\u5199\u4f5c\u671f\u95f4\u7075\u6d3b\u534f\u540c\u6587\u672c\u548c\u56fe\u8868\u751f\u6210\u7684\u65b0\u6846\u67b6\u3002", "method": "EvidFuse\u5305\u62ec\u4e24\u4e2a\u534f\u540c\u7ec4\u4ef6\uff1a\u4e00\u4e2a\u5177\u5907EDA\u77e5\u8bc6\u4e14\u53ef\u8bbf\u95ee\u539f\u59cb\u8868\u683c\u7684\u6570\u636e\u589e\u5f3a\u5206\u6790\u667a\u80fd\u4f53\uff0c\u8d1f\u8d23\u5206\u6790\uff1b\u4e00\u4e2a\u5b9e\u65f6\u6784\u8bc1\u5199\u4f5c\u667a\u80fd\u4f53\uff0c\u8d1f\u8d23\u89c4\u5212\u62a5\u544a\u5927\u7eb2\u3001\u8349\u62df\u6587\u672c\u548c\u6309\u9700\u8bf7\u6c42\u5206\u6790\uff0c\u4ece\u800c\u5b9e\u73b0\u5199\u4f5c\u8fc7\u7a0b\u4e2d\u52a8\u6001\u5d4c\u5165\u56fe\u8868\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cEvidFuse\u5728\u56fe\u8868\u8d28\u91cf\u3001\u56fe\u6587\u4e00\u81f4\u6027\u4ee5\u53ca\u62a5\u544a\u5b9e\u7528\u6027\u65b9\u9762\uff0c\u5747\u5728LLM\u8bc4\u5224\u548c\u4eba\u5de5\u8bc4\u6d4b\u4e2d\u83b7\u5f97\u6700\u9ad8\u5206\u3002", "conclusion": "EvidFuse\u80fd\u5b9e\u65f6\u6839\u636e\u6587\u672c\u9700\u6c42\u53ca\u65f6\u751f\u6210\u5e76\u5f15\u5165\u53ef\u89c6\u5316\u8bc1\u636e\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u56fe\u6587\u4e0d\u4e00\u81f4\u548c\u89c1\u89e3\u50f5\u5316\u95ee\u9898\uff0c\u5e76\u5728\u591a\u9879\u8bc4\u6d4b\u4e2d\u53d6\u5f97\u6700\u4f73\u8868\u73b0\u3002"}}
