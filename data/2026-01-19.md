<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 19]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Can Small Agent Collaboration Beat a Single Big LLM?](https://arxiv.org/abs/2601.11327)
*Agata Żywot,Xinyi Chen,Maarten de Rijke*

Main category: cs.MA

TL;DR: 该报告探讨了小规模、工具增强型智能体在GAIA基准测试上的表现，并比较了其与更大规模单体模型的差异。


<details>
  <summary>Details</summary>
Motivation: 探究在任务解决中，小模型通过工具增强能否匹敌甚至超越大型单体模型，并分析工具使用与显式思维对智能体表现的影响。

Method: 采用Qwen3模型（参数规模4B-32B），并在Agentic-Reasoning框架下，研究模型规模、显式思维及工具使用（检索、代码、思维导图）的影响。通过比较无思考、仅规划、完全思考，以及不同工具增强方式的配置进行实验。

Result: 工具增强带来最大的性能提升，使得4B模型在使用工具后超过了32B无工具模型。显式思维表现依赖配置，规划型思维有助于任务分解与约束跟踪，而全量显式思维可能因工具管控混乱导致性能下降。

Conclusion: 工具增强是提升智能体性能的最有效且稳定的方法，甚至能使小模型超越无工具的大模型。显式思维的提升具有依赖性，并可能导致性能下降。

Abstract: This report studies whether small, tool-augmented agents can match or outperform larger monolithic models on the GAIA benchmark. Using Qwen3 models (4B-32B) within an adapted Agentic-Reasoning framework, we isolate the effects of model scale, explicit thinking (no thinking, planner-only, or full), and tool use (search, code, mind-map). Tool augmentation provides the largest and most consistent gains. Using tools, 4B models can outperform 32B models without tool access on GAIA in our experimental setup. In contrast, explicit thinking is highly configuration- and difficulty-dependent: planner-only thinking can improve decomposition and constraint tracking, while unrestricted full thinking often degrades performance by destabilizing tool orchestration, leading to skipped verification steps, excessive tool calls, non-termination, and output-format drift.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Building AI Agents to Improve Job Referral Requests to Strangers](https://arxiv.org/abs/2601.10726)
*Ross Chu,Yuting Huang*

Main category: cs.AI

TL;DR: 本文提出一种结合RAG的多智能体系统，自动优化职业社交平台上的内推请求，实现弱请求预测成功率大幅提升，对强请求无负面影响。


<details>
  <summary>Details</summary>
Motivation: 在职业社区中，请求内推的成效差异大，部分用户因措辞或表达不当导致请求难以被接受，从而影响求职效率。本文致力于为求职者提供自动化且高效的内推请求优化工具，以增加请求的获得内推概率。

Method: 本文提出了一种AI工作流，包含重写（improver）和质量评估（evaluator）两类智能体。重写智能体基于LLM对请求进行优化，评估智能体则利用训练模型预测推荐成功率。此外，通过Retrieval-Augmented Generation（RAG）机制增强LLM表现。

Result: RAG增强的LLM修正能够在不影响强请求的基础上，将弱请求的预测成功率提升14%。

Conclusion: 结合RAG的LLM修正方法在不降低强请求表现的情况下，能显著提升弱推荐请求的预测成功率。

Abstract: This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.

</details>


### [3] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: 本文提出CTHA架构以修正多时间尺度系统中的协调稳定性问题，实验证实其显著超越现有方法，在效率与鲁棒性上均具备优势。


<details>
  <summary>Details</summary>
Motivation: 当前多时间尺度的智能体架构虽提升了性能，但同时导致了协调稳定性下降，出现层间冲突、错误传播和可扩展性受限等问题。

Method: 提出了受约束的时序层次架构（CTHA），通过将层间通信限制在结构化流形上，并设计裁决机制，协调各层决策。具体包括三大约束：消息合同约束（规范信息流）、权限流形约束（限定决策空间）、裁决消解约束（冲突消解）。

Result: CTHA在复杂任务执行中，比无约束层级基线表现更优，降低47%故障连锁，提高2.3倍样本效率，并具有更佳可扩展性。

Conclusion: 受约束时序层次架构可提升多智能体协同与系统健壮性，对多层次自主系统发展具有指导意义。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [4] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: 该论文提出以长期记忆驱动的具身探索和学习框架，实现具身体智能体的主动探索与追忆能力提升。


<details>
  <summary>Details</summary>
Motivation: 当前主流具身任务重结果，忽略探索与记忆利用过程，限制长期复杂任务中的学习能力。因此提出结合长期记忆和探索以促进智能体终身学习。

Method: 通过强化学习微调多模态大语言模型，结合多任务奖励函数（动作预测、前沿选择、问答），提升智能体主动记忆检索与探索能力，并构建LMEE-Bench用于综合评测。

Result: 提出的MemoryExplorer在包含多目标导航与基于记忆的问答任务中，实现了更优的探索效率和任务完成率。

Conclusion: 所提方法MemoryExplorer在长时序具身任务上实现了显著性能提升，优于现有主流模型。

Abstract: An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.

</details>


### [5] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 本文基于启发式规则，以趋势为量化指标，提出创新过程建模方法，通过转移图展现系统的各种可能行为路径。


<details>
  <summary>Details</summary>
Motivation: 现有的复杂产品创新过程难以建模，传统方法多依赖数值或粗略集合，信息需求高。本文旨在提出一种基于启发式的建模方法，以简化对过程趋势的量化。

Method: 利用一组启发式规则，将创新过程中的关键变量趋势（递增、递减或保持不变）作为建模基础。通过构建趋势模型，生成包含状态场景及相互转移关系的转移图，描述系统演化路径。

Result: 提出了一种仅依赖趋势（递增、递减、保持不变）作为信息量极低量化指标的建模框架，实现了复杂创新过程的系统行为描述。

Conclusion: 该方法能以较低信息要求有效建模复杂产品创新过程，并可用转移图路径展现系统历史和未来的全部可能行为。

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [6] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 在固定模型和训练协议下，精确的难度型样本选择优于传统的多样性或扩充策略，是提升多模态推理性能的关键。


<details>
  <summary>Details</summary>
Motivation: 对多模态推理任务，现有研究主要关注模型优化，本研究通过NeurIPS DCVLR挑战专注于数据集选择，探究如何通过高效数据策划提升性能。

Method: 挑战赛固定模型与训练方案，仅聚焦数据策划策略。提出并评估了以难度为主的样本选择方法，并与增加数据量、多样性、合成增强等传统策略进行对比消融分析。

Result: 通过以Walton Multimodal Cold Start为主源构建精简的数据集，论文在比赛中取得第一。消融实验发现，基于难度的样本选择是性能提升的核心；增加数据量并不显著提升平均准确率，只降低了结果的波动；常用的多样性和合成增强方法无效甚至负面影响。

Conclusion: DCVLR属于饱和评估场景，数据对齐和样本难度优先于规模和多样性，是数据高效多模态推理的核心。

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [7] [Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics](https://arxiv.org/abs/2601.11012)
*Jiahao Wang,Shuangjia Zheng*

Main category: cs.AI

TL;DR: HADES通过结构感知采样与贝叶斯优化，有效提升蛋白序列设计性能，实现结构与功能的协同优化，实验表现领先，代码开放。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白序列优化受限于序列空间复杂度（如表型易位效应）和未能考虑三维结构约束，亟需整合结构信息的新优化方式。

Method: 提出基于Hamiltonian动力学的贝叶斯优化方法HADES，结合结构感知后验采样及位置离散化过程，辅以两阶段编码-解码框架学习结构-功能关系，并在体外进行实验验证。

Result: HADES在多项指标上均优于主流方法，能有效实现结构与性质的双重优化，促进蛋白设计。

Conclusion: HADES方法能高效设计结构受限且性质优化的蛋白序列，优于现有方法。

Abstract: The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.

</details>


### [8] [BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search](https://arxiv.org/abs/2601.11037)
*Shiyu Liu,Yongjing Yin,Jianhao Yan,Yunbo Tang,Qinggang Zhang,Bei Li,Xin Chen,Jingang Wang,Xunliang Cai,Jinsong Su*

Main category: cs.AI

TL;DR: BAPO方法显著提升了RL-agent在知识边界处承认"I DON'T KNOW"的能力，降低了不可靠答案的风险，同时保持了问题求解精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的agentic search增强了大型语言模型（LLM）的复杂问题求解能力，但缺乏合理的边界感知，往往在缺乏充分证据或推理力达到极限时无法承认"I DON'T KNOW"，导致极易生成似是而非但不可信的答案，带来实际应用风险。

Method: 提出了Boundary-Aware Policy Optimization（BAPO）强化学习框架，引入基于群体的边界感知奖励以及自适应奖励调节器，用以提升RL-agent能在推理极限时恰当地表达"I DON'T KNOW"，而非强行给出不可靠答案。

Result: 在四项基准测试上，BAPO明显提高了RL-agent在agentic search中的整体可靠性。

Conclusion: 通过引入边界感知奖励和合理调控，BAPO有效提升了agent在面对未知或证据不足时的自我约束能力，为RL驱动的复杂问题求解带来了更高的可靠性，对实际应用具有重要意义。

Abstract: RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search.

</details>


### [9] [AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts](https://arxiv.org/abs/2601.11044)
*Keyu Li,Junhao Shi,Yang Xiao,Mohan Jiang,Jie Sun,Yunze Wu,Shijie Xia,Xiaojie Cai,Tianze Xu,Weiye Si,Wenjie Li,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 该论文提出了AgencyBench，一个针对多维智能体能力的全面基准，用于评估大语言模型驱动的自主智能体在真实场景中的表现，突破了现有仅关注单一能力和人工反馈瓶颈的局限。


<details>
  <summary>Details</summary>
Motivation: 现有智能体评估标准局限于单一能力，且严重依赖人工反馈，无法扩展和自动评估，难以反映实际复杂场景中模型的综合表现。提出AgencyBench旨在填补这一空白、推进智能体评估自动化和全面性。

Method: 作者构建了AgencyBench基准，涵盖6个核心智能体能力、32个场景、138项任务，引入用户模拟智能体进行自动化反馈、设计Docker沙箱进行视觉与功能评测，并通过不同模型在其中的实验对比分析性能与资源利用。

Result: 实验发现封闭源模型成绩显著优于开源模型（48.4% vs 32.1%），不同模型在资源效率、自我纠错和工具使用偏好方面差异明显；封闭源模型在其原生生态下表现突出，开源模型受执行框架影响较大。

Conclusion: AgencyBench显示，封闭源模型在多智能体评估中表现优于开源模型，并指出模型与智能体框架需要协同优化，为未来自主智能体的研究方向提供参考。

Abstract: Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AgencyBench, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench.

</details>


### [10] [MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting](https://arxiv.org/abs/2601.11089)
*Suhan Guo,Jiahong Deng,Furao Shen*

Main category: cs.AI

TL;DR: 本文提出MiCA模块，有效融合流动信息提升流行病预测性能，兼顾轻量性与准确性，实验结果优越。


<details>
  <summary>Details</summary>
Motivation: 流行病预测需要考虑人群流动的影响，但现有的流动数据噪声大、难与病例数据结合，且数据量有限，限制了参数复杂的流动感知模型的应用。为兼顾准确性与轻量性，迫切需要新的模型方法。

Method: 提出Mobility-Informed Causal Adapter（MiCA）模块，通过因果发现推断流动关系，并通过门控残差混合将其集成到时序预测模型中，提升对流动结构的建模能力，同时适应噪声大、数据有限的实际情形。

Result: 在COVID-19发病、COVID-19死亡、流感和登革热等数据集上的实验表明，MiCA平均相对误差降低7.5%，并与当前主流的时空模型达成了竞争性性能。

Conclusion: MiCA在多个真实流行病数据集上显著提升了轻量级时序预测模型的表现，在保持轻量性的同时，性能达到了与现有先进时空模型相当的水平。

Abstract: Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility plays a central role in shaping the spatial spread of epidemics, but mobility data are noisy, indirect, and difficult to integrate reliably with disease records. Meanwhile, epidemic case time series are typically short and reported at coarse temporal resolution. These conditions limit the effectiveness of parameter-heavy mobility-aware forecasters that rely on clean and abundant data. In this work, we propose the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to selectively exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components such as graph neural networks or full attention. Extensive experiments on four real-world epidemic datasets, including COVID-19 incidence, COVID-19 mortality, influenza, and dengue, show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5\% across forecasting horizons. Moreover, MiCA attains performance competitive with SOTA spatio-temporal models while remaining lightweight.

</details>


### [11] [ReCreate: Reasoning and Creating Domain Agents Driven by Experience](https://arxiv.org/abs/2601.11100)
*Zhezheng Hao,Hong Wang,Jian Luo,Jianqing Zhang,Yuyan Zhou,Qiang Lin,Can Wang,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: 本论文提出了ReCreate框架，利用大模型的交互历史经验自动生成和改进领域智能体，相较现有方法提升了效果和效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型智能体的生成多需人工设计，自动化生成依赖黑盒优化，未能高效利用经验信息，导致资源消耗大、改进瓶颈明显，亟需更智能且具备解释性的自动生成框架。

Method: 方法包括：①存储与检索智能体交互经验机制；②将经验转化为智能体结构修改的关联管道（reasoning-creating synergy pipeline）；③通过分层泛化提取可复用的领域知识模式。通过系统性地利用经验数据，指导智能体持续优化。

Result: 实验证明，ReCreate在多个真实域任务中，均显著优于人工设计和主流自动化智能体生成方法，且即便初始资源有限（仅有极少种子结构），也能快速实现优异表现。

Conclusion: ReCreate框架可自动且高效地创建和适应各领域智能体，效果显著优于人工设计和现有自动化方法，具有较强通用性和扩展性。

Abstract: Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.

</details>


### [12] [Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems](https://arxiv.org/abs/2601.11147)
*Zixu Wang,Bingbing Xu,Yige Yuan,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: 该论文针对大型语言模型驱动的多智能体系统中，生成和评估多智能体协作流程的成本与效果问题进行了研究，提出了低成本的任务级别生成与评估框架SCALE，实现了接近于现有方法的性能但大幅降低了算力消耗。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统中，流程生成与评估存在极高的token成本与可靠性问题，尤其是任务级与查询级流程生成效费比不明。本研究旨在探索更省资源、可扩展的方法简化流程生成评估。

Method: 论文提出了SCALE方法，通过自预测与少量校准实现任务级别多智能体流程的生成和评估，摒弃了高成本的全面执行式验证。该方法受自我进化与生成式奖励建模启发，主张利用最佳若干任务级方案覆盖大部分查询，无需针对每个查询单独生成流程。

Result: SCALE在多个数据集上相较现有方法，性能损失极小（0.61%），但整体算力开销下降可达83%，验证了其高效性和实用价值。

Conclusion: SCALE框架显著减少了token消耗（最高83%），性能仅略有下降（平均0.61%），为多智能体系统任务流程生成与评估提供了更高效的解决方案。

Abstract: Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \textbf{SCALE}, which means \underline{\textbf{S}}elf prediction of the optimizer with few shot \underline{\textbf{CAL}}ibration for \underline{\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\%.

</details>


### [13] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: 本文提出了TANDEM框架，通过结构化推理和跨模态强化学习方法提升了多模态长内容中的仇恨检测的可解释性和性能，实现在目标识别和时间定位上的显著提升。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的长格式多模态内容日益增多，现有自动化系统虽然能高效识别仇恨言论，但缺乏细粒度、可解释证据，难以满足人工审核需求。因此亟需一种可解释且性能优异的多模态内容识别方法。

Method: 方法上，TANDEM将音视频仇恨检测由简单的二分类升级为结构化推理任务，引入了视觉-语言和音频-语言模型的协同强化学习机制，利用自约束的跨模态上下文稳定长期序列中的推理，无需密集帧级监督。通过三个基准数据集进行实验验证。

Result: 在HateMM数据集的目标识别任务上，TANDEM获得了0.73的F1分数，比现有方法提升了30%，同时在时间定位上也保证了高精度。零样本和上下文增强基线均被显著超越。但在多类别区分（如侮辱与仇恨内容）方面仍存在标签歧义与数据不均衡问题。

Conclusion: TANDEM显著提升了多模态仇恨内容的目标识别和时间定位的准确率，为实现更透明和可操作的内容安全审核工具提供了新思路。该框架证实在复杂多模态环境下实现可解释对齐是可行的。

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [14] [Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning](https://arxiv.org/abs/2601.11252)
*Qianyue Wang,Jinwu Hu,Yufeng Wang,Huanxiang Lin,Bolin Chen,Zhiquan Wen,Yaofo Chen,Mingkui Tan*

Main category: cs.AI

TL;DR: 提出Think-with-Me交互式推理范式，在合适节点引入外部反馈显著提升LRM推理效率与准确率，获得实证上的优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有LRMs在多步推理时常因过度推理或方向偏离而导致计算成本高与性能下降，传统闭环高效推理方法缺乏外部干预机制。

Method: 提出了一种新型测试时交互式推理范式，通过在推理时加入外部反馈干预，利用转折词作为干预点，结合多标准评估（合理性与完整性），并通过GRPO训练模型以适应该模式。

Result: Think-with-Me在AIME24上比QwQ-32B提升了7.19%准确率，并在8K窗口下将平均推理长度减少了81%；同时在安全与创新任务上也表现出优势。

Conclusion: Think-with-Me显著提高了LRMs的推理效率和准确率，在受限上下文窗口下达到了更优的推理长度和性能平衡。

Abstract: Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.

</details>


### [15] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: 提出XChoice机制模型，用于AI与人类决策对齐的解释性评估，揭示不同群体间存在对齐差异，并通过RAG改善。


<details>
  <summary>Details</summary>
Motivation: 现有AI-人类对齐评估主要关注结果一致性，缺乏对决策机制层面一致性的解释性衡量手段，急需更深入诊断和改进AI对齐质量的方法。

Method: 通过机制模型拟合AI/人类决策数据，参数化决策规则，并对模型、选项和子群体间的参数向量进行比较，辅以不变性分析和RAG干预评估。

Result: 本文提出了XChoice框架，一种用于评估AI与人类在受限决策任务中的对齐方式。该方法不仅关注决策结果的一致性（如准确率、F1分数），而且通过拟合基于机制的决策模型，提取可解释参数（如决策因素权重、对约束的敏感性与权衡）。论文采用美国时间使用调查（ATUS）数据作为人类对照基准，对每日时间分配的AI与人类对齐进行实证分析，发现不同模型、活动及子群体间对齐程度异质，黑人及已婚群体中存在显著错配。框架还包括稳健性验证和RAG干预的效果评估，综合提供机制层面的对齐衡量与改进建议。

Conclusion: XChoice能够诊断AI-人类决策机制的错配，为超越结果一致性、实现机制一致提供指导，有助于发现和定向改进AI模型的对齐问题。

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [16] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 提出了一个针对空间规划问题的新基准 AstroReason-Bench，结果发现，主流通用 agentic LLM 在现实物理约束场景下远逊于专业工具，这为未来相关领域研究提供了有力诊断工具。


<details>
  <summary>Details</summary>
Motivation: 当前针对 agentic LLM 的基准测试多聚焦于符号或弱物理约束环境，缺乏在严格物理约束、现实高风险任务中的评测，亟需拓展至复杂现实场景以诊断其实际能力与局限。

Method: 提出了 AstroReason-Bench 基准，涵盖多种调度情境，为空间规划问题设定统一的 agent 交互协议，并对多种主流 agentic LLM 系统进行了性能评估。

Result: 在 AstroReason-Bench 上，多种开源和闭源 agentic LLM 系统均表现不佳，远低于专业解算器水平。该基准揭示了通用 LLM 在长周期、物理约束复杂任务中存在的不足。

Conclusion: 现有的通用型 agentic LLM 在面对具有严格物理约束的空间规划问题时，性能明显逊于专业解算器，暴露了其在现实约束下的关键局限性。

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [17] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: 提出了一种自动超参数优化机制（probe and solve algorithm），在多实例测试中，贝叶斯优化显著优于默认配置与局部搜索，提升了多泛化场景下的解质量。


<details>
  <summary>Details</summary>
Motivation: 约束规划求解器的性能对超参数选择高度敏感，手动调参耗时且依赖专家，亟需自动化高效的优化技术。

Method: 提出了probe and solve算法，在CPMpy库中实现，分为探测（超参数优化）和求解两个阶段。探测阶段采用贝叶斯优化和汉明距离搜索两种方法。

Result: 贝叶斯优化在ACE求解器上提升了25.4%的实例结果，并在57.9%的实例上保持性能；在Choco上提升了38.6%的实例。贝叶斯优化明显优于汉明距离搜索。

Conclusion: probe and solve算法为约束求解器提供了一种高效、自动、资源感知的超参数优化方案，在实际问题中取得了稳定的性能提升。

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [18] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: 提出并实证验证了LLM在过程监控中对不同KPI的优越预测能力，尤其在数据稀缺场景下优于传统方法，且其推理能力超越了普通机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 为提升过程挖掘中在数据稀缺情况下的预测效果，并探究LLM能否通过其先验知识和推理能力，提升过程监控的泛化性与解释性。

Method: 基于大型语言模型，通过prompting进行预测，将方法拓展至对多种KPI（如总时间、活动发生）的预测能力，结合多组事件日志进行实证评测，并深入剖析模型的推理机制。

Result: 本文研究了基于大型语言模型（LLM）的预测过程监控方法，重点在于总时间预测的基础上，拓展评估其通用性、语义利用能力、推理机制，并扩展到多个关键绩效指标（KPI）领域。实证分析基于三组不同的事件日志，涵盖总时间和活动发生等KPI任务，结果显示在数据稀缺（仅100条轨迹）情况下，LLM优于现有基线方法。进一步分析显示，LLM不仅利用了其内在的先验知识与训练数据间的相关性，还展现出高阶推理能力，超越了现有预测方法的简单复现。

Conclusion: LLM在预测过程监控任务中具有较强的通用性和逻辑推理能力，特别是在数据不足时优于传统方法，并能利用自身丰富的语义知识与高阶推理进行精准预测。

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [19] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: 提出人机融合LEG框架，结合大模型理解专家意图与优化算法，优选卫生站升级名单，兼顾理论覆盖与实际需求，实测表现优异。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的情况下，既保证升级卫生设施覆盖最大人口，同时充分考虑来自不同专家与利益相关方的多样化主观偏好。传统优化方法只能处理量化目标，难以整合人类专业直觉。

Method: 提出了LEG（Large language model and Extended Greedy）框架，将优化算法与大模型驱动的人机迭代结合，实现城乡卫生站选址升级的最优覆盖与专家知识融合决策。

Result: 在埃塞俄比亚三个区域真实数据上的实验证明，该框架既能保证最优或近似最优的人口覆盖，又能有效反映专家和利益相关方的意愿，实现人机联合优化选址方案。

Conclusion: LEG框架为公共卫生基础设施提升提供了可复用、可推广的科学决策工具，实现了理论最优与实际偏好有机结合，助力实现更公平、高效的数据驱动卫生健康规划。

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


### [20] [BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics](https://arxiv.org/abs/2601.11492)
*Kaiwen Wang,Kaili Zheng,Rongrong Deng,Qingmin Fan,Milin Zhang,Zongrui Li,Xuesi Zhou,Bo Han,Liren Chen,Chenyi Guo,Ji Wu*

Main category: cs.AI

TL;DR: BoxMind通过精细分解拳击动作、融合显式和隐式战术特征，以图模型进行预测和推荐，实现了同人类专家相当的战术建议，并助力中国队在奥运取得突破。


<details>
  <summary>Details</summary>
Motivation: 现有的竞技体育战术分析中，格斗类项目（如拳击）的AI分析受限于动作复杂、缺乏结构化的战术表示，发展滞后。

Method: 定义原子级拳击事件及18项分层技战术指标，构建图结构预测模型，融合显式技战术特征与深度可学习时变隐变量；将比赛结果建模为技战术指标的可微函数，通过梯度指导战术调整。

Result: 提出的BoxMind系统在BoxerGraph测试集上达到了69.8%准确率，在奥运比赛上达到了87.5%准确率。系统在2024年巴黎奥运会期间的闭环部署，直接推动中国国家队取得3金2银的历史性成绩。

Conclusion: BoxMind可实现从非结构化视频到可执行战术策略的转化，奠定了格斗类运动AI分析和决策支持的新范式。

Abstract: Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.

</details>
