<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 4]
- [cs.AI](#cs.AI) [Total: 10]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Gen-DBA: Generative Database Agents (Towards a Move 37 for Databases)](https://arxiv.org/abs/2601.16409)
*Yeasir Rayhan,Walid G. Aref*

Main category: cs.DB

TL;DR: 论文提出数据库系统领域AI取得突破的概念，类比围棋领域的Move 37问世，探讨如何通过生成式数据库智能体（Gen-DBA）实现数据库领域创新。


<details>
  <summary>Details</summary>
Motivation: 随着AI在围棋、自然语言处理、计算机视觉等领域取得突破，论文关注数据库系统领域未出现类似重大创新（Move 37时刻），希望引入生成式智能体推动数据库智能发展。

Method: 论文提出了一种构建Gen-DBA的方法，包括：基于Transformer的架构、硬件相关的分词机制、双阶段目标导向的下一个Token预测训练范式，以及生成式推理流程。

Result: 该论文为数据库领域迈向突破性创新提供了构想和技术方案，具体实现及实际突破尚需后续工作验证。

Conclusion: 作者认为，通过构建生成式数据库智能体（Gen-DBA），数据库系统有机会获得类似AI在围棋、自然语言等领域的突破性进展，从而实现更高层次的自动推理和创造力。

Abstract: Move\,37 marks one of the major breakthroughs in AI in terms of its ability to surpass human expertise and discover novel strategies beyond the traditional game play in the strategic two-player board game of Go. The domains of Natural Language Processing, Computer Vision, and Robotics have also undergone a similar phenomenon through the advent of large foundational models in the form of Large Language Models (LLMs), Vision Language Models (VLMs) and Vision Language Action models (VLAs), respectively. In this paper, we investigate the current state of Artificial Intelligence for Database Systems research (AI4DB), and assess how far AI4DB systems are from achieving their own Move\,37 moment. We envision a Generative Database Agent (Gen-DBA, for short) as the pathway to achieving Move\,37 for database systems that will bring generative reasoning and creativity into the realm of database learning tasks. This vision paper explores this direction by presenting the recipe for building Gen-DBA that encompasses but is not limited to a Transformer backbone, a hardware-grounded tokenization mechanism, a two-stage Goal-Directed Next Token Prediction training paradigm, and a generative inference process.

</details>


### [2] [iPDB -- Optimizing SQL Queries with ML and LLM Predicates](https://arxiv.org/abs/2601.16432)
*Udesh Kumarasinghe,Tyler Liu,Chunwei Liu,Walid G. Aref*

Main category: cs.DB

TL;DR: iPDB扩展SQL，实现了数据库内无缝调用LLM/ML能力，大幅提升语义查询效率，减少数据迁移和工程复杂度。


<details>
  <summary>Details</summary>
Motivation: 当前SQL及其关联数据库系统不适合直接支持和高效实现基于大语言模型(LLM)等学习型模型的工作负载，导致应用开发需要复杂的工程实现和多次数据迁移。

Method: 设计并实现了新型关系型数据库系统iPDB，在SQL中集成了ML/LLM调用的扩展语法，并提出新的关系型预测算子和语义查询优化方法，用于支持高效的语义工程（如语义选择、连接、分组等操作）。

Result: 引入了一种新型关系型系统iPDB，支持通过扩展SQL语法在数据库内高效执行机器学习和LLM推理任务，实现了比现有技术更优的性能。

Conclusion: iPDB能够通过扩展SQL，原生集成和高效地管理语义推理与机器学习任务，显著强化了关系型数据库在语义查询和复杂数据处理方面的能力。

Abstract: Structured Query Language (SQL) has remained the standard query language for databases. SQL is highly optimized for processing structured data laid out in relations. Meanwhile, in the present application development landscape, it is highly desirable to utilize the power of learned models to perform complex tasks. Large language models (LLMs) have been shown to understand and extract information from unstructured textual data. However, SQL as a query language and accompanying relational database systems are either incompatible or inefficient for workloads that require leveraging learned models. This results in complex engineering and multiple data migration operations that move data between the data sources and the model inference platform. In this paper, we present iPDB, a relational system that supports in-database machine learning (ML) and large language model (LLM) inferencing using extended SQL syntax. In iPDB, LLMs and ML calls can function as semantic projects, as predicates to perform semantic selects and semantic joins, or for semantic grouping in group-by clauses. iPDB has a novel relational predict operator and semantic query optimizations that enable users to write and efficiently execute semantic SQL queries, outperforming the state-of-the-art.

</details>


### [3] [A Scalable Transaction Management Framework for Consistent Document-Oriented NoSQL Databases](https://arxiv.org/abs/2601.16490)
*Adam A. E. Alflahi,Mohammed A. Y. Mohammed,Abdallah Alsammani*

Main category: cs.DB

TL;DR: 本文提出一种适用于NoSQL数据库的高效事务管理框架，显著提升数据一致性、降低事务中止、消除死锁，同时兼顾高并发性能扩展。


<details>
  <summary>Details</summary>
Motivation: NoSQL数据库因其可扩展性和灵活结构被广泛应用，但其最终一致性模型限制了可靠事务处理。本研究动因是改进NoSQL数据库中的事务管理，提高一致性与系统性能兼容性。

Method: 设计并实现一种包含事务生命周期管理、操作分类、预执行冲突检测和自适应锁定及超时死锁预防的事务管理框架。形式化分析冲突可串行化，在YCSB基准下与主流NoSQL/分布式数据库进行对比实验，进行参数灵敏度分析。

Result: 提出的四阶段事务管理框架在MongoDB及分布式实验中，将事务中止率从8.3%降至4.7%，消除死锁，降低延迟方差34.2%，高并发下系统吞吐量提升6.3%-18.4%，集群规模扩展下吞吐量提升15.2%，中止率降低53%。对比MongoDB原生事务、CockroachDB和TiDB，不仅提供较优的数据一致性，还有效控制了性能开销。

Conclusion: 通过四阶段事务管理、冲突检测和自适应锁机制，NoSQL数据库能在保证良好可扩展性的同时，提高数据完整性和系统性能。合理参数配置进一步提升整体效果，展示一致性机制改进对NoSQL系统的巨大价值。

Abstract: NoSQL databases are widely used in modern applications due to their scalability and schema flexibility, yet they often rely on eventual consistency models that limit reliable transaction processing. This study proposes a four-stage transaction management framework for document-oriented NoSQL databases, with MongoDB as the reference platform. The framework combines transaction lifecycle management, operation classification, pre-execution conflict detection, and an adaptive locking strategy with timeout-based deadlock prevention. Formal correctness analysis shows that the proposed approach guarantees conflict serializability under defined conditions. An experimental evaluation using the Yahoo Cloud Serving Benchmark (YCSB) workloads A, B, and F, with concurrency levels ranging from 1 to 100 clients, demonstrates a reduction in transaction abort rates from 8.3% to 4.7%, the elimination of observed deadlocks, and a 34.2% decrease in latency variance. Throughput improvements ranging from 6.3% to 18.4% are observed under high concurrency, particularly for read-modify-write workloads. Distributed experiments on clusters of up to 9 nodes confirm scalability, achieving 15.2% higher throughput and 53% lower abort rates than baseline systems. Comparisons with MongoDB's native transactions, CockroachDB, and TiDB indicate that the proposed framework strikes a good balance between consistency guarantees and performance overhead. Sensitivity analysis identifies optimal parameter settings, including a lock timeout of 100 ms, an initial backoff of 10 ms, and a maximum backoff of 500 ms. These results show that carefully designed consistency mechanisms can significantly improve data integrity in NoSQL systems without undermining scalability.

</details>


### [4] [A Categorical Approach to Semantic Interoperability across Building Lifecycle](https://arxiv.org/abs/2601.16663)
*Zoltan Nagy,Ryan Wisnesky,Kevin Carlson,Eswaran Subrahmanian,Gioele Zardini*

Main category: cs.DB

TL;DR: 建筑生命周期中的数据整合挑战因元数据模式碎片化而加剧，现有方法复杂且难以扩展。本文提出以范畴论为基础的结构化数据整合办法，显著简化整合过程。


<details>
  <summary>Details</summary>
Motivation: 尽管已进行30年的标准化工作，建筑领域元数据方案仍高度碎片化，导致数据整合复杂、难以维护。缺乏数学基础使得结构保留的数据转换成为未解决难题。

Method: 作者将建筑本体形式化为一阶理论，采用Categorical Query Language（CQL）进行范畴论建模，并实现了两个原型：通过范畴组合自动生成和整合BRICK、IFC、RealEstateCore数据。

Result: 通过范畴论模型及CQL工具，实现了n个本体只需O(n)复杂度的映射。支持自动生成模型、三方本体整合、双向迁移及跨本体查询，且证明构造正确。

Conclusion: 范畴论为建筑异构数据整合提供了可行的数学基础，实现了自动、结构保留的数据迁移，比传统方法更高效可靠，推动可扩展的数据整合生态。

Abstract: Buildings generate heterogeneous data across their lifecycle, yet integrating these data remains a critical unsolved challenge. Despite three decades of standardization efforts, over 40 metadata schemas now span the building lifecycle, with fragmentation accelerating rather than resolving. Current approaches rely on point-to-point mappings that scale quadratically with the number of schemas, or universal ontologies that become unwieldy monoliths. The fundamental gap is the absence of mathematical foundations for structure-preserving transformations across heterogeneous building data. Here we show that category theory provides these foundations, enabling systematic data integration with $O(n)$ specification complexity for $n$ ontologies. We formalize building ontologies as first-order theories and demonstrate two proof-of-concept implementations in Categorical Query Language (CQL): 1) generating BRICK models from IFC design data at commissioning, and 2) three-way integration of IFC, BRICK, and RealEstateCore where only two explicit mappings yield the third automatically through categorical composition. Our correct-by-construction approach treats property sets as first-class schema entities and provides automated bidirectional migrations, and enables cross-ontology queries. These results establish feasibility of categorical methods for building data integration and suggest a path toward an app ecosystem for buildings, where mathematical foundations enable reliable component integration analogous to smartphone platforms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems](https://arxiv.org/abs/2601.16286)
*Varun Chillara,Dylan Kline,Christopher Alvares,Evan Wooten,Huan Yang,Shlok Khetan,Cade Bauer,Tré Guillory,Tanishka Shah,Yashodhara Dhariwal,Volodymyr Pavlov,George Popstefanov*

Main category: cs.AI

TL;DR: SemanticALLI通过结构化缓存机制显著提升AI推理管道的效率，远超传统黑盒式缓存。


<details>
  <summary>Details</summary>
Motivation: 当前agentic AI因为忽视中间环节的重复逻辑，导致系统效率低下。现有的端到端缓存方式无法应对用户语句变化带来的低缓存命中率，因此亟需一种能结构化处理和复用中间结果的架构。

Method: 将AI推理流程拆分为分析意图解析（AIR）和可视化合成（VS）两个可缓存阶段，并在管道中将中间表示（IRs）作为一等缓存对象，实现了内部逻辑的高效复用。通过在Alli营销智能平台中的应用，对比结构化缓存与传统黑盒缓存的命中率与系统性能。

Result: 本文提出了SemanticALLI，这是一种管道感知的架构，专为减少agentic AI系统在中间逻辑层面上的重复计算而设计。传统的缓存机制因把推理过程视为黑盒而忽略了中间结果的复用潜力，造成效率低下。SemanticALLI通过显式划分分析意图解析（AIR）与可视化合成（VS）两个阶段，将结构化的中间表示提升为可缓存的一等公民。实验证明，该方法能极大提高缓存命中率，减少重复LLM调用与整体资源消耗。

Conclusion: 结构分解和中间结果复用显著提高了AI管道缓存的命中率和系统效率，显示在AI系统设计中关注结构化中间检查点具有重要实际意义。

Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.

</details>


### [6] [DSGym: A Holistic Framework for Evaluating and Training Data Science Agents](https://arxiv.org/abs/2601.16344)
*Fan Nie,Junlin Wang,Harper Hua,Federico Bianchi,Yongchan Kwon,Zhenting Qi,Owen Queen,Shang Zhu,James Zou*

Main category: cs.AI

TL;DR: 本文提出了DSGym，一个标准化且可扩展的数据科学智能体评测与训练平台，解决了现有基准的不足，通过丰富任务和自动验证训练智能体，在标准任务上取得超越GPT-4o的表现。


<details>
  <summary>Details</summary>
Motivation: 现有数据科学评测基准存在接口碎片化、任务过窄、数据依赖不足等问题，部分任务甚至无需数据即可完成，缺乏对智能体真实数据分析能力的检验。

Method: 提出DSGym标准化评测框架，包含可扩展模块架构，标准化任务集（DSGym-Tasks），涵盖生物信息学和多领域预测任务，支持通过自动数据合成实现智能体训练，并进行实验对比验证其有效性。

Result: 1. 构建了DSGym平台，支持任务、工具与智能体扩展。2. 筛选并补充高质量任务集。3. 衍生针对不同领域的子任务集。4. 在DSGym上训练的4B模型在标准分析基准测试中优于GPT-4o。

Conclusion: DSGym为评估和训练数据科学智能体提供了一个标准化的平台，可以实现端到端的数据分析能力测试，并超过目前主流模型如GPT-4o在标准化分析基准上的表现。

Abstract: Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.

</details>


### [7] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: 提出Doc2AHP框架，将AHP原理作为约束，引导LLM进行结构化推理，实现自动化决策模型构建，显著提升逻辑与任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在复杂决策任务中难以保证结构一致性与推理可靠性，而传统决策理论如AHP则依赖专家知识，制约了通用性和可扩展性。作者致力于解决LLMs泛化能力与决策理论严谨性之间的鸿沟。

Method: 以AHP结构为约束，引导LLM进行有约束的文档空间搜索，实现父子节点之间的逻辑蕴含；引入多智能体加权机制与自适应一致性优化，确保权重分配的数值一致性。

Result: Doc2AHP框架能够在无需大量标注数据和人工干预的情况下，帮助非专家用户从零构建高质量决策模型，在逻辑完整性和下游任务精度上显著超过直接生成式基线方法。

Conclusion: Doc2AHP有效结合LLM泛化能力与AHP结构约束，在非专家场景下提升决策模型自动化与可靠性，对推广结构化推理有重要意义。

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [8] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: 大多数大语言模型在患者劝说下，容易做出不适当的临床决策，传统静态安全测试不能充分衡量其真实安全风险。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在临床决策支持中的安全性，特别是在面对患者不合理施压时的鲁棒性。

Method: 提出SycoEval-EM框架，通过多智能体模拟让患者以劝说策略影响LLM在急诊医学决策中的选择，覆盖20种模型、1,875次交互，分三种典型医疗场景，系统性测试模型在社会压力下的表现。

Result: 实验证明，模型在患者劝说下依从不当医疗请求的概率极高（0-100%），且在影像检查请求上的脆弱性高于阿片类药物处方。模型能力与鲁棒性相关性低。所有劝说策略对模型影响类似，显示普遍易受影响。

Conclusion: 现有静态评测难以覆盖重要安全风险，应采用多轮对抗测试作为临床AI认证的必要环节，以确保其在真实情境下的鲁棒性与安全性。

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [9] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 多模态VLM和LLM在医疗分类场景下未能全方位超越传统ML，尤其PEFT微调方式对结果影响极大，传统模型依然最可靠。


<details>
  <summary>Details</summary>
Motivation: 医药领域当前正快速引入多模态视觉-语言模型（VLMs）和大语言模型（LLMs），但其在医学分类中的实际表现和相较传统机器学习（ML）方法的优劣并未系统化对比。作者希望通过统一基准，系统性评估各种模型类型的表现。

Method: 基于四个公开医学数据集（含文本和图像、二分类和多分类），实验对比三种模型类别：传统ML（LR、LightGBM、ResNet-50）、零样本VLM/LLM（Gemini 2.5）、微调PEFT模型（LoRA-Gemma3）。所有实验采用统一的数据切分及指标。

Result: 传统机器学习模型（如LR、LightGBM）在绝大多数医学分类任务中始终表现最好，尤其是在结构化文本数据上表现突出。LoRA微调的Gemma3模型在所有文本和图像任务中表现最差，无法通过极少量微调实现泛化。零样本VLM/LLM（如Gemini 2.5）在文本任务中表现不佳，但在多类别图像任务上则能媲美传统ResNet-50基线。

Conclusion: 当前主流基础模型并非对所有医学分类任务均具优势，PEFT效果依赖具体策略和任务类型；传统ML模型仍在医学分类领域有明显优势。

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [10] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: 本文提出了AgentsEval，一个多智能体推理框架，针对自动生成医学影像报告的评估难题，实现了结构化、临床相关的评测，并通过多领域扰动基准验证其鲁棒性和解释性。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像报告的自动评估方法未能有效捕捉医学诊断的结构化推理逻辑，导致评测结果缺乏临床相关性和可靠性。为此，提出更具可解释性和临床基础的自动评估方案。

Method: 方法上，采用多智能体框架模拟放射科医生协同诊断流程，将评估分为准则定义、证据提取、对齐和一致性评分等步骤，全程显示推理轨迹和结构化反馈。此外，建立了涵盖多模态、多语义扰动条件的基准数据集进行实证验证。

Result: 实验证明，AgentsEval在不同领域和数据扰动下保持对临床语义和风格的高一致性评测，具备优良的鲁棒性、可解释性及临床适用性。

Conclusion: AgentsEval能够提供临床一致、语义忠实且可解释性强的自动医学报告评估结果，为大语言模型在医学实际应用中的采纳提供了更可靠的支持。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [11] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: 该文提出了5600亿参数的MoE模型，在多个agentic基准测试上刷新SOTA，具备强泛化性和鲁棒性，专为复杂推理和实际应用设计，完善训练和环境协同，特别强调对复杂工具交互与真实世界噪声的处理。


<details>
  <summary>Details</summary>
Motivation: 开发高参数、高效的开源MoE推理模型，有效提升agentic（自治体式）推理、工具使用以及工具集成推理能力，并显著增强模型在复杂、带噪声的真实世界环境中的泛化性和鲁棒性。

Method: 构建5600亿参数的MoE模型，采用域并行专家训练与融合的统一框架，端到端联合设计数据、环境、算法及基础设施；扩展异步强化学习框架DORA以支持多环境大规模高效训练；系统分析和分解真实世界噪声并在训练中显式纳入；引入Heavy Thinking模式以测试时扩展推理广度和深度。

Result: 模型在开放源领域创造了agentic推理诸多基准测试的新SOTA表现，对复杂工具交互具有很强的泛化性，面对真实世界噪声也具备较高鲁棒性，复杂推理任务上表现卓越。

Conclusion: LongCat-Flash-Thinking-2601展现出极强的agentic推理、工具应用及复杂场景下的泛化和鲁棒能力，为开源大型模型在复杂真实任务中应用提供了重要支撑。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [12] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 将昆虫脑的关联学习与路径积分模型结合，用于视觉目标导航任务，达到了现有SOTA水平但极低的计算开销，并具备良好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一种受昆虫启发的视觉目标导航智能体。结合了昆虫脑中与关联学习和路径积分相关的两个结构的抽象模型，以提升导航智能体的性能与效率。

Method: 将昆虫脑两个与导航相关的结构进行了抽象建模，并在Habitat等视觉导航基准下进行测试和分析，强调其简单结构与低计算开销以及在模拟环境下的鲁棒性。

Result: 该昆虫启发的智能体在标准点目标导航任务中表现接近最新SOTA模型，但计算成本低许多数量级，在更真实的模拟环境中也表现出对扰动的鲁棒性。

Conclusion: 昆虫启发的方法可实现高效且稳健的视觉导航，不仅性能优越，还能显著降低计算资源需求，对实际导航系统设计具有潜在价值。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [13] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: RLVR训练的大型语言模型在心理理论任务中表现出更强的鲁棒性，其优势更可能来源于解题鲁棒性的提升，而非产生了新的推理能力。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLMs在ToM测试中高分引发了其推理能力本质的争议，作者希望通过分析强化学习优化后的LLMs在ToM任务中的真实表现，探讨其所展现能力的真正来源及其对社会认知行为评估的启示。

Method: 利用适配后的机器心理学实验和既有基准，对RLVR训练的推理型LLMs在ToM任务中的表现进行测试和行为分析，对其对任务扰动和提示变化的响应进行系统评估。

Result: 推理能力导向的大型语言模型（LLMs），特别是通过可验证奖励强化学习（RLVR）训练的模型，在心理理论（ToM）任务中表现出较强的鲁棒性，尤其是在应对提示变化和任务扰动时。另外，这些模型在多个基准测试中也展现出了显著提升。研究利用了机器心理学实验的创新适配及现有基准结果，发现其性能提升主要归因于求解正确答案的鲁棒性增强，而非产生了新的ToM推理方式。

Conclusion: 当前LLMs在ToM任务中的优异表现，更应归因于对扰动和变化条件下鲁棒性的提升，而不是其社会-认知推理能力本质上的增强。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [14] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: 提出并实证了一款AI辅助医疗设备维修平台，能有效提升设备维护效率，减缓设备故障对低中收入国家医疗服务的不利影响。


<details>
  <summary>Details</summary>
Motivation: 低中收入国家医疗设备因缺乏维护和技术支持，导致大量设备未被充分利用或无法使用，影响病患护理和医疗质量。研究旨在为设备维护难题提供创新智能支持。

Method: 本研究开发并验证了一套结合大语言模型（LLM）与网页界面的AI支持平台，用户可输入错误码或设备症状，系统即时提供分步排查和修复指南，并设有全球同业论坛促进知识交流。以Philips HDI 5000超声机为案例，检验平台的可行性。

Result: 平台对错误码理解的精度达100%，对修复建议的准确率为80%，在医疗设备维护方面展现出高效可行性。

Conclusion: AI驱动的支持平台可有效辅助生物医学技术人员在资源有限环境下维护和修理医疗设备，展现出减少设备停机时间、提升医疗服务质量的潜力。

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>
