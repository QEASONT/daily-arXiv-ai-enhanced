<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Building AI Agents to Improve Job Referral Requests to Strangers](https://arxiv.org/abs/2601.10726)
*Ross Chu,Yuting Huang*

Main category: cs.AI

TL;DR: 本论文提出了AI智能体自动优化求职转介请求，通过RAG增强LLM显著提升预测成功率，改善弱请求且不影响强请求。


<details>
  <summary>Details</summary>
Motivation: 求职者在在线社区发送的转介请求普遍存在质量参差不齐的问题，影响其获得推荐机会。研究希望通过AI自动提升请求文本质量，显著提升弱请求的成功率。

Method: 提出了两类AI智能体：提升智能体（对请求文本进行改写）和评估智能体（采用预测转介概率的模型评估改写效果）；并引入RAG技术以增强LLM在生成内容时的相关性和质量。

Result: 结合RAG的LLM智能体，使转介请求质量较弱者的成功概率提升了14%，且不会对强请求造成负面影响。

Conclusion: 利用结合RAG的LLM智能体能够显著提升求职者在专业社交社区中转介请求的预测成功率，尤其是对原本较弱的请求，同时避免对强请求带来负面影响。

Abstract: This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.

</details>


### [2] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: 提出CTHA架构，通过三类约束恢复和增强分层多智能体系统的稳定性与扩展性，显著提升了复杂任务的完成效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 多时间尺度的智能体架构虽然提高了性能，但因此引入的分层结构破坏了原有的协调稳定性，导致层间冲突、错误扩散和可扩展性受限等问题。推进多智能体系统的稳定和高效协调需求驱动了本工作的产生。

Method: 提出了受约束的时间层次架构（Constrained Temporal Hierarchical Architecture，CTHA），通过将层间通信空间投影到结构化流形，并引入约束化仲裁机制，实现分层之间的协调和决策一致。CTHA包含三类关键约束：(1) 消息契约约束——用类型化摘要、计划和策略包规范层间信息流；(2) 权限流形约束——根据时间范围限制各层决策空间；(3) 仲裁分解约束——保证多层决策无冲突合成。

Result: 实验证明CTHA可有效完成大规模复杂任务，与无约束层次基线相比，失败级联减少47%，样本效率提升2.3倍且具备更优的可扩展性。

Conclusion: CTHA以严谨的理论原则扩展了时间层次架构，增强了多智能体系统的协调性和性能，有助于深入理解多智能体协调机制，并推动自主系统的稳健发展。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [3] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: 本文提出LMEE框架和MemoryExplorer方法，通过强化多模态大模型实现主动记忆查询，并在新构建的评测基准LMEE-Bench上取得优异结果。


<details>
  <summary>Details</summary>
Motivation: 现有主流的具身智能任务多以一次性任务完成度为目标，普遍忽视了探索过程和长期记忆利用，而理想的具身智能体应具备持续学习、长期策略优化能力以适应复杂环境。

Method: 提出长期记忆具身探索（LMEE）框架及配套基准LMEE-Bench，支持多目标导航与基于记忆的问答；提出MemoryExplorer方法，采用强化学习微调多模态大模型，通过多任务奖励函数引导智能体主动探索和记忆回溯。

Result: 所提方法在长时序具身智能任务中对比主流探索模型，展现了显著性能优势。

Conclusion: 本文验证了通过融合主动探索和记忆利用，可以提升具身智能体的长期任务性能，为构建终生学习型智能体提供了新的有效路径。

Abstract: An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.

</details>


### [4] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 该文提出用趋势建模和转移图描述产品创新过程，减少对具体数值依赖。


<details>
  <summary>Details</summary>
Motivation: 为避免在建模复杂产品创新过程时对具体数值或粗集信息的依赖，提出以趋势为量化手段构建模型，提高模型的通用性和可解释性。

Method: 采用以趋势为基础的启发式模型，并通过转移图方法描述状态及其间转移，揭示创新过程的多样性。

Result: 该论文利用启发式方法建模复杂产品创新过程，将每一启发式表达为简单趋势（增加、减少或恒定），以最小化对参数化信息的依赖。解决方案被定义为一组场景及其间可能的状态转移，并通过转移图加以表达。系统任何可能的过去或未来行为都可通过图中的路径呈现。

Conclusion: 通过趋势模型和转移图，可以全面刻画产品创新过程的多种可能演化路径，无需依赖复杂的参数或数值信息。

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [5] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 本研究表明，在多模态推理固定模型和训练流程下，数据筛选中的难度和对齐比多样性与合成增强更重要，主导模型性能。


<details>
  <summary>Details</summary>
Motivation: 探究多模态推理任务中的数据筛选（curation）策略对模型性能的影响，尤其是在已固定模型架构和训练流程的情况下。

Method: 固定模型和训练流程后，采用源自Walton Multimodal Cold Start的紧凑数据集，通过难度筛选和对齐构建训练集，通过消融实验对比数据规模、多样性、合成增强等因素对推理性能的影响。

Result: 通过在NeurIPS 2025 DCVLR挑战赛中，利用基于难度筛选并对齐的基础数据集，获得第一名。消融实验证明难度驱动的数据筛选是性能提升的关键，数据集规模扩大仅减少训练的方差，对均值准确率影响有限，多样性和合成增强反而无益甚至有害。

Conclusion: DCVLR问题属于饱和评测阶段，数据集的对齐和难度选择对于提升数据-效率型多模态推理性能起决定性作用，常用的多样性和增强手段并不能带来额外收益。

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [6] [Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics](https://arxiv.org/abs/2601.11012)
*Jiahao Wang,Shuangjia Zheng*

Main category: cs.AI

TL;DR: 为克服传统方法在蛋白设计中的高维复杂性和结构约束问题，本文提出了结合哈密顿动力学和贝叶斯优化的HADES方法，并在多项指标上取得了优越性能，成功实现蛋白结构与序列互约束的高效设计。


<details>
  <summary>Details</summary>
Motivation: 现有基于序列的蛋白优化方法无法有效应对高维复杂性，易受互作效应（epistasis）和结构约束忽视的影响，导致优化效果受限。

Method: 提出了HADES，一种基于哈密顿动力学采样的贝叶斯优化方法，通过结构感知的近似后验高效采样。采用动量和模拟物理运动的不确定性来加速采样，并结合位置离散化将连续状态转换为离散蛋白序列。后验由两阶段编码-解码框架支持，以学习突变邻居间的结构和功能关系，形成平滑的采样景观。

Result: 大规模实验表明，HADES在多项评估指标上超越当前主流方法，能够设计出结构相似且功能优化的蛋白序列。

Conclusion: 本文提出的方法优于现有主流基准，在大量体外评估指标中表现更佳，能够有效地进行蛋白序列的设计和优化，充分利用蛋白结构与序列的互约束关系。

Abstract: The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.

</details>


### [7] [BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search](https://arxiv.org/abs/2601.11037)
*Shiyu Liu,Yongjing Yin,Jianhao Yan,Yunbo Tang,Qinggang Zhang,Bei Li,Xin Chen,Jingang Wang,Xunliang Cai,Jinsong Su*

Main category: cs.AI

TL;DR: 本文提出BAPO，优化LLM基于RL的agent推理边界识别能力，有效提升模型在证据不足时正确使用“IDK”，大幅增强搜索可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有RL优化的LLM agentic search在解答复杂问题时，缺乏对自身推理边界的识别能力，很少在信息不充分时回答“IDK”，导致不可靠甚至风险性的答案。提升模型可靠性亟需解决这一问题。

Method: 提出了Boundary-Aware Policy Optimization (BAPO)强化学习框架，包括分组边界感知奖励和自适应奖励调节器，促进在推理受限时合理使用“IDK”。在早期探索时通过调节器抑制奖励，避免模型滥用“IDK”。

Result: 在四个基准测试上，BAPO方法显著增强了agentic search的整体可靠性。

Conclusion: BAPO方法显著提升了基于RL的agentic search在LLM上的可靠性，使其在证据不足或推理受限时能更好地使用“IDK”回答。

Abstract: RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search.

</details>


### [8] [ReCreate: Reasoning and Creating Domain Agents Driven by Experience](https://arxiv.org/abs/2601.11100)
*Zhezheng Hao,Hong Wang,Jian Luo,Jianqing Zhang,Yuyan Zhou,Qiang Lin,Can Wang,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: ReCreate通过系统性利用智能体交互经验，实现了自动化、可解释且高性能的领域智能体生成，在多个领域显著优于传统与现有自动方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型智能体多为人工设计，构建代价高，难以适应多变的任务需求。自动生成智能体的现有方法多以黑箱方式进行，只关注最终性能指标，忽略了导致智能体成败的具体原因，且计算代价高。故需提出更有效的自动化智能体构建方法。

Method: 提出了一种名为ReCreate的以经验驱动的自动化智能体生成框架。该方法包含三大核心模块：（1）智能体经验存储与检索，实现交互历史的按需调取和分析；（2）推理-创造协同流水线，将执行经验映射为 scaffold（智能体结构）的编辑建议；（3）分层式更新机制，将具体实例抽象为可复用的领域模式。整体采用agent-as-optimizer范式，持续利用经验优化智能体设计。

Result: 在多个不同领域的实验中，ReCreate框架无论是对比人工设计还是现有自动化生成方法，在初始仅使用极少种子结构的情况下，均表现出更优异的性能。

Conclusion: ReCreate框架实现了基于经验的智能体自动生成与优化，有效提升了自动化水平和智能体性能，超过人工和现有方法，证明了利用交互历史作为优化依据的有效性。

Abstract: Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.

</details>


### [9] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: TANDEM转变了音视频有害内容检测任务为结构化推理问题，利用新颖的联动强化学习提升多模态解释性与识别准确度，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体上的长文本多模态内容（音频、视觉、文本等）使有害叙述更具隐蔽性和复杂性，自动化检测系统缺乏可解释性，无法为人工监管提供细粒度证据。

Method: 方法引入TANDEM框架，将任务由二分类转为结构化推理，利用视觉-文本与音频-文本模型联动，通过无须密集标注的自约束跨模态强化学习共同优化，实现对有害内容的稳定推理和精确时序定位。

Result: 提出的TANDEM框架在三大基准数据集上表现优异，尤其在HateMM目标识别任务中F1分数为0.73（比SOTA提升30%），并能精确完成时序定位。

Conclusion: 结构化、可解释的多模态对齐机制是可行的，这为下一代透明且可操作的内容安全工具提供了范例。

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [10] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: XChoice框架以机制型参数为指标，揭示AI与人类在时间分配等决策中的深层次一致性与失衡，比传统结果指标更具解释力。


<details>
  <summary>Details</summary>
Motivation: 目前用于评估AI与人类在受限决策场景中的一致性的方法，如准确率和F1评分，无法揭示更深层次的决策机制和内在参数，因此需要开发更具解释性和机制性的评估框架。

Method: 通过将AI和人类的决策数据拟合到机制型决策模型，并恢复参数，进而比较参数向量，评估对齐状况。模型应用于ATUS数据，并进行异质性分析、鲁棒性检验以及针对性干预评估。

Result: 提出了XChoice框架，通过拟合机制型决策模型，恢复出可解释参数（决策要素重要性、约束敏感性、权衡），并通过参数向量比较深入分析AI与人类对齐情况。实证分析发现，不同模型、活动和子群体间存在异质性对齐情况，其中黑人和已婚群体的对齐失衡尤为突出。

Conclusion: XChoice能够诊断并量化AI-human misalignment的具体机制，为后续定向改进（如RAG干预）提供依据，推动领域从表面结果对齐走向机制解释和干预优化。

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [11] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 该研究构建了针对空间规划问题的智能体基准，并发现当前通用LLMs在真实物理约束下任务表现较弱。


<details>
  <summary>Details</summary>
Motivation: 以往智能体基准多针对符号或弱物理场景，未充分评估LLMs在真实物理约束领域的规划能力。针对航天及高现实性环境的需求，提出新的基准以推动相关研究。

Method: 方法包括建立高物理约束、多目标、需长时决策的空间规划任务集，并整合多种调度机制（如地面站通信、地球观测），通过统一协议测试当前主流开源与闭源智能体LLMs系统表现。

Result: 提出了AstroReason-Bench基准，用于评估基于大型语言模型（LLMs）的智能体在空间规划问题（SPP）中的规划表现。实验结果表明，现有智能体LLMs在具备严格物理约束的实际场景下，明显不如专用问题求解器。

Conclusion: AstroReason-Bench为未来智能体研究提供了更具挑战性的测试平台。当前LLMs在高物理现实性场景下尚存显著不足。

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [12] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: 该算法自动调优约束求解器超参数，用贝叶斯优化显著超过默认配置和简单局部搜索。


<details>
  <summary>Details</summary>
Motivation: 约束规划求解器的性能高度依赖超参数设置，但手工调参耗时且需要专家知识，因此需要自动化的高效超参数优化方法来提升求解质量并降低人力消耗。

Method: 提出两阶段自动化超参数优化框架：先用探测阶段统计各种超参数表现（用贝叶斯优化和Hamming距离搜索），再在剩余时间用最佳配置解决问题，并在ACE与Choco求解器、多实例下对不同方法进行实验对比分析。

Result: 该论文提出了一种自动化超参数优化框架——Probe and Solve算法，并将其集成到CPMpy库中。该方法在约束规划求解器ACE和Choco上进行了测试，并与默认配置进行性能比较。结果表明，利用贝叶斯优化方法时，Probe and Solve算法能在25.4%的ACE实例和38.6%的Choco实例上显著提升解决质量，且在大多数剩余实例中能匹配或超过默认性能。同时，该算法在相同设置下明显优于基于Hamming距离的搜索方法。

Conclusion: Probe and Solve算法能显著提升约束规划求解器的性能，是一种切实有效且能充分利用资源的超参数自动优化方法，适用于多类型问题。

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [13] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文扩展了LLM在预测流程监控中的应用，结果表明其在数据少时表现优异且具备更强推理能力，对未来流程智能具有借鉴价值。


<details>
  <summary>Details</summary>
Motivation: 近年来，基于机器学习与深度学习的方法在预测性流程监控领域取得了进展，但如何利用大型语言模型（LLM）提升预测效果、扩展其泛化能力和推理机制尚待系统性研究。

Method: 本文扩展了先前以LLM为核心、基于prompt的方法，围绕关键性能指标（KPI），在三个不同事件日志上综合性评估其泛化性、语义利用及推理机制，涵盖总时长预测与活动发生预测两个典型KPI，并分析模型的推理过程。

Result: 在仅有100条流程记录的数据稀缺情景下，LLM方法在总时长和活动发生预测上均优于主流基线方法；此外，实验证明LLM不仅能利用其内在先验知识，还能有效利用训练数据中的相互关联；推理机制分析展示了LLM具备更高阶的推理能力，而不是简单照搬已有方法。

Conclusion: LLM不仅在数据稀缺场景下实现更优预测，还能进行复杂推理，显示出超越传统方法的潜力，推进了预测性流程监控在泛化性与推理能力上的边界。

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [14] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: 提出LEG框架，将专家定性知识与优化算法结合，用于医疗点优先升级，实验验证其有效、公平，实现覆盖最大化。


<details>
  <summary>Details</summary>
Motivation: 卫生资源有限，需在升级医疗点时优先排序，实现最大人口覆盖；专家和利益相关方的标准多为语言表述，难以量化，需一种能结合定量优化与定性专家知识的方法。

Method: 提出了Large language model and Extended Greedy（LEG）混合框架，将专家知识与优化算法结合，用于升级医疗点。该框架融合了具有理论保证的覆盖率优化贪心算法与大语言模型（LLM）驱动的人机交互迭代，以实现专家定性指导与优化目标的统一。

Result: 在埃塞俄比亚三地区真实数据实验显示，LEG框架能兼顾人口覆盖的最优化与专家定性需求，有效提升公平性与数据驱动的卫生系统规划。

Conclusion: LEG框架为卫生设施升级提供了理论与实践结合的新方法，有助于实现资源利用最优化与专家主导的政策制定，对低资源环境下的数据驱动医疗决策具有重要参考价值。

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


### [15] [BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics](https://arxiv.org/abs/2601.11492)
*Kaiwen Wang,Kaili Zheng,Rongrong Deng,Qingmin Fan,Milin Zhang,Zongrui Li,Xuesi Zhou,Bo Han,Liren Chen,Chenyi Guo,Ji Wu*

Main category: cs.AI

TL;DR: BoxMind利用AI解析拳击赛事视频，提取技术-战术指标，结合图模型优化赛局预测与即时战术建议，在奥运会实战中提升队伍战绩。


<details>
  <summary>Details</summary>
Motivation: 拳击等对抗型运动因动作复杂及战术结构表征匮乏，AI驱动战术分析发展滞后。该研究旨在通过结构化战术表征与智能分析，提升计算机视觉在竞技体育中的决策支持能力。

Method: 1. 明确定义原子拳击事件，具备时间、空间与技术属性。2. 视频解析为18类技术-战术指标。3. 构建图结构模型，融合显式特征与隐变量进行赛局动态建模。4. 将预测结果导向战术调整，实现闭环反馈推荐。

Result: BoxMind系统能够解析拳击比赛的动作动态，将比赛录像中的原子拳击事件映射为18个层次化技术-战术指标，通过图结构预测模型融合显式的技术-战术特征与可学习的时变隐变量，实现赛局输出预测与战术建议。

Conclusion: BoxMind不仅在比赛结果预测中表现优异（BoxerGraph数据集69.8%、奥运赛事87.5%准确率），还能生成媲美人类专家的战术推荐，并已在顶级赛事闭环应用验证，推动队伍取得历史性成绩。

Abstract: Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [16] [Can Small Agent Collaboration Beat a Single Big LLM?](https://arxiv.org/abs/2601.11327)
*Agata Żywot,Xinyi Chen,Maarten de Rijke*

Main category: cs.MA

TL;DR: 工具增强能显著提升小模型性能，甚至超过更大模型；显式思考需谨慎设计，否则可能反而损害性能。


<details>
  <summary>Details</summary>
Motivation: 探索小规模、工具增强型智能体是否能在GAIA基准测试中匹敌甚至超越大型一体化模型。

Method: 采用Qwen3不同规模模型（4B-32B）在经过改造的Agentic-Reasoning框架下，设置不同的思考方式（无、仅规划、完全思考）和工具使用（搜索、代码、思维导图），以分析各因素对GAIA基准性能的影响。

Result: 工具增强为模型性能带来了最大且最稳定的提升。配备工具的小模型（4B）可以在GAIA任务上超过不配备工具的大模型（32B）。显式思考对性能影响高度依赖具体设置和任务难度。

Conclusion: 工具增强是提升智能体性能的关键，尤其在小模型上表现突出。显式思考的设计需结合任务配置，否则可能带来负面影响。

Abstract: This report studies whether small, tool-augmented agents can match or outperform larger monolithic models on the GAIA benchmark. Using Qwen3 models (4B-32B) within an adapted Agentic-Reasoning framework, we isolate the effects of model scale, explicit thinking (no thinking, planner-only, or full), and tool use (search, code, mind-map). Tool augmentation provides the largest and most consistent gains. Using tools, 4B models can outperform 32B models without tool access on GAIA in our experimental setup. In contrast, explicit thinking is highly configuration- and difficulty-dependent: planner-only thinking can improve decomposition and constraint tracking, while unrestricted full thinking often degrades performance by destabilizing tool orchestration, leading to skipped verification steps, excessive tool calls, non-termination, and output-format drift.

</details>


### [17] [EvidFuse: Writing-Time Evidence Learning for Consistent Text-Chart Data Reporting](https://arxiv.org/abs/2601.05487)
*Huanxiang Lin,Qianyue Wang,Jinwu Hu,Bailin Chen,Qing Du,Mingkui Tan*

Main category: cs.MA

TL;DR: 该论文提出了一种训练免疫的多智能体框架EvidFuse，实现了数据驱动报告的文本与图表协同生成。


<details>
  <summary>Details</summary>
Motivation: 当前LLM系统报告生成多采取分阶段流程，容易导致图文不一致和见解空间受限，难以动态调整分析内容。亟需一种能在写作期间灵活协同文本和图表生成的新框架。

Method: EvidFuse包括两个协同组件：一个具备EDA知识且可访问原始表格的数据增强分析智能体，负责分析；一个实时构证写作智能体，负责规划报告大纲、草拟文本和按需请求分析，从而实现写作过程中动态嵌入图表。该方法无需额外训练。

Result: 实验证明，EvidFuse在图表质量、图文一致性以及报告实用性方面，均在LLM评判和人工评测中获得最高分。

Conclusion: EvidFuse能实时根据文本需求及时生成并引入可视化证据，有效解决了传统方法中的图文不一致和见解僵化问题，并在多项评测中取得最佳表现。

Abstract: Data-driven reports communicate decision-relevant insights by tightly interleaving narrative text with charts grounded in underlying tables. However, current LLM-based systems typically generate narratives and visualizations in staged pipelines, following either a text-first-graph-second or a graph-first-text-second paradigm. These designs often lead to chart-text inconsistency and insight freezing, where the intermediate evidence space becomes fixed and the model can no longer retrieve or construct new visual evidence as the narrative evolves, resulting in shallow and predefined analysis. To address the limitations, we propose \textbf{EvidFuse}, a training-free multi-agent framework that enables writing-time text-chart interleaved generation for data-driven reports. EvidFuse decouples visualization analysis from long-form drafting via two collaborating components: a \textbf{Data-Augmented Analysis Agent}, equipped with Exploratory Data Analysis (EDA)-derived knowledge and access to raw tables, and a \textbf{Real-Time Evidence Construction Writer} that plans an outline and drafts the report while intermittently issuing fine-grained analysis requests. This design allows visual evidence to be constructed and incorporated exactly when the narrative requires it, directly constraining subsequent claims and enabling on-demand expansion of the evidence space. Experiments demonstrate that EvidFuse attains the top rank in both LLM-as-a-judge and human evaluations on chart quality, chart-text alignment, and report-level usefulness.

</details>
