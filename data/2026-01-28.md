<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 1]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.AI](#cs.AI) [Total: 23]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Reimagining Peer Review Process Through Multi-Agent Mechanism Design](https://arxiv.org/abs/2601.19778)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.MA

TL;DR: 论文针对软件工程领域同行评审危机，提出以多智能体强化学习为核心的机制创新方案，包含信用经济、智能分配与一致性混合验证等措施，为实现可持续评审流程奠定理论及应用基础。


<details>
  <summary>Details</summary>
Motivation: 同行评审机制因投稿量激增、激励失衡、评审疲劳等问题陷入危机，社区普遍认为该过程“已坏掉”，亟需创新机制来重塑评审流程。

Method: 将学术社区建模为随机多智能体系统，利用多智能体强化学习（MARL）设计激励兼容机制，包括信用制投稿经济、MARL优化的评审分配、及混合审查一致性验证。

Result: 提出三项机制干预策略，分析潜在安全威胁、公平性问题，并给出分阶段试点评估指标，为同行评审机制的可持续发展提供理论与实践框架建议。

Conclusion: 提出用多智能体强化学习和机制设计来解决软件工程研究领域的同行评审系统性危机，展望可持续的同行评审研究方向。

Abstract: The software engineering research community faces a systemic crisis: peer review is failing under growing submissions, misaligned incentives, and reviewer fatigue. Community surveys reveal that researchers perceive the process as "broken." This position paper argues that these dysfunctions are mechanism design failures amenable to computational solutions. We propose modeling the research community as a stochastic multi-agent system and applying multi-agent reinforcement learning to design incentive-compatible protocols. We outline three interventions: a credit-based submission economy, MARL-optimized reviewer assignment, and hybrid verification of review consistency. We present threat models, equity considerations, and phased pilot metrics. This vision charts a research agenda toward sustainable peer review.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [2] [Accelerating Large-Scale Cheminformatics Using a Byte-Offset Indexing Architecture for Terabyte-Scale Data Integration](https://arxiv.org/abs/2601.18921)
*Malikussaid,Septian Caesar Floresko,Sutiyo*

Main category: cs.DB

TL;DR: 数据库整合效率大提升，哈希标识符有局限，完整数据标识符更可靠。该方法适用于高要求数据唯一性的科学数据集成。


<details>
  <summary>Details</summary>
Motivation: 大型化学数据库的集成是现代化学信息学研究的关键瓶颈，尤其是在机器学习应用对高质量多源验证数据集的需求下。该工作旨在解决数据库整合在百万级数据量下的可扩展性和数据完整性问题。

Method: 以PubChem、ChEMBL和eMolecules等三大公有数据库为例，采用字节偏移索引技术替代传统的暴力搜索，在分子性质预测任务中构建高质量的整合数据集，并系统验证数据唯一性与完整性。

Result: 字节偏移索引将算法复杂度从O(NxM)降到O(N+M)，将数据库处理时间由预计100天缩短至3.2小时，实现了740倍性能提升。发现InChIKey存在哈希冲突，需以完整InChI字符串重构数据处理流程，最终成功提取435,413个有效分子。

Conclusion: 字节偏移索引显著提升了大规模数据库整合效率，证明了在唯一性约束高于哈希标识符能力场景下，完整标识符不可或缺，并为科学数据集成提供了通用方法。

Abstract: The integration of large-scale chemical databases represents a critical bottleneck in modern cheminformatics research, particularly for machine learning applications requiring high-quality, multi-source validated datasets. This paper presents a case study of integrating three major public chemical repositories: PubChem (176 million compounds), ChEMBL, and eMolecules, to construct a curated dataset for molecular property prediction. We investigate whether byte-offset indexing can practically overcome brute-force scalability limits while preserving data integrity at hundred-million scale. Our results document the progression from an intractable brute-force search algorithm with projected 100-day runtime to a byte-offset indexing architecture achieving 3.2-hour completion-a 740-fold performance improvement through algorithmic complexity reduction from O(NxM) to O(N+M). Systematic validation of 176 million database entries revealed hash collisions in InChIKey molecular identifiers, necessitating pipeline reconstruction using collision-free full InChI strings. We present performance benchmarks, quantify trade-offs between storage overhead and scientific rigor, and compare our approach with alternative large-scale integration strategies. The resulting system successfully extracted 435,413 validated compounds and demonstrates generalizable principles for large-scale scientific data integration where uniqueness constraints exceed hash-based identifier capabilities.

</details>


### [3] [Educational Database Prototype: the Simplest of All](https://arxiv.org/abs/2601.19165)
*Yi Lyu,Yiyin Shen,Takashi Matsuzawa*

Main category: cs.DB

TL;DR: 论文介绍了EduDB，一个用于教学的数据库系统原型，解决现有课程中学生难以全面理解数据库结构的问题，并通过该平台设计了一系列实践项目用于优化学习。


<details>
  <summary>Details</summary>
Motivation: 现有数据库课程中，学生实现特定模块时容易陷入细节，难以全面理解数据库系统结构，因此需要一种更简洁、便于教学的数据库原型。

Method: 设计并实现了EduDB数据库系统，并基于该平台开发了一系列课程项目用于教学。

Result: EduDB为学生提供了简洁、全面的数据库系统概览，支持课程中各种优化实践，提升教学效果。

Conclusion: 提出了EduDB，一个简化、教育用途的数据库系统原型，旨在帮助学生更好地理解数据库内部设计。

Abstract: Database Management System (DBMS) is designed to help store and process large collections of data, and is incredibly flexible to perform various kinds of optimizations as long as it achieves serializability with a high-level interface available. The current undergraduate level DBMS course in UW-Madison (i.e., CS564) involves implementing specific modules of DB architecture, including B+ tree, but students may end up spending numerous amounts of effort on corner cases and not gaining a more comprehensive understanding of the internal design. Thus, we present EduDB, a simple database prototype for educational purposes that provides students a clean, concise, and comprehensive overview of the database system. We also attempt to develop an integrative series of course projects based on EduDB, which offers a platform for students to perform any optimization learned during the semester.

</details>


### [4] [Create Benchmarks for Data Lakes](https://arxiv.org/abs/2601.19176)
*Yi Lyu,Pei-Chieh Lo,Natan Lidukhover*

Main category: cs.DB

TL;DR: 本文提出了一个面向数据湖系统的、新的基准测试框架，支持多种数据类型和工作负载，能有效、可复现地评估不同平台的性能，并通过实验演示其实用价值。


<details>
  <summary>Details</summary>
Motivation: 数据湖能够灵活、高效地存储和分析大量异构数据，但目前缺少统一和全面的性能评估基准，现有基准多偏重结构化SQL工作负载，不适用于数据湖的多样化应用场景。

Method: 提出了针对数据湖系统的全新基准测试框架，覆盖多种数据类型和工作负载模型，包括数据检索、聚合、查询和相似性搜索，并衡量如查询执行时间、元数据生成时间与元数据规模等关键性能指标。该框架支持可扩展和可复现的数据集生成及系统评估。

Result: 在CloudLab环境下实验验证该基准测试框架的有效性，并实现了对商用与开源数据湖平台的客观性能对比。

Conclusion: 该基准框架能填补数据湖性能评估领域的空白，推动数据湖系统的公平对比与持续进步，为用户与开发者提供实用的测试工具。

Abstract: Data lakes have emerged as a flexible and scalable solution for storing and analyzing large volumes of heterogeneous data, including structured, semi-structured, and unstructured formats. Despite their growing adoption in both industry and academia, there is a lack of standardized and comprehensive benchmarks for evaluating the performance of data lake systems. Existing benchmarks primarily target traditional data warehouses and focus on structured SQL workloads, making them insufficient for capturing the diverse workloads and access patterns typical of data lakes.
  In this work, we propose a new benchmarking framework for data lakes that aims to provide an objective and comparative evaluation of different data lake implementations. Our benchmark covers multiple data types and workload models, including data retrieval, aggregation, querying, and similarity search, which is a common yet underexplored operation in existing benchmarks. We measure key performance metrics such as query execution time, metadata generation time, and metadata size across different scale factors. The benchmark is designed to be extensible and reproducible, enabling users to generate datasets and evaluate data lake systems under realistic and diverse scenarios. We conduct our experiments on CloudLab and demonstrate how the proposed benchmark can be used to compare both commercial and open-source data lake platforms.

</details>


### [5] [Topology-Aware Subset Repair via Entropy-Guided Density and Graph Decomposition](https://arxiv.org/abs/2601.19671)
*Guoqi Zhao,Xixian Han,Xiaolong Wan*

Main category: cs.DB

TL;DR: 本文提出了一种结合密度与冲突度量的新型子集修复框架，能更有效识别并修复数据中的约束冲突，同时较好保留数据质量，且具备较强的扩展性和理论保障。


<details>
  <summary>Details</summary>
Motivation: 现有的子集修复方法在处理由约束违反导致的冲突元组时，存在多解歧义（多个最小子集修复解），密度驱动的子集修复方法虽然能缓解歧义问题，但易受脏数据密集簇影响、计算成本高、属性权重一律等局限。

Method: 1）引入两层冲突检测策略，将属性倒排索引与CFD规则分组结合提高检测效率；2）创新性定义EntroCFDensity，结合信息熵和CFD权重动态调整属性重要性，减少同质性偏差；3）定义冲突度量，配合局部密度通过系数变异自适应分配惩罚权重，实现拓扑自适应修复；4）通过冲突图分解，将全局问题转化为独立子图上的局部修复；5）设计了可扩展启发式算法PPIS及具备理论保障的MICO混合整数规划算法。

Result: 提出了一个基于联合密度-冲突惩罚模型的拓扑感知近似子集修复框架，通过引入新的密度指标、冲突度量和自适应权重分配机制，改进了修复的准确性和鲁棒性，同时提升了高质量数据的保留效果。实验结果验证了该方法的优越性。

Conclusion: 所提拓扑感知的子集修复方法和算法能够有效提升数据修复的准确性与鲁棒性，兼顾修复效率，并在多项指标上优于现有方法。

Abstract: Subset repair is an important data cleaning technique that enforces integrity constraints by deleting a minimal number of conflicting tuples, yet multiple minimal repairs often exist. Density-based methods address this ambiguity by favoring repairs that preserve dense, high-quality data regions; however, their effectiveness is limited by density bias from dirty clusters, high computational cost, and uniform attribute weighting. We propose a topology-aware approximate subset repair framework based on a joint density-conflict penalty model. The framework integrates three key components. First, a two-layer conflict detection strategy combines attribute inverted indexes with CFD rule grouping to efficiently identify violations. Second, we introduce EntroCFDensity, a density metric that incorporates information entropy and CFD weights to dynamically adjust attribute importance and reduce homogeneity bias. Third, a conflict degree measure is defined to complement local density, enabling a topology-adaptive penalty mechanism with dynamic weight allocation guided by the coefficient of variation. The conflict graph is further decomposed into independent subgraphs, transforming global repair into tractable local subproblems. Based on this framework, we develop two algorithms: PPIS, a scalable heuristic, and MICO, a mixed-integer programming method with theoretical guarantees. Experimental results show that our approach improves repair accuracy and robustness while effectively preserving high-quality data.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Routing End User Queries to Enterprise Databases](https://arxiv.org/abs/2601.19825)
*Saikrishna Sudarshan,Tanay Kulkarni,Manasi Patwardhan,Lovekesh Vig,Ashwin Srinivasan,Tanmay Tulsidas Verlekar*

Main category: cs.AI

TL;DR: 作者针对多数据库环境中的自然语言查询路由任务，提出了更结构化、基于推理的解决方案，并在现实数据集扩展基础上验证其在多项指标上的优势。


<details>
  <summary>Details</summary>
Motivation: 随着数据库数量和领域交叉性增加，查询路由难度显著提升，尤其对含糊或不明确的查询。因此需要更强结构化和鲁棒性的推理方法来弥补传统嵌入或直接LLM提示的不足。

Method: 该方法结合显式的模式覆盖建模、结构连通性分析和细粒度语义对齐，再利用基于推理的模块化重排序策略对候选数据库进行排序，以实现高效且准确的查询路由。

Result: 该论文提出了一种基于推理的模块化重排序策略，用于多数据库企业环境下的自然语言查询路由。实验结果显示，该方法在所有评测指标上都优于仅使用嵌入和直接LLM提示的基线方法。

Conclusion: 通过显式建模数据库模式覆盖、结构连接性及语义对齐，论文方法在实际基准测试中实现了更高的查询路由准确性和鲁棒性。

Abstract: We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.

</details>


### [7] [More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas](https://arxiv.org/abs/2601.19082)
*Trung-Kiet Huynh,Dao-Sy Duy-Minh,Thanh-Bang Cao,Phong-Hao Le,Hong-Dan Nguyen,Nguyen Lam Phu Quy,Minh-Luan Nguyen-Vo,Hong-Phat Pham,Pham Phu Hoa,Thien-Kim Than,Chi-Nguyen Tran,Huy Tran,Gia-Thoai Tran-Le,Alessio Buscemi,Le Hong Trang,The Anh Han*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型（LLMs）在重复社交困境（如囚徒困境）中，如何受激励强度和语言语境的影响，展现出特有的策略行为。作者发现，不同模型和语言下，LLM都表现出对激励敏感的条件性策略，并存在明显的跨语言差异，还揭示了语言表达方式对模型策略行为的显著影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地作为自主体参与交互式与多智能体场景，其策略行为对安全性、协调性及AI主导的社会经济系统的发展至关重要，因此有必要深入理解其策略形成机制。

Method: 借助激励强度可调节的囚徒困境实验，考察各类LLM在不同语言下的策略行为模式，并利用训练有监督分类器对经典重复博弈策略进行识别分析，从而解释LLM的战略动态。

Result: LLM在不同模型和语言下展现出对激励强度敏感的条件性策略，且存在明显的跨语言行为差异。语言措辞有时对策略行为的影响可与模型架构本身相媲美甚至更大，提示LLM存在合作倾向，这对AI多体系统的治理与设计具有启示价值。

Conclusion: 建立了一个可用于审核LLM战略行为的统一框架，并指出LLM在协作场景下存在合作偏差，这对AI治理和多智能体系统设计有重要意义。

Abstract: As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.

</details>


### [8] [LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties](https://arxiv.org/abs/2601.18846)
*Urban Skvorc,Niki van Stein,Moritz Seiler,Britta Grimme,Thomas Bäck,Heike Trautmann*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的进化框架，用于自动生成具有特定结构属性的连续黑箱优化基准问题，从而提升现有基准测试集（如BBOB）的结构多样性。


<details>
  <summary>Details</summary>
Motivation: 当前黑箱优化基准测试集结构多样性有限，难以支持复杂景观分析和算法评估，亟需自动化、可控性强的基准问题生成方法。

Method: 采用LLaMEA框架，将LLM嵌入进化循环，通过自然语言描述指导LLM生成问题代码，并利用ELA（Exploratory Landscape Analysis）属性预测器对候选函数打分。引入ELA空间的适应度共享机制以提升多样性，并通过盆吸引域分析、统计测试和可视化验证生成函数的结构特性。

Result: 生成的函数在多项结构属性（如多模态性、可分性、盆大小均匀性等）上展示出预期特征，且在低维嵌入（t-SNE）下与BBOB保持特性连续，拓展了测试集覆盖范围。

Conclusion: 所提出的方法能够生成具备明确结构特性的优化函数，其组成的新基准函数库在特性空间中补充了现有BBOB集合，具备高可解释性和可复现性，可服务于景观分析和自动算法选择等任务。

Abstract: Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.

</details>


### [9] [Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System](https://arxiv.org/abs/2601.18897)
*Qusai Khaled,Bahjat Mallak,Uzay Kaymak,Laura Genga*

Main category: cs.AI

TL;DR: 提出了IT2-ANFIS方法，实现污水处理厂能耗预测，兼具解释性和预测区间，同等精度下不确定性更低且可解释性强。


<details>
  <summary>Details</summary>
Motivation: 现有污水处理厂能耗预测依赖机器学习模型，但缺乏对预测不确定性的可解释性量化，影响安全和风险管理。本研究旨在实现风险感知、可解释的预测系统。

Method: 开发并验证了一种区间二型自适应神经模糊推理系统（IT2-ANFIS），通过模糊规则结构生成可解释的预测区间，并分解不确定性至特征层、规则层和实例层。

Result: IT2-ANFIS在墨尔本东部处理厂数据集上的表现与一阶ANFIS预测性能相当，但训练结果方差显著降低，且能生成将置信度与运行条件和输入变量关联的可解释不确定性估计。

Conclusion: IT2-ANFIS不仅实现了高水平预测性能，还显著提升了预测不确定性的解释能力，为污水处理厂等关键基础设施的风险敏感决策提供了理论和实践支撑。

Abstract: Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.

</details>


### [10] [RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures](https://arxiv.org/abs/2601.18924)
*Andrew Jaffe,Noah Reicin,Jinho D. Choi*

Main category: cs.AI

TL;DR: 本工作发现主流LLM在指令顺序打乱下性能大幅下降，说明其指令跟随依赖顺序连续性，对非线性控制流程存在明显局限。


<details>
  <summary>Details</summary>
Motivation: 现有基准往往将任务复杂性与结构顺序混为一谈，难以单独分析提示结构（topology）对模型性能的影响，因此需要新的方法剖析结构敏感性。

Method: 提出了RIFT（Reordered Instruction Following Testbed）基准，通过将指令结构和内容进行解耦，考察大语言模型在不同指令结构下的表现。具体实验利用重新措辞的Jeopardy!题目和答案对，分为线性提示（顺序推进）与跳跃提示（内容相同但顺序打乱），对六个主流开源LLM进行10000次评测。

Result: 在跳跃顺序下，模型准确率最多下降72%，显示出对顺序连续性的显著依赖。50%左右的失败由指令顺序违规和语义漂移导致。

Conclusion: 当前LLM架构本质上将指令跟随作为序列模式学习，而非真正的推理能力，结构敏感性成为其核心短板，对自动化流程及多智能体等实际应用有直接影响。

Abstract: Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.

</details>


### [11] [Neural Theorem Proving for Verification Conditions: A Real-World Benchmark](https://arxiv.org/abs/2601.18944)
*Qiyuan Xu,Xiaokun Luan,Renxi Wang,Joshua Ong Jun Leang,Peixin Wang,Haonan Li,Wenda Li,Conrad Watt*

Main category: cs.AI

TL;DR: 本文提出并发布了针对程序验证VC自动证明的NTP4VC多语言基准，系统评测了多种大型语言模型的能力，发现大模型在VC证明上虽有希望但还远不能满足实践需求。


<details>
  <summary>Details</summary>
Motivation: 现有自动定理证明器难以自动证明实际项目中的复杂VC，导致程序验证需要大量手工证明，严重掣肘实际应用。现有神经定理证明虽在数学推理中有进展，但未针对VC自动化证明这一关键难点提供基准和系统性研究。该工作旨在填补这一空白并推动相关技术发展。

Method: 提出NTP4VC基准，并利用Why3和Frama-C等工业流程，从真实项目自动提取并转换等价VCs，覆盖多种语言（Isabelle、Lean、Rocq），评测通用及定制化大型语言模型在这些VC上的表现。

Result: 建立了首个面向多语言、真实项目VC自动证明的基准，推动了领域进展。评测结果显示，现有大模型虽有能力，但距完全自动化仍有较大提升空间。

Conclusion: 大型语言模型在VC证明中展现潜力，但在程序验证上依然存在显著挑战，显示出当前模型能力与工业实际需求之间存在较大差距。

Abstract: Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.

</details>


### [12] [Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation](https://arxiv.org/abs/2601.19112)
*Nanhan Shen,Zhilei Liu*

Main category: cs.AI

TL;DR: UA-3DTalk提出了针对3D情感人脸合成的全新架构，通过情感提取与不确定性建模，实现更精确的情感呈现和融合效果，性能显著领先现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D人脸合成领域音视情感对齐差、微表情控制不足，以及多视角融合简单粗暴导致渲染质量受损的问题。

Method: 包括情感先验提取模块（将音频解耦为对齐和个性化特征）、情感蒸馏模块（多模态注意力融合及4D高斯编码），以及不确定性变形模块（通过不确定性估算自适应多视角融合，并采用多头解码优化高斯基元）。

Result: UA-3DTalk方法通过引入不确定性感知模块和情感先验提取技术，有效提升了3D情感对话人脸合成过程中音频与视觉的情感对齐度、微表情控制精度及多视角融合的自适应性。实验证明在情感对齐、唇同步和渲染质量等方面均优于最新的同类方法。

Conclusion: 该方法显著改善了音视情感对齐、微表情控制和多视角自适应融合，提升了合成质量和性能，优于主流3D情感人脸合成方法。

Abstract: Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk

</details>


### [13] [Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach](https://arxiv.org/abs/2601.19122)
*Weiran Guo,Bing Bo,Shaoxiang Wu,Jingsheng Yang*

Main category: cs.AI

TL;DR: 提出用强化学习生成对抗性查询，通过博弈式交替训练增强大模型调用函数的能力与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目前提升大语言模型（LLM）函数调用能力的方法主要依赖于手工标注或模型自动生成数据进行微调，但这些方法设计较为固定、缺乏针对性、泛化性和鲁棒性有限。

Method: 采用对抗性数据增强方法，引入强化学习训练的查询模型，专门生成挑战FC模型的对抗性查询，FC模型和查询模型采用零和博弈框架进行交替训练，不断提升双方能力。

Result: 该方法通过引入强化学习对抗性数据增强，有效提升了函数调用（FC）模型的鲁棒性和泛化能力，并能系统地发现并修复模型在与外部工具交互中的薄弱环节。

Conclusion: 本文方法为开发更强大且健壮的函数调用模型提供了新方案，对提升LLM与外部工具协作能力具有重要意义。

Abstract: Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.

</details>


### [14] [LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge](https://arxiv.org/abs/2601.19155)
*Qiujun Li,Zijin Xiao,Xulin Wang,Zhidan Ma,Cheng Yang,Haifeng Li*

Main category: cs.AI

TL;DR: 提出了一种层次化定位智能体 LocationAgent，通过分离推理和证据验证，结合外部线索工具，解决了图像地理定位中的泛化及事实幻觉问题；并发布了新中文基准 CCL-Bench，实验中 LocationAgent 在零样本时优于现有方法至少30%。


<details>
  <summary>Details</summary>
Motivation: 现有图像地理定位方法只能记忆静态知识，遇到开放世界、新场景或需要调用动态知识时表现不佳，且容易产生事实幻觉。针对这一局限，需引入交互式推理及真实证据实时验证机制，并提升中文场景下的测试标准。

Method: (1) 设计 Reasoner-Executor-Recorder (RER) 层次推理结构，分离模型内部推理和证据检验环节，通过角色分工和上下文压缩提升多步推理稳定性；(2) 构建一套地理证据探索工具集供模型实时查找和验证线索；(3) 发布中文场景多样的地理定位基准数据集 CCL-Bench 用于模型评测。

Result: LocationAgent 在零样本测试下的地理定位准确率比现有方法高至少30%，在中文 CCL-Bench 数据集上也展示出优越的泛化和鲁棒性。

Conclusion: LocationAgent 在零样本地理定位任务中具有明显优势，能有效缓解现有方法泛化不足及事实凭空产生的问题，推动了领域发展。提出的数据集 CCL-Bench 也为后续研究提供了标准化测试平台。

Abstract: Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\% in zero-shot settings.

</details>


### [15] [Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement](https://arxiv.org/abs/2601.19170)
*Wangyang Ying,Yanchi Liu,Xujiang Zhao,Wei Cheng,Zhengzhang Chen,Wenchao Yu,Yanjie Fu,Haifeng Chen*

Main category: cs.AI

TL;DR: 论文提出一种多智能体三阶段流程图自动抽取方法，能显著提升抽取结果的结构和逻辑准确率。


<details>
  <summary>Details</summary>
Motivation: 从自然语言自动提取流程图有广阔的前景，但现有方法在结构规范和逻辑对齐性上表现有限，特别是大语言模型易产生结构错误或逻辑误解。

Method: 引入多智能体框架，分三阶段：流程图智能体初步抽取，仿真智能体进行结构诊断与解释，语义智能体做逻辑对齐并语言化反馈，反馈注入后续推理流程，循环优化结果。

Result: 提出的\model{}多智能体框架在结构正确性和逻辑一致性方面相较先进基线有显著提升。

Conclusion: 通过结构和逻辑的专人反馈机制，不依赖人工监督或参数更新，方法具备可解释性、可控性，并能有效减少不同类型的抽取错误。

Abstract: Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.

</details>


### [16] [CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation](https://arxiv.org/abs/2601.19178)
*Jingyu Li,Zhaocheng Du,Qianhui Zhu,kaiyuan Li,Zhicheng Zhang,Song-Li Wu,Chaolang Li,Pengwen Dai*

Main category: cs.AI

TL;DR: CollectiveKV通过跨用户KV共享，大幅减少KV缓存空间，同时保证甚至优化推荐性能。


<details>
  <summary>Details</summary>
Motivation: Transformer结构在序列推荐中的推理延迟高，KV缓存虽能降延迟，但带来存储开销。观察到不同用户KV序列高度相似，且SVD分析显示KV信息大部分可跨用户共享，仅少部分为用户特有，因此提出利用共享机制压缩KV缓存。

Method: 提出了CollectiveKV，一种跨用户的KV共享机制，通过可学习的全局KV池共享高维KV信息，同时结合低维用户特定KV信息，生成最终的KV。推理过程中，每个用户从全局池中检索共享KV并拼接用户特定KV。

Result: 实验证明，CollectiveKV方法可将KV缓存压缩至原始大小的0.8%，且在五种推荐模型与三种数据集上，保持甚至提升模型性能。

Conclusion: CollectiveKV能有效利用用户间的协作信号，实现高效KV缓存压缩，为大规模序列推荐系统带来显著推理性能与存储优化，具备实际应用价值。

Abstract: Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.

</details>


### [17] [CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning](https://arxiv.org/abs/2601.19193)
*Van-Quang Nguyen,Takayuki Okatani*

Main category: cs.AI

TL;DR: CoReTab通过代码驱动的多步推理标注与大规模数据集，显著提升了多模态表格理解中的推理能力、准确性及可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态表格理解数据集主要提供简短事实答案，缺乏多步推理监督，导致模型生成的回答简略，准确性和可解释性有限。

Method: 提出了名为CoReTab的代码驱动推理框架，将多步推理与可执行Python代码结合，实现可扩展、可解释且自动可验证的标注数据集；基于此框架构建了115K样本数据集，并通过三阶段流程微调开源多模态大模型(MLLMs)。在17个MMTab基准任务上对模型进行了评估。

Result: 模型在MMTab基准的表格问答、事实验证、结构理解三大任务上分别较MMTab训练基线提升6.2%、5.7%和25.6%；实现了可追溯和可验证的推理过程。

Conclusion: CoReTab为多模态表格理解提供了更强、可解释且通用的推理范式，能够有效提升多步推理性能，同时带来了结果的可验证性和推理过程透明度。

Abstract: Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.

</details>


### [18] [MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution](https://arxiv.org/abs/2601.19199)
*Libo Sun,Jiwen Zhang,Siyuan Wang,Zhongyu Wei*

Main category: cs.AI

TL;DR: 提出MAGNET框架，通过记忆语义和任务意图的稳定部分，显著提升移动GUI Agent在频繁变动UI中的适应与泛化能力，实验表现优越。


<details>
  <summary>Details</summary>
Motivation: 移动GUI agent因UI频繁变化，导致训练于历史数据的Agent在实际环境下失效。尽管“表层”UI变化，底层功能语义和任务意图往往保持不变。基于这一洞察，希望增强Agent对UI变动的适应性与泛化能力。

Method: MAGNET框架引入了双层记忆结构：静态记忆将不同视觉特征与稳定的功能语义绑定，实现稳健的动作定位；过程记忆则捕捉不同工作流下稳定的任务意图。此外，实现了动态记忆演化机制，优先优化高频访问的知识。

Result: 在AndroidWorld在线基准上大幅优于基础方法，同时在离线基准下也展现了在分布变化下的持续增益，显示出良好的稳健性与泛化性能。

Conclusion: 论证了抓取UI不变的结构（功能语义和任务意图）能有效提升Agent在界面频繁变动环境中的表现和泛化性，对今后软件自动化具有重要价值。

Abstract: Mobile GUI agents powered by large foundation models enable autonomous task execution, but frequent updates altering UI appearance and reorganizing workflows cause agents trained on historical data to fail. Despite surface changes, functional semantics and task intents remain fundamentally stable. Building on this insight, we introduce MAGNET, a memory-driven adaptive agent framework with dual-level memory: stationary memory linking diverse visual features to stable functional semantics for robust action grounding and procedural memory capturing stable task intents across varying workflows. We propose a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge. Online benchmark AndroidWorld evaluations show substantial improvements over baselines, while offline benchmarks confirm consistent gains under distribution shifts. These results validate that leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments.

</details>


### [19] [MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning](https://arxiv.org/abs/2601.19204)
*Zhixi Cai,Fucai Ke,Kevin Leo,Sukai Huang,Maria Garcia de la Banda,Peter J. Stuckey,Hamid Rezatofighi*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体分层可训练自动机（MATA），用于提升视觉-语言推理任务的解释性和性能，通过引入可监督训练的顶层智能体动态选择最优子智能体，实现状态可跟踪和高效推理，达到当前最优效果。


<details>
  <summary>Details</summary>
Motivation: 目前视觉-语言模型难以解释其隐式推理过程，且复杂问题易出现幻觉。虽然组合式方法提升了解释性，但大多仅依赖单一智能体或人工设计流程，无法高效决定在何时协同或竞争，缺乏灵活性和优越性。

Method: 作者提出多智能体层次化自动机结构，将每个智能体设为自动机的一个状态，具体由规则化子自动机实现细粒度控制。顶层转移策略通过LLM微调获得，所有智能体共享内存，实现透明的执行记录。转移策略学习通过构造状态转移轨迹数据集（MATA-SFT-90K），利用监督微调（SFT）训练大语言模型作为高层策略选择器。

Result: MATA在多个主流视觉推理测试集上超越了传统单智能体和已有组合式实现，充分验证了多智能体分层自动机结构及其透明决策机制的有效性。

Conclusion: MATA在多个视觉推理基准上取得了领先的效果，相较单一模型和以往可组合性方法展示了更优的性能和更高的可解释性。

Abstract: Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.

</details>


### [20] [Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection](https://arxiv.org/abs/2601.19245)
*Yongxin Deng,Zhen Fang,Yixuan Li,Ling Chen*

Main category: cs.AI

TL;DR: 本文提出SpikeScore方法，通过量化多轮对话中的不确定性波动，实现了更优异的跨领域大模型幻觉检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法在单一领域数据表现良好，但普遍无法泛化到新的领域。因此亟需一种能够实现跨领域泛化的幻觉检测方法。

Method: 提出SpikeScore指标，量化多轮对话中响应的不确定性波动，通过理论分析与实证验证，使用SpikeScore进行跨领域幻觉检测。

Result: SpikeScore在多个大型语言模型和基准测试上的实验表明，其跨域检测性能优于以往方法，实现了更好的泛化效果。

Conclusion: SpikeScore方法在跨领域幻觉检测任务中优于现有代表性基线和先进方法，能够有效区分幻觉内容和真实内容，验证了方法的有效性和普适性。

Abstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors on data from a single domain while ensuring robust performance across diverse related domains. In studying GHD, we simulate multi-turn dialogues following LLMs initial response and observe an interesting phenomenon: hallucination-initiated multi-turn dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. Based on the phenomenon, we propose a new score SpikeScore, which quantifies abrupt fluctuations in multi-turn dialogues. Through both theoretical analysis and empirical validation, we demonstrate that SpikeScore achieves strong cross-domain separability between hallucinated and non-hallucinated responses. Experiments across multiple LLMs and benchmarks demonstrate that the SpikeScore-based detection method outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods, verifying the effectiveness of our method in cross-domain hallucination detection.

</details>


### [21] [Balancing Sustainability And Performance: The Role Of Small-Scale Llms In Agentic Artificial Intelligence Systems](https://arxiv.org/abs/2601.19311)
*Anh Khoa Ngo Ho,Martin Chauvin,Simon Gosset,Philippe Cordier,Boris Gamazaychikov*

Main category: cs.AI

TL;DR: 较小规模的语言模型可在保证输出质量基础上，有效降低系统推理能耗，并据此提出可持续AI设计原则，包括合理的批处理规模和计算资源分配。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型被广泛应用于智能体系统，推理流程的高能耗带来可持续性挑战。该研究旨在探索缩小模型规模是否能在不损失响应能力和输出质量的前提下降低能耗。

Method: 对不同规模的大语言模型在多智能体真实环境中的能耗及性能进行对比分析。

Result: 较小规模、开源权重的语言模型在保持任务质量的同时，显著降低了能耗。

Conclusion: 小规模模型有助于能效和性能平衡，为可持续的AI系统开发提供实用指导。

Abstract: As large language models become integral to agentic artificial intelligence systems, their energy demands during inference may pose significant sustainability challenges. This study investigates whether deploying smaller-scale language models can reduce energy consumption without compromising responsiveness and output quality in a multi-agent, real-world environments. We conduct a comparative analysis across language models of varying scales to quantify trade-offs between efficiency and performance. Results show that smaller open-weights models can lower energy usage while preserving task quality. Building on these findings, we propose practical guidelines for sustainable artificial intelligence design, including optimal batch size configuration and computation resource allocation. These insights offer actionable strategies for developing scalable, environmentally responsible artificial intelligence systems.

</details>


### [22] [RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization](https://arxiv.org/abs/2601.19404)
*Hongzhu Yi,Xinming Wang,Zhenghao zhang,Tianyu Zong,Yuanxiang Wang,Jun Xie,Tao Yu,Haopeng Jin,Zhepeng Wang,Kaixin Xu,Feng Chen,Jiahuan Chen,Yujia Yang,Zhenyu Guan,Bingkang Shi,Jungang Xu*

Main category: cs.AI

TL;DR: RPO算法通过仅生成部分推理路径，大幅提升了大模型强化微调效率，可与常见算法结合并保持性能，显著减少训练时间和开销。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型强化微调（RLFT）需生成完整的推理路径，训练推理阶段带来极高的计算开销，需要探索降低训练消耗的替代方法。

Method: 通过分析推理路径中各部分对最终结果正确性的影响，RPO只生成推理路径的后缀部分并借助“经验缓存”，替代传统方法需要完整推理路径生成的方式。可与GRPO、DAPO等现有算法融合，属于即插即用方案。

Result: RPO在训练推理阶段减少约95%的token生成，1.5B参数模型训练耗时减少90%，7B模型减少72%。集成后可维持与原算法接近的性能。代码已开源。

Conclusion: 提出了一种名为RPO（Reinforcement Fine-Tuning with Partial Reasoning Optimization）的新型强化微调算法，在大幅减少训练消耗的同时还能保持算法性能。

Abstract: Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.

</details>


### [23] [Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach](https://arxiv.org/abs/2601.19527)
*Temirbolat Maratuly,Pakizar Shamoi,Timur Samigulin*

Main category: cs.AI

TL;DR: 本文提出了结合模糊专家系统与数字孪生的自动化酸性废水处理方案，验证了系统对多场景的适应性与优越性能，提高了安全性与易用性，并具备广泛应用前景。


<details>
  <summary>Details</summary>
Motivation: 酸性水不经适当处理会造成环境危害及设备腐蚀，且手工操作存在安全风险。本研究旨在通过自动化与智能化控制，降低操作难度和相关风险，实现高效、可复用的废水处理。

Method: 开发了基于文档化工业过程的数字孪生模型（使用Honeywell UniSim Design R492），采用系统辨识在MATLAB中建模阀门动态，并通过OPC DA实现实时数据交互。模糊控制器采用分程控制，两阀门分别受控。系统在21种初始压力、5种去模糊策略下共105个场景中进行测试；性能以误差指标和动态响应指标进行综合评价。仿真界面由Python+Streamlit实现，便于交互和展示。

Result: 模糊专家系统成功实现了对关键参数的智能调节，控制策略简单直观，适合初级或非专业人员操作。105种测试场景下系统在各项误差与动态响应指标上表现优异。提出的方法具有普适性，能应用于其他工业过程的自动化控制。

Conclusion: 提出了适用于工业酸性废水处理的模糊专家系统，并通过数字孪生模型和多种测试场景验证了其性能与通用性。该系统简化操作，方便非专业人员使用，并有助于提升自动化与安全性。

Abstract: Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.

</details>


### [24] [Benchmarks Saturate When The Model Gets Smarter Than The Judge](https://arxiv.org/abs/2601.19532)
*Marthe Ballon,Andres Algaba,Brecht Verbeken,Vincent Ginis*

Main category: cs.AI

TL;DR: 本文提出并手工改进了Omni-MATH-2数据集，大幅提升LLMs数学能力评测的可靠性。同时揭示了当前自动判题系统在准确性和能力区分上存在严重问题，强调提升题目和评判者质量的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的评测基准在大型语言模型（LLMs）的发展中非常重要，但由于数据集和评测方法的不准确，评测效果屡受影响。

Method: 对已有数学Benchmarks中的每道题进行人工审校，包括排除无法编译、无法解答及描述混乱的题目，补充缺失信息，并对题目类型进行标注。同时用人工及自动评测者对模型答案进行交叉比对，分析评判者带来的评测误差。

Result: Omni-MATH-2数据集消除了许多原有的噪音，提升了对模型性能评估的准确性。同时评测发现，现有自动评判（如Omni-Judge）在与人类标注的分歧中96.4%为机器错误，表明评测者能力也是评测公平性的关键瓶颈。

Conclusion: 高质量的问题数据与高水平的评测者缺一不可，两者的缺陷均会严重干扰LLMs性能测评，需同步提升以获得有效Benchmarks。

Abstract: Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.

</details>


### [25] [Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search](https://arxiv.org/abs/2601.19622)
*Thomas Bömer,Nico Koltermann,Max Disselnmeyer,Bastian Amberg,Anne Meyer*

Main category: cs.AI

TL;DR: 该文通过引入A*代码到大语言模型提示，实现自动化生成优质A*启发式函数，并在两个问题域中效果优异，超过专家设计。


<details>
  <summary>Details</summary>
Motivation: 传统启发式函数设计依赖人工经验，难以普适和自动化，且高质量设计门槛高。大语言模型和进化方法有潜力自动化这一过程，提高效率和适用范围。

Method: 将A*算法代码嵌入大语言模型的提示中，以利用模型的上下文学习能力。结合进化框架，对生成启发式函数进行优化，并在不同问题领域进行实验评估。

Result: 提出了一种基于大语言模型（LLM）和进化框架自动生成A*搜索启发式函数的新方法，即A-CEoH（Algorithmic-Contextual Evolution of Heuristics），通过在提示中引入A*代码实现跨领域启发式设计自动化。应用于仓储物流中的Unit-Load Pre-Marshalling问题和经典滑块拼图问题。实验结果显示A-CEoH能生成高质量启发式函数，性能优于专家手工设计的启发式函数。

Conclusion: A-CEoH框架能够自动化生成A*搜索高效启发式函数，且性能优于人工设计启发式，显示出LLM与进化框架结合的广泛适用性和有效性。

Abstract: Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.

</details>


### [26] [Agentic Design Patterns: A System-Theoretic Framework](https://arxiv.org/abs/2601.19752)
*Minh-Dung Dao,Quy Minh Le,Hoang Thanh Lam,Duc-Trong Le,Quoc-Viet Pham,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: 本论文提出基于系统理论的5大子系统架构及12种智能体设计模式，系统化解决了智能体设计中复用性和健壮性不足的问题，为行业标准化和工程落地提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 现有智能体AI系统在设计上常常缺乏理论基础，系统性强、可复用的设计方法不足，导致应用可靠性差、难以推广。

Method: 提出了一种系统理论框架，将具身智能体AI系统分解为五大核心功能子系统，并基于该架构形成了12种可复用的智能体设计模式。通过案例分析（以ReAct框架为例），展示模式如何改善系统性架构缺陷。

Result: 引入了基于系统理论的五大功能子系统架构，并划分出12种设计模式，有助于标准化和提升AI智能体系统的模块化与可解释性。实证案例（ReAct框架）验证了方法的有效性。

Conclusion: 通过原则性的系统理论方法和具体设计模式，论文有效标准化了AI智能体的设计语言和流程，提升了自主系统的模块化、可理解性与可靠性，对智能体工程领域具有实际指导意义。

Abstract: With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.

</details>


### [27] [An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care](https://arxiv.org/abs/2601.19824)
*Andre Paulino de Lima,Paula Castro,Suzana Carvalho Vaz de Andrade,Rosa Maria Marcucci,Ruth Caldeira de Melo,Marcelo Garcia Manzato*

Main category: cs.AI

TL;DR: 面向老年医疗护理领域，提出了一种具有优良可解释性的推荐模型，并经实证验证其有效性与应用潜力。


<details>
  <summary>Details</summary>
Motivation: 针对医疗推荐系统在实际应用中的若干核心问题，包括缺乏公开临床数据、推荐原因难以理解、跟随推荐存在风险和疗效不确定性。旨在提升推荐系统在医疗领域的可用性和专业人员的信任度。

Method: 提出了一种利用心理测量数据结构的推荐模型，能够生成模型忠实且易理解的视觉解释。

Result: 模型在巴西的相关医疗数据集上进行了离线性能对比评估，并通过用户研究验证了视觉解释的可解释性。结果表明该模型能够提升个性化护理方案的制定，有助于推动该领域推荐系统的实际应用。

Conclusion: 该方法能够有效提升医疗推荐系统在细分领域（如老年初级护理）中的可用性和解释性，预计将在人口变化带来的需求增长中发挥重要作用。

Abstract: There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.

</details>


### [28] [Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models](https://arxiv.org/abs/2601.19834)
*Jialong Wu,Xiaoying Zhang,Hongyi Yuan,Xiangcheng Zhang,Tianhao Huang,Changjing He,Chaoyi Deng,Renrui Zhang,Youbin Wu,Mingsheng Long*

Main category: cs.AI

TL;DR: 多模态模型在需要物理/空间推理的任务上，通过视觉-语言交替推理可显著提升表现。提出并实证视觉在某些世界模型构建中的天然优势。


<details>
  <summary>Details</summary>
Motivation: 语言大模型在抽象和形式化领域已接近专家水平，但在需要物理/空间智能的任务上仍大幅落后人类；而统一多模态模型（能视觉+语言生成）或许能更好模拟人类推理，但其优势尚不清楚。因而研究视觉生成在哪些情景下、以何种方式有助于推理。

Method: 1. 理论上，将内在世界建模形式化为链式思维推理的核心；分析不同世界模型类型的差异。2. 实证上，设计了需要视觉-语言交替推理的任务集VisWorld-Eval，在先进多模态模型上进行对比测试。

Result: 提出“视觉优越假说”，在某些任务（尤其是与物理世界相关的任务）中，视觉生成比纯语言生成更适合作为内在世界模型。实验证明，在需要视觉-语言交替推理的任务上，交替链式思维(CoT)显著优于纯语言CoT；但在不需要视觉建模的任务中，两者表现相当。还构建了新的评测集VisWorld-Eval。

Conclusion: 多模态世界模型，尤其是视觉生成能力，在使AI具备更接近人类智能的推理能力上具有重要作用。视觉-语言交替推理能显著提升在物理/空间推理任务上的效果。

Abstract: Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.

</details>
